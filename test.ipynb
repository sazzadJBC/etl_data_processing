{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79447c60",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Expected 1 fields in line 8, saw 57",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df  = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/s3_downloads/営業本部/営業活動/名刺データ/eight20250225132647utf8.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8-sig\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpython\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SevenSix/etl_data_extraction/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SevenSix/etl_data_extraction/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SevenSix/etl_data_extraction/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SevenSix/etl_data_extraction/.venv/lib/python3.11/site-packages/pandas/io/parsers/python_parser.py:288\u001b[39m, in \u001b[36mPythonParser.read\u001b[39m\u001b[34m(self, rows)\u001b[39m\n\u001b[32m    285\u001b[39m     indexnamerow = content[\u001b[32m0\u001b[39m]\n\u001b[32m    286\u001b[39m     content = content[\u001b[32m1\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m alldata = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_rows_to_cols\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m data, columns = \u001b[38;5;28mself\u001b[39m._exclude_implicit_index(alldata)\n\u001b[32m    291\u001b[39m conv_data = \u001b[38;5;28mself\u001b[39m._convert_data(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SevenSix/etl_data_extraction/.venv/lib/python3.11/site-packages/pandas/io/parsers/python_parser.py:1063\u001b[39m, in \u001b[36mPythonParser._rows_to_cols\u001b[39m\u001b[34m(self, content)\u001b[39m\n\u001b[32m   1057\u001b[39m             reason = (\n\u001b[32m   1058\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mError could possibly be due to quotes being \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1059\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mignored when a multi-char delimiter is used.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1060\u001b[39m             )\n\u001b[32m   1061\u001b[39m             msg += \u001b[33m\"\u001b[39m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m + reason\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_alert_malformed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_num\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[38;5;66;03m# see gh-13320\u001b[39;00m\n\u001b[32m   1066\u001b[39m zipped_content = \u001b[38;5;28mlist\u001b[39m(lib.to_object_array(content, min_width=col_len).T)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SevenSix/etl_data_extraction/.venv/lib/python3.11/site-packages/pandas/io/parsers/python_parser.py:781\u001b[39m, in \u001b[36mPythonParser._alert_malformed\u001b[39m\u001b[34m(self, msg, row_num)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    765\u001b[39m \u001b[33;03mAlert a user about a malformed row, depending on value of\u001b[39;00m\n\u001b[32m    766\u001b[39m \u001b[33;03m`self.on_bad_lines` enum.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    778\u001b[39m \u001b[33;03m    even though we 0-index internally.\u001b[39;00m\n\u001b[32m    779\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.on_bad_lines == \u001b[38;5;28mself\u001b[39m.BadLineHandleMethod.ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m781\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ParserError(msg)\n\u001b[32m    782\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.on_bad_lines == \u001b[38;5;28mself\u001b[39m.BadLineHandleMethod.WARN:\n\u001b[32m    783\u001b[39m     warnings.warn(\n\u001b[32m    784\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSkipping line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    785\u001b[39m         ParserWarning,\n\u001b[32m    786\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    787\u001b[39m     )\n",
      "\u001b[31mParserError\u001b[39m: Expected 1 fields in line 8, saw 57"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df  = pd.read_csv(\"data/s3_downloads/営業本部/営業活動/名刺データ/eight20250225132647utf8.csv\",encoding=\"utf-8-sig\",engine=\"python\",\n",
    "    sep=\",\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3952645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "df = pd.read_csv(\n",
    "    \"data/s3_downloads/技術本部/iqom/広報（youtube動画）/中村youtube/iqom応用編③/参考資料/optogenetics_twophoton_pubmed_timeline_results_by_year.csv\",\n",
    "    \n",
    "    encoding=\"utf-8\",\n",
    "\n",
    "    # on_bad_lines=\"skip\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2621800c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search query: (optgenetics) AND (two photon)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Search query: (optgenetics) AND (two photon)\n",
       "Year                                        Count\n",
       "2022                                           36\n",
       "2021                                           58\n",
       "2020                                           42\n",
       "2019                                           46"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d179e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"scratch/text.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef2540c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff4dbf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c10af90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_SOURCE = \"https://arxiv.org/pdf/2311.18481\"\n",
    "\n",
    "# we set some start-stop cues for defining an excerpt to print\n",
    "start_cue = \"Copyright © 2024\"\n",
    "stop_cue = \"Application of NLP to ESG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d41ce8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbc/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/jbc/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "converter = DocumentConverter()\n",
    "doc = converter.convert(source=DOC_SOURCE).document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e6fb449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "\n",
    "console = Console(width=210)  # for preventing Markdown table wrapped rendering\n",
    "\n",
    "\n",
    "def print_in_console(text):\n",
    "    console.print(Panel(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38581e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.&lt;/p&gt;                                                                                          │\n",
       "│ &lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Report&lt;/th&gt;&lt;th&gt;Question&lt;/th&gt;&lt;th&gt;Answer&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;IBM 2022&lt;/td&gt;&lt;td&gt;How many hours were spent on employee learning in 2021?&lt;/td&gt;&lt;td&gt;22.5 million hours&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;IBM         │\n",
       "│ 2022&lt;/td&gt;&lt;td&gt;What was the rate of fatalities in 2021?&lt;/td&gt;&lt;td&gt;The rate of fatalities in 2021 was 0.0016.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;IBM 2022&lt;/td&gt;&lt;td&gt;How many full audits were con- ducted in 2022 in                    │\n",
       "│ India?&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Starbucks 2022&lt;/td&gt;&lt;td&gt;What is the percentage of women in the Board of Directors?&lt;/td&gt;&lt;td&gt;25%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Starbucks 2022&lt;/td&gt;&lt;td&gt;What was the total energy con-         │\n",
       "│ sumption in 2021?&lt;/td&gt;&lt;td&gt;According to the table, the total energy consumption in 2021 was 2,491,543 MWh.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Starbucks 2022&lt;/td&gt;&lt;td&gt;How much packaging material was made from renewable mate-    │\n",
       "│ rials?&lt;/td&gt;&lt;td&gt;According to the given data, 31% of packaging materials were made from recycled or renewable materials in FY22.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;                                                       │\n",
       "│ &lt;p&gt;Table 1: Example question answers from the ESG reports of IBM and Starbucks using Deep Search DocQA system.&lt;/p&gt;                                                                                             │\n",
       "│ &lt;p&gt;ESG report in our library via our QA conversational assistant. Our assistant generates answers and also presents the information (paragraph or table), in the ESG report, from which it has generated the   │\n",
       "│ response.&lt;/p&gt;                                                                                                                                                                                                  │\n",
       "│ &lt;h2&gt;Related Work&lt;/h2&gt;                                                                                                                                                                                          │\n",
       "│ &lt;p&gt;The DocQA integrates multiple AI technologies, namely:&lt;/p&gt;                                                                                                                                                  │\n",
       "│ &lt;p&gt;Document Conversion: Converting unstructured documents, such as PDF files, into a machine-readable format is a challenging task in AI. Early strategies for document conversion were based on geometric     │\n",
       "│ layout analysis (Cattoni et al. 2000; Breuel 2002). Thanks to the availability of large annotated datasets (PubLayNet (Zhong et al. 2019), DocBank (Li et al. 2020), DocLayNet (Pfitzmann et al. 2022; Auer et │\n",
       "│ al. 2023), deep learning-based methods are routinely used. Modern approaches for recovering the structure of a document can be broadly divided into two categories: image-based or PDF representation-based .  │\n",
       "│ Imagebased methods usually employ Transformer or CNN architectures on the images of pages (Zhang et al. 2023; Li et al. 2022; Huang et al. 2022). On the other hand, deep learning-&lt;/p&gt;                        │\n",
       "│ &lt;figure&gt;&lt;figcaption&gt;&lt;div class=\"caption\"&gt;Figure 1: System architecture: Simplified sketch of document question-answering pipeline.&lt;/div&gt;&lt;/figcaption&gt;&lt;/figure&gt;                                                 │\n",
       "│ &lt;p&gt;based language processing methods are applied on the native PDF content (generated by a single PDF printing command) (Auer et al. 2022; Livathinos et al. 2021; Staar et al. 2018).&lt;/p&gt;                     │\n",
       "│ &lt;p&gt;                                                                                                                                                                                                            │\n",
       "╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.</p>                                                                                          │\n",
       "│ <table><tbody><tr><th>Report</th><th>Question</th><th>Answer</th></tr><tr><td>IBM 2022</td><td>How many hours were spent on employee learning in 2021?</td><td>22.5 million hours</td></tr><tr><td>IBM         │\n",
       "│ 2022</td><td>What was the rate of fatalities in 2021?</td><td>The rate of fatalities in 2021 was 0.0016.</td></tr><tr><td>IBM 2022</td><td>How many full audits were con- ducted in 2022 in                    │\n",
       "│ India?</td><td>2</td></tr><tr><td>Starbucks 2022</td><td>What is the percentage of women in the Board of Directors?</td><td>25%</td></tr><tr><td>Starbucks 2022</td><td>What was the total energy con-         │\n",
       "│ sumption in 2021?</td><td>According to the table, the total energy consumption in 2021 was 2,491,543 MWh.</td></tr><tr><td>Starbucks 2022</td><td>How much packaging material was made from renewable mate-    │\n",
       "│ rials?</td><td>According to the given data, 31% of packaging materials were made from recycled or renewable materials in FY22.</td></tr></tbody></table>                                                       │\n",
       "│ <p>Table 1: Example question answers from the ESG reports of IBM and Starbucks using Deep Search DocQA system.</p>                                                                                             │\n",
       "│ <p>ESG report in our library via our QA conversational assistant. Our assistant generates answers and also presents the information (paragraph or table), in the ESG report, from which it has generated the   │\n",
       "│ response.</p>                                                                                                                                                                                                  │\n",
       "│ <h2>Related Work</h2>                                                                                                                                                                                          │\n",
       "│ <p>The DocQA integrates multiple AI technologies, namely:</p>                                                                                                                                                  │\n",
       "│ <p>Document Conversion: Converting unstructured documents, such as PDF files, into a machine-readable format is a challenging task in AI. Early strategies for document conversion were based on geometric     │\n",
       "│ layout analysis (Cattoni et al. 2000; Breuel 2002). Thanks to the availability of large annotated datasets (PubLayNet (Zhong et al. 2019), DocBank (Li et al. 2020), DocLayNet (Pfitzmann et al. 2022; Auer et │\n",
       "│ al. 2023), deep learning-based methods are routinely used. Modern approaches for recovering the structure of a document can be broadly divided into two categories: image-based or PDF representation-based .  │\n",
       "│ Imagebased methods usually employ Transformer or CNN architectures on the images of pages (Zhang et al. 2023; Li et al. 2022; Huang et al. 2022). On the other hand, deep learning-</p>                        │\n",
       "│ <figure><figcaption><div class=\"caption\">Figure 1: System architecture: Simplified sketch of document question-answering pipeline.</div></figcaption></figure>                                                 │\n",
       "│ <p>based language processing methods are applied on the native PDF content (generated by a single PDF printing command) (Auer et al. 2022; Livathinos et al. 2021; Staar et al. 2018).</p>                     │\n",
       "│ <p>                                                                                                                                                                                                            │\n",
       "╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from docling_core.transforms.serializer.html import HTMLDocSerializer\n",
    "\n",
    "serializer = HTMLDocSerializer(doc=doc)\n",
    "ser_result = serializer.serialize()\n",
    "ser_text = ser_result.text\n",
    "\n",
    "# we here only print an excerpt to keep the output brief:\n",
    "print_in_console(ser_text[ser_text.find(start_cue) : ser_text.find(stop_cue)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e47fa600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.                                                                                              │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ | Report         | Question                                                         | Answer                                                                                                          |        │\n",
       "│ |----------------|------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------|        │\n",
       "│ | IBM 2022       | How many hours were spent on employee learning in 2021?          | 22.5 million hours                                                                                              |        │\n",
       "│ | IBM 2022       | What was the rate of fatalities in 2021?                         | The rate of fatalities in 2021 was 0.0016.                                                                      |        │\n",
       "│ | IBM 2022       | How many full audits were con- ducted in 2022 in India?          | 2                                                                                                               |        │\n",
       "│ | Starbucks 2022 | What is the percentage of women in the Board of Directors?       | 25%                                                                                                             |        │\n",
       "│ | Starbucks 2022 | What was the total energy con- sumption in 2021?                 | According to the table, the total energy consumption in 2021 was 2,491,543 MWh.                                 |        │\n",
       "│ | Starbucks 2022 | How much packaging material was made from renewable mate- rials? | According to the given data, 31% of packaging materials were made from recycled or renewable materials in FY22. |        │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ Table 1: Example question answers from the ESG reports of IBM and Starbucks using Deep Search DocQA system.                                                                                                    │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ ESG report in our library via our QA conversational assistant. Our assistant generates answers and also presents the information (paragraph or table), in the ESG report, from which it has generated the      │\n",
       "│ response.                                                                                                                                                                                                      │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ ## Related Work                                                                                                                                                                                                │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ The DocQA integrates multiple AI technologies, namely:                                                                                                                                                         │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ Document Conversion: Converting unstructured documents, such as PDF files, into a machine-readable format is a challenging task in AI. Early strategies for document conversion were based on geometric layout │\n",
       "│ analysis (Cattoni et al. 2000; Breuel 2002). Thanks to the availability of large annotated datasets (PubLayNet (Zhong et al. 2019), DocBank (Li et al. 2020), DocLayNet (Pfitzmann et al. 2022; Auer et al.    │\n",
       "│ 2023), deep learning-based methods are routinely used. Modern approaches for recovering the structure of a document can be broadly divided into two categories: image-based or PDF representation-based .      │\n",
       "│ Imagebased methods usually employ Transformer or CNN architectures on the images of pages (Zhang et al. 2023; Li et al. 2022; Huang et al. 2022). On the other hand, deep learning-                            │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ Figure 1: System architecture: Simplified sketch of document question-answering pipeline.                                                                                                                      │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ &lt;!-- image --&gt;                                                                                                                                                                                                 │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ based language processing methods are applied on the native PDF content (generated by a single PDF printing command) (Auer et al. 2022; Livathinos et al. 2021; Staar et al. 2018).                            │\n",
       "│                                                                                                                                                                                                                │\n",
       "│                                                                                                                                                                                                                │\n",
       "╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.                                                                                              │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ | Report         | Question                                                         | Answer                                                                                                          |        │\n",
       "│ |----------------|------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------|        │\n",
       "│ | IBM 2022       | How many hours were spent on employee learning in 2021?          | 22.5 million hours                                                                                              |        │\n",
       "│ | IBM 2022       | What was the rate of fatalities in 2021?                         | The rate of fatalities in 2021 was 0.0016.                                                                      |        │\n",
       "│ | IBM 2022       | How many full audits were con- ducted in 2022 in India?          | 2                                                                                                               |        │\n",
       "│ | Starbucks 2022 | What is the percentage of women in the Board of Directors?       | 25%                                                                                                             |        │\n",
       "│ | Starbucks 2022 | What was the total energy con- sumption in 2021?                 | According to the table, the total energy consumption in 2021 was 2,491,543 MWh.                                 |        │\n",
       "│ | Starbucks 2022 | How much packaging material was made from renewable mate- rials? | According to the given data, 31% of packaging materials were made from recycled or renewable materials in FY22. |        │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ Table 1: Example question answers from the ESG reports of IBM and Starbucks using Deep Search DocQA system.                                                                                                    │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ ESG report in our library via our QA conversational assistant. Our assistant generates answers and also presents the information (paragraph or table), in the ESG report, from which it has generated the      │\n",
       "│ response.                                                                                                                                                                                                      │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ ## Related Work                                                                                                                                                                                                │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ The DocQA integrates multiple AI technologies, namely:                                                                                                                                                         │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ Document Conversion: Converting unstructured documents, such as PDF files, into a machine-readable format is a challenging task in AI. Early strategies for document conversion were based on geometric layout │\n",
       "│ analysis (Cattoni et al. 2000; Breuel 2002). Thanks to the availability of large annotated datasets (PubLayNet (Zhong et al. 2019), DocBank (Li et al. 2020), DocLayNet (Pfitzmann et al. 2022; Auer et al.    │\n",
       "│ 2023), deep learning-based methods are routinely used. Modern approaches for recovering the structure of a document can be broadly divided into two categories: image-based or PDF representation-based .      │\n",
       "│ Imagebased methods usually employ Transformer or CNN architectures on the images of pages (Zhang et al. 2023; Li et al. 2022; Huang et al. 2022). On the other hand, deep learning-                            │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ Figure 1: System architecture: Simplified sketch of document question-answering pipeline.                                                                                                                      │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ <!-- image -->                                                                                                                                                                                                 │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ based language processing methods are applied on the native PDF content (generated by a single PDF printing command) (Auer et al. 2022; Livathinos et al. 2021; Staar et al. 2018).                            │\n",
       "│                                                                                                                                                                                                                │\n",
       "│                                                                                                                                                                                                                │\n",
       "╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from docling_core.transforms.serializer.markdown import MarkdownDocSerializer\n",
    "\n",
    "serializer = MarkdownDocSerializer(doc=doc)\n",
    "ser_result = serializer.serialize()\n",
    "ser_text = ser_result.text\n",
    "\n",
    "print_in_console(ser_text[ser_text.find(start_cue) : ser_text.find(stop_cue)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "483e02ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.                                                                                              │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ | Report         | Question                                                         | Answer                                                                                                          |        │\n",
       "│ |----------------|------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------|        │\n",
       "│ | IBM 2022       | How many hours were spent on employee learning in 2021?          | 22.5 million hours                                                                                              |        │\n",
       "│ | IBM 2022       | What was the rate of fatalities in 2021?                         | The rate of fatalities in 2021 was 0.0016.                                                                      |        │\n",
       "│ | IBM 2022       | How many full audits were con- ducted in 2022 in India?          | 2                                                                                                               |        │\n",
       "│ | Starbucks 2022 | What is the percentage of women in the Board of Directors?       | 25%                                                                                                             |        │\n",
       "│ | Starbucks 2022 | What was the total energy con- sumption in 2021?                 | According to the table, the total energy consumption in 2021 was 2,491,543 MWh.                                 |        │\n",
       "│ | Starbucks 2022 | How much packaging material was made from renewable mate- rials? | According to the given data, 31% of packaging materials were made from recycled or renewable materials in FY22. |        │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ Table 1: Example question answers from the ESG reports of IBM and Starbucks using Deep Search DocQA system.                                                                                                    │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ ESG report in our library via our QA conversational assistant. Our assistant generates answers and also presents the information (paragraph or table), in the ESG report, from which it has generated the      │\n",
       "│ response.                                                                                                                                                                                                      │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ ## Related Work                                                                                                                                                                                                │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ The DocQA integrates multiple AI technologies, namely:                                                                                                                                                         │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ Document Conversion: Converting unstructured documents, such as PDF files, into a machine-readable format is a challenging task in AI. Early strategies for document conversion were based on geometric layout │\n",
       "│ analysis (Cattoni et al. 2000; Breuel 2002). Thanks to the availability of large annotated datasets (PubLayNet (Zhong et al. 2019), DocBank (Li et al. 2020), DocLayNet (Pfitzmann et al. 2022; Auer et al.    │\n",
       "│ 2023), deep learning-based methods are routinely used. Modern approaches for recovering the structure of a document can be broadly divided into two categories: image-based or PDF representation-based .      │\n",
       "│ Imagebased methods usually employ Transformer or CNN architectures on the images of pages (Zhang et al. 2023; Li et al. 2022; Huang et al. 2022). On the other hand, deep learning-                            │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ Figure 1: System architecture: Simplified sketch of document question-answering pipeline.                                                                                                                      │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ &lt;!-- image --&gt;                                                                                                                                                                                                 │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ based language processing methods are applied on the native PDF content (generated by a single PDF printing command) (Auer et al. 2022; Livathinos et al. 2021; Staar et al. 2018).                            │\n",
       "│                                                                                                                                                                                                                │\n",
       "│                                                                                                                                                                                                                │\n",
       "╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.                                                                                              │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ | Report         | Question                                                         | Answer                                                                                                          |        │\n",
       "│ |----------------|------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------|        │\n",
       "│ | IBM 2022       | How many hours were spent on employee learning in 2021?          | 22.5 million hours                                                                                              |        │\n",
       "│ | IBM 2022       | What was the rate of fatalities in 2021?                         | The rate of fatalities in 2021 was 0.0016.                                                                      |        │\n",
       "│ | IBM 2022       | How many full audits were con- ducted in 2022 in India?          | 2                                                                                                               |        │\n",
       "│ | Starbucks 2022 | What is the percentage of women in the Board of Directors?       | 25%                                                                                                             |        │\n",
       "│ | Starbucks 2022 | What was the total energy con- sumption in 2021?                 | According to the table, the total energy consumption in 2021 was 2,491,543 MWh.                                 |        │\n",
       "│ | Starbucks 2022 | How much packaging material was made from renewable mate- rials? | According to the given data, 31% of packaging materials were made from recycled or renewable materials in FY22. |        │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ Table 1: Example question answers from the ESG reports of IBM and Starbucks using Deep Search DocQA system.                                                                                                    │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ ESG report in our library via our QA conversational assistant. Our assistant generates answers and also presents the information (paragraph or table), in the ESG report, from which it has generated the      │\n",
       "│ response.                                                                                                                                                                                                      │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ ## Related Work                                                                                                                                                                                                │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ The DocQA integrates multiple AI technologies, namely:                                                                                                                                                         │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ Document Conversion: Converting unstructured documents, such as PDF files, into a machine-readable format is a challenging task in AI. Early strategies for document conversion were based on geometric layout │\n",
       "│ analysis (Cattoni et al. 2000; Breuel 2002). Thanks to the availability of large annotated datasets (PubLayNet (Zhong et al. 2019), DocBank (Li et al. 2020), DocLayNet (Pfitzmann et al. 2022; Auer et al.    │\n",
       "│ 2023), deep learning-based methods are routinely used. Modern approaches for recovering the structure of a document can be broadly divided into two categories: image-based or PDF representation-based .      │\n",
       "│ Imagebased methods usually employ Transformer or CNN architectures on the images of pages (Zhang et al. 2023; Li et al. 2022; Huang et al. 2022). On the other hand, deep learning-                            │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ Figure 1: System architecture: Simplified sketch of document question-answering pipeline.                                                                                                                      │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ <!-- image -->                                                                                                                                                                                                 │\n",
       "│                                                                                                                                                                                                                │\n",
       "│ based language processing methods are applied on the native PDF content (generated by a single PDF printing command) (Auer et al. 2022; Livathinos et al. 2021; Staar et al. 2018).                            │\n",
       "│                                                                                                                                                                                                                │\n",
       "│                                                                                                                                                                                                                │\n",
       "╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_md = doc.export_to_markdown()\n",
    "print_in_console(doc_md[doc_md.find(start_cue) : doc_md.find(stop_cue)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "094564a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('text', \"## ESG Accountability Made Easy: DocQA at Your Service\\n\\nLokesh Mishra 1 , Cesar Berrospi 1 , Kasper Dinkla 1 , Diego Antognini 1 , Francesco Fusco 1 , Benedikt Bothur 2 , Maksym Lysak 1 , Nikolaos Livathinos 1 , Ahmed Nassar 1 , Panagiotis Vagenas 1 , Lucas Morin 1,3 , Christoph Auer 1 , Michele Dolfi 1 , Peter Staar 1\\n\\n1 IBM Research, R¨ uschlikon, Switzerland\\n\\n{ mis, ceb, dkl, ffu, mly, nli, ahn, pva, lum, cau, dol, taa } @zurich.ibm.com\\n\\n2 IBM Technology, Z¨ urich, Switzerland\\n\\n{ Benedikt.Bothur, Diego.Antognini } @ibm.com\\n\\n3 ETH Z¨ urich, Z¨ urich, Switzerland\\n\\n## Abstract\\n\\nWe present Deep Search DocQA. This application enables information extraction from documents via a questionanswering conversational assistant. The system integrates several technologies from different AI disciplines consisting of document conversion to machine-readable format (via computer vision), finding relevant data (via natural language processing), and formulating an eloquent response (via large language models). Users can explore over 10,000 Environmental, Social, and Governance (ESG) disclosure reports from over 2000 corporations. The Deep Search platform can be accessed at: https://ds4sd.github.io.\\n\\n## Introduction\\n\\nThe global impact of climate change has galvanized organizations to announce key information about their environmental footprint (carbon emissions, energy usage, waste emission and management, etc.). Integrating sustainability information into the company reporting cycle is one of the targets of the UN 2030 Agenda for Sustainable Development and institutions like Principles for Responsible Investing (a UN-supported network of investors) encourage investors to incorporate this information into their investment decisions . Companies are thus increasingly disclosing environmental, social, and governance (ESG) data in their ESG reports, typically as PDF files.\\n\\nUnlike financial data, regulators such as the U.S. SEC do not require public companies to file ESG data with specific forms. There have been massive efforts from several organizations to standardize these reports. However, major challenges continue to persist, including complex regulations, rapidly evolving reporting frameworks, verifying ESG compliance, among others. These matters become more complicated when we realize that most of the ESG reporting is done in non machine-readable formats. Unlocking this vast amount of data in an easily consumable manner would greatly help researchers, policy-makers, lawyers, and corporations by extracting information and gaining insights.\\n\\nTo this end, we have developed Deep Search DocQA. The application offers users to perform document question answering (QA), i.e., users can extract information from any\\n\\nCopyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\\n\\n| Report         | Question                                                         | Answer                                                                                                          |\\n|----------------|------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------|\\n| IBM 2022       | How many hours were spent on employee learning in 2021?          | 22.5 million hours                                                                                              |\\n| IBM 2022       | What was the rate of fatalities in 2021?                         | The rate of fatalities in 2021 was 0.0016.                                                                      |\\n| IBM 2022       | How many full audits were con- ducted in 2022 in India?          | 2                                                                                                               |\\n| Starbucks 2022 | What is the percentage of women in the Board of Directors?       | 25%                                                                                                             |\\n| Starbucks 2022 | What was the total energy con- sumption in 2021?                 | According to the table, the total energy consumption in 2021 was 2,491,543 MWh.                                 |\\n| Starbucks 2022 | How much packaging material was made from renewable mate- rials? | According to the given data, 31% of packaging materials were made from recycled or renewable materials in FY22. |\\n\\nTable 1: Example question answers from the ESG reports of IBM and Starbucks using Deep Search DocQA system.\\n\\nESG report in our library via our QA conversational assistant. Our assistant generates answers and also presents the information (paragraph or table), in the ESG report, from which it has generated the response.\\n\\n## Related Work\\n\\nThe DocQA integrates multiple AI technologies, namely:\\n\\nDocument Conversion: Converting unstructured documents, such as PDF files, into a machine-readable format is a challenging task in AI. Early strategies for document conversion were based on geometric layout analysis (Cattoni et al. 2000; Breuel 2002). Thanks to the availability of large annotated datasets (PubLayNet (Zhong et al. 2019), DocBank (Li et al. 2020), DocLayNet (Pfitzmann et al. 2022; Auer et al. 2023), deep learning-based methods are routinely used. Modern approaches for recovering the structure of a document can be broadly divided into two categories: image-based or PDF representation-based . Imagebased methods usually employ Transformer or CNN architectures on the images of pages (Zhang et al. 2023; Li et al. 2022; Huang et al. 2022). On the other hand, deep learning-\\n\\nFigure 1: System architecture: Simplified sketch of document question-answering pipeline.\\n\\n<!-- image -->\\n\\nbased language processing methods are applied on the native PDF content (generated by a single PDF printing command) (Auer et al. 2022; Livathinos et al. 2021; Staar et al. 2018).\\n\\nApplication of NLP to ESG: ESG reports contain large amount of useful data in textual and tabular format. There have been some attempts to use NLP on this data. Luccioni, Baylor, and Duchene (2020) developed ClimateQA, a model trained to classify whether a sentence from an ESG report answers regulatory questions. In addition, there are several works which aim to mine information from ESG reports for financial predictions (Guo et al. 2020; Goel et al. 2020). Nevertheless, to the best of our knowledge, no QA system which can extract data directly from an ESG report PDF has been reported in the literature.\\n\\nOCR, 2) analyze layout and segment it (Auer et al. 2022; Livathinos et al. 2021; Staar et al. 2018) and 3) extract table structures (Lysak et al. 2023; Nassar et al. 2022). Finally, the data from multiple pages is assembled together, preserving the reading order, in a machine-readable format.\\n\\nLLM &amp; RAG: Due to the increasing scale of training data and model size, large language models (LLMs) demonstrate surprising emergent properties (Wei et al. 2022). For example, the behaviour of the GPT-3 model, with 175 billion parameters, could be modified with in-context learning (Brown et al. 2020; Bommasani et al. 2022; Raffel et al. 2020). Such LLMs are adaptable to a variety of downstream tasks via prompting and can be fine-tuned to better perform in a specific ESG domain (Webersinke et al. 2022). The Retrieval Augmented Generation (RAG) approach aims at improving the performance of these models on knowledge intensive tasks (Lewis et al. 2020). In this approach, the capabilities of natural language generation are combined with a knowledge index, from which relevant documents are retrieved.\\n\\n## System Architecture\\n\\nIn this section, we describe the AI technologies which are integrated into our document question-answering application. The architecture is described in Fig. 1. The pipeline works end-to-end from PDF documents to question-answering using LLMs. It consists of three components described below.\\n\\nDocument Conversion: The document conversion system is designed in an asynchronous task-based queueworker architecture. The user-facing API accepts documents in PDF format (both programmatically created and scanned). The client receives a task identifier, while an orchestrator enqueues several ML tasks to ephemeral workers. After splitting the document into pages, we: 1) depending on the nature of the PDF, we employ either PDF parsing or\\n\\nInformation Retrieval: Using an encoder model, vector embeddings for the data in a document are computed and stored in a vector database. For text this is relatively straightforward, for tables the triplet of (cell content, column header, row header) is expressed as a sentence which gets encoded. The sentence expression is: string(column header) + string(row header) = string(cell content) 1 . We perform a k-nearest neighbour search to identify the top-k relevant passages for a user query. For sentence encoding, we use several encoding models from the Sentence Transformer library (Reimers and Gurevych 2019).\\n\\nResponse Generation: We employ a suite of LLMs like LLAMA 2 (Touvron et al. 2023), Flan-UL2 (Tay et al. 2023), or T5 (Raffel et al. 2020) for generating a response to the user query. The user query and relevant context (identified by the previous model) are packaged together in a prompt for the LLM. The response of the model is checked against hate speech, abuse, and profanity. Finally the response is grounded in the context and inspected for hallucinations. If all tests are passed, the response is presented to the user via a virtual assistant. Table 1 shows some examples of questions and the generated answers by the system.\\n\\n## Conclusions\\n\\nIn this paper, we presented our DocQA application targeting ESG reports. The DocQA system can be useful for anyone, from policy-makers to students, trying to find information from a large document. Our future work is focused on enabling querying on multiple documents at once to extract aggregated insights for questions like 'How have the Scope 1 emissions evolved over the last decade?'. In addition, we will expand this service to other types of documents like scientific papers, financial reports, and patents.\\n\\n1 Here, string() returns the string representation of an object.\\n\\n## References\\n\\nAuer, C.; Dolfi, M.; Carvalho, A.; Ramis, C. B.; and Staar, P. W. J. 2022. Delivering Document Conversion as a Cloud Service with High Throughput and Responsiveness. In 2022 IEEE 15th International Conference on Cloud Computing (CLOUD) . IEEE.\\n\\nAuer, C.; et al. 2023. ICDAR 2023 Competition on Robust Layout Segmentation in Corporate Documents. In Lecture Notes in Computer Science , 471-482. Springer Nature Switzerland.\\n\\nBommasani, R.; et al. 2022. On the Opportunities and Risks of Foundation Models. arXiv:2108.07258.\\n\\nBreuel, T. M. 2002. Two Geometric Algorithms for Layout Analysis. In Lopresti, D.; Hu, J.; and Kashi, R., eds., Document Analysis Systems V , 188-199. Berlin, Heidelberg: Springer Berlin Heidelberg. ISBN 978-3-540-45869-2.\\n\\nBrown, T. B.; et al. 2020. Language Models are Few-Shot Learners. arXiv:2005.14165.\\n\\nCattoni, R.; Coianiz, T.; Messelodi, S.; and Modena, C. 2000. Geometric Layout Analysis Techniques for Document Image Understanding: a Review. Technical Report TR970309, ITC-irst, Via Sommarive 18, I-38050 Povo, Trento, Italy. Goel, T.; Jain, P.; Verma, I.; Dey, L.; and Paliwal, S. 2020. Mining company sustainability reports to aid financial decision-making. In The AAAI-20 Workshop on Knowledge Discovery from Unstructured Data in Financial Services .\\n\\nGuo, T.; et al. 2020. ESG2Risk: A Deep Learning Framework from ESG News to Stock Volatility Prediction. arXiv:2005.02527.\\n\\nHuang, Y.; et al. 2022. LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking. Proceedings of the 30th ACM International Conference on Multimedia .\\n\\nLewis, P.; Perez, E.; Piktus, A.; Petroni, F.; Karpukhin, V.; Goyal, N.; K¨ uttler, H.; Lewis, M.; Yih, W.-t.; Rockt¨ aschel, T.; Riedel, S.; and Kiela, D. 2020. Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. In Advances in Neural Information Processing Systems , volume 33, 9459-9474. Curran Associates, Inc.\\n\\nLi, J.; et al. 2022. DiT: Self-supervised Pre-training for Document Image Transformer. Proceedings of the 30th ACM International Conference on Multimedia .\\n\\nLi, M.; Xu, Y.; Cui, L.; Huang, S.; Wei, F.; Li, Z.; and Zhou, M. 2020. DocBank: A Benchmark Dataset for Document Layout Analysis. In Scott, D.; Bel, N.; and Zong, C., eds., Proceedings of the 28th International Conference on Computational Linguistics , 949-960. Barcelona, Spain (Online): International Committee on Computational Linguistics.\\n\\nLivathinos, N.; Berrospi, C.; Lysak, M.; Kuropiatnyk, V.; Nassar, A.; Carvalho, A.; Dolfi, M.; Auer, C.; Dinkla, K.; and Staar, P. 2021. Robust PDF Document Conversion using Recurrent Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence , 35(17): 15137-15145. Number: 17.\\n\\nLuccioni, S.; Baylor, E.; and Duchene, N. 2020. Analyzing Sustainability Reports Using Natural Language Processing. In NeurIPS 2020 Workshop on Tackling Climate Change with Machine Learning .\\n\\nLysak, M.; Nassar, A.; Livathinos, N.; Auer, C.; and Staar, P. 2023. Optimized Table Tokenization for Table Structure Recognition. In Document Analysis and Recognition - ICDAR 2023: 17th International Conference, San Jos´ e, CA, USA, August 21-26, 2023, Proceedings, Part II , 3750. Berlin, Heidelberg: Springer-Verlag. ISBN 978-3-03141678-1.\\n\\nNassar, A.; Livathinos, N.; Lysak, M.; and Staar, P. 2022. TableFormer: Table Structure Understanding with Transformers. In 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 4604-4613. Los Alamitos, CA, USA: IEEE Computer Society.\\n\\nPfitzmann, B.; et al. 2022. DocLayNet: A Large HumanAnnotated Dataset for Document-Layout Segmentation.\\n\\nRaffel, C.; Shazeer, N.; Roberts, A.; Lee, K.; Narang, S.; Matena, M.; Zhou, Y.; Li, W.; and Liu, P. J. 2020. Exploring the Limits of Transfer Learning with a Unified Text-toText Transformer. Journal of Machine Learning Research , 21(140): 1-67.\\n\\nReimers, N.; and Gurevych, I. 2019. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In Inui, K.; Jiang, J.; Ng, V.; and Wan, X., eds., Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) , 3982-3992. Hong Kong, China: Association for Computational Linguistics.\\n\\nStaar, P. W. J.; et al. 2018. Corpus Conversion Service. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining . ACM.\\n\\nTay, Y.; Dehghani, M.; Tran, V. Q.; Garcia, X.; Wei, J.; Wang, X.; Chung, H. W.; Bahri, D.; Schuster, T.; Zheng, S.; Zhou, D.; Houlsby, N.; and Metzler, D. 2023. UL2: Unifying Language Learning Paradigms. In The Eleventh International Conference on Learning Representations .\\n\\nTouvron, H.; et al. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models. arXiv:2307.09288.\\n\\nWebersinke, N.; Kraus, M.; Bingler, J.; and Leippold, M. 2022. ClimateBERT: A Pretrained Language Model for Climate-Related Text. In Proceedings of AAAI 2022 Fall Symposium: The Role of AI in Responding to Climate Challenges .\\n\\nWei, J.; Tay, Y.; Bommasani, R.; Raffel, C.; Zoph, B.; Borgeaud, S.; Yogatama, D.; Bosma, M.; Zhou, D.; Metzler, D.; Chi, E. H.; Hashimoto, T.; Vinyals, O.; Liang, P.; Dean, J.; and Fedus, W. 2022. Emergent Abilities of Large Language Models. Transactions on Machine Learning Research . Survey Certification.\\n\\nZhang, M.; et al. 2023. WeLayout: WeChat Layout Analysis System for the ICDAR 2023 Competition on Robust Layout Segmentation in Corporate Documents. ArXiv , abs/2305.06553.\\n\\nZhong, X.; et al. 2019. PubLayNet: Largest Dataset Ever for Document Layout Analysis. In 2019 International Conference on Document Analysis and Recognition (ICDAR) , 1015-1022.\")\n",
      "('spans', [Span(item=SectionHeaderItem(self_ref='#/texts/1', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=133.331, t=693.015, r=478.673, b=680.118, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 51))], orig='ESG Accountability Made Easy: DocQA at Your Service', text='ESG Accountability Made Easy: DocQA at Your Service', formatting=None, hyperlink=None, level=1)), Span(item=TextItem(self_ref='#/texts/2', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.657, t=671.495, r=557.344, b=631.573, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 264))], orig='Lokesh Mishra 1 , Cesar Berrospi 1 , Kasper Dinkla 1 , Diego Antognini 1 , Francesco Fusco 1 , Benedikt Bothur 2 , Maksym Lysak 1 , Nikolaos Livathinos 1 , Ahmed Nassar 1 , Panagiotis Vagenas 1 , Lucas Morin 1,3 , Christoph Auer 1 , Michele Dolfi 1 , Peter Staar 1', text='Lokesh Mishra 1 , Cesar Berrospi 1 , Kasper Dinkla 1 , Diego Antognini 1 , Francesco Fusco 1 , Benedikt Bothur 2 , Maksym Lysak 1 , Nikolaos Livathinos 1 , Ahmed Nassar 1 , Panagiotis Vagenas 1 , Lucas Morin 1,3 , Christoph Auer 1 , Michele Dolfi 1 , Peter Staar 1', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/3', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=223.675, t=629.276, r=388.327, b=619.055, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 41))], orig='1 IBM Research, R¨ uschlikon, Switzerland', text='1 IBM Research, R¨ uschlikon, Switzerland', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/4', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=157.817, t=616.966, r=454.184, b=608.096, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 78))], orig='{ mis, ceb, dkl, ffu, mly, nli, ahn, pva, lum, cau, dol, taa } @zurich.ibm.com', text='{ mis, ceb, dkl, ffu, mly, nli, ahn, pva, lum, cau, dol, taa } @zurich.ibm.com', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/5', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=228.173, t=607.358, r=383.828, b=597.137, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 39))], orig='2 IBM Technology, Z¨ urich, Switzerland', text='2 IBM Technology, Z¨ urich, Switzerland', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/6', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=209.946, t=595.048, r=402.055, b=586.178, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 45))], orig='{ Benedikt.Bothur, Diego.Antognini } @ibm.com', text='{ Benedikt.Bothur, Diego.Antognini } @ibm.com', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/7', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=237.742, t=585.44, r=374.259, b=575.219, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 37))], orig='3 ETH Z¨ urich, Z¨ urich, Switzerland', text='3 ETH Z¨ urich, Z¨ urich, Switzerland', formatting=None, hyperlink=None)), Span(item=SectionHeaderItem(self_ref='#/texts/8', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=154.715, t=567.81, r=191.786, b=558.854, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 8))], orig='Abstract', text='Abstract', formatting=None, hyperlink=None, level=1)), Span(item=TextItem(self_ref='#/texts/9', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=63.963, t=549.565, r=282.537, b=442.241, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 614))], orig='We present Deep Search DocQA. This application enables information extraction from documents via a questionanswering conversational assistant. The system integrates several technologies from different AI disciplines consisting of document conversion to machine-readable format (via computer vision), finding relevant data (via natural language processing), and formulating an eloquent response (via large language models). Users can explore over 10,000 Environmental, Social, and Governance (ESG) disclosure reports from over 2000 corporations. The Deep Search platform can be accessed at: https://ds4sd.github.io.', text='We present Deep Search DocQA. This application enables information extraction from documents via a questionanswering conversational assistant. The system integrates several technologies from different AI disciplines consisting of document conversion to machine-readable format (via computer vision), finding relevant data (via natural language processing), and formulating an eloquent response (via large language models). Users can explore over 10,000 Environmental, Social, and Governance (ESG) disclosure reports from over 2000 corporations. The Deep Search platform can be accessed at: https://ds4sd.github.io.', formatting=None, hyperlink=None)), Span(item=SectionHeaderItem(self_ref='#/texts/10', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=140.81, t=424.412, r=205.691, b=413.664, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 12))], orig='Introduction', text='Introduction', formatting=None, hyperlink=None, level=1)), Span(item=TextItem(self_ref='#/texts/11', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=408.673, r=292.505, b=279.573, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 664))], orig='The global impact of climate change has galvanized organizations to announce key information about their environmental footprint (carbon emissions, energy usage, waste emission and management, etc.). Integrating sustainability information into the company reporting cycle is one of the targets of the UN 2030 Agenda for Sustainable Development and institutions like Principles for Responsible Investing (a UN-supported network of investors) encourage investors to incorporate this information into their investment decisions . Companies are thus increasingly disclosing environmental, social, and governance (ESG) data in their ESG reports, typically as PDF files.', text='The global impact of climate change has galvanized organizations to announce key information about their environmental footprint (carbon emissions, energy usage, waste emission and management, etc.). Integrating sustainability information into the company reporting cycle is one of the targets of the UN 2030 Agenda for Sustainable Development and institutions like Principles for Responsible Investing (a UN-supported network of investors) encourage investors to incorporate this information into their investment decisions . Companies are thus increasingly disclosing environmental, social, and governance (ESG) data in their ESG reports, typically as PDF files.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/12', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=277.1569999999999, r=292.505, b=148.05700000000002, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 683))], orig='Unlike financial data, regulators such as the U.S. SEC do not require public companies to file ESG data with specific forms. There have been massive efforts from several organizations to standardize these reports. However, major challenges continue to persist, including complex regulations, rapidly evolving reporting frameworks, verifying ESG compliance, among others. These matters become more complicated when we realize that most of the ESG reporting is done in non machine-readable formats. Unlocking this vast amount of data in an easily consumable manner would greatly help researchers, policy-makers, lawyers, and corporations by extracting information and gaining insights.', text='Unlike financial data, regulators such as the U.S. SEC do not require public companies to file ESG data with specific forms. There have been massive efforts from several organizations to standardize these reports. However, major challenges continue to persist, including complex regulations, rapidly evolving reporting frameworks, verifying ESG compliance, among others. These matters become more complicated when we realize that most of the ESG reporting is done in non machine-readable formats. Unlocking this vast amount of data in an easily consumable manner would greatly help researchers, policy-makers, lawyers, and corporations by extracting information and gaining insights.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/13', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=145.64099999999996, r=292.505, b=115.17100000000005, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 168))], orig='To this end, we have developed Deep Search DocQA. The application offers users to perform document question answering (QA), i.e., users can extract information from any', text='To this end, we have developed Deep Search DocQA. The application offers users to perform document question answering (QA), i.e., users can extract information from any', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/14', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=105.79999999999995, r=292.497, b=88.13999999999999, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 113))], orig='Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.', text='Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.', formatting=None, hyperlink=None)), Span(item=TableItem(self_ref='#/tables/0', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TABLE: 'table'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=318.4297790527344, t=571.1541595458984, r=559.6930541992188, b=375.6693115234375, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 0))], captions=[], references=[], footnotes=[], image=None, data=TableData(table_cells=[TableCell(bbox=BoundingBox(l=325.478, t=226.84799999999996, r=346.392, b=233.11800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=0, end_col_offset_idx=1, text='Report', column_header=True, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=226.84799999999996, r=389.682, b=233.11800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=1, end_col_offset_idx=2, text='Question', column_header=True, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=226.84799999999996, r=491.296, b=233.11800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=2, end_col_offset_idx=3, text='Answer', column_header=True, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=325.478, t=242.08500000000004, r=338.652, b=248.07100000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=0, end_col_offset_idx=1, text='IBM 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=242.08500000000004, r=376.327, b=248.07100000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=1, end_col_offset_idx=2, text='How many hours were spent on employee learning in 2021?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=242.08500000000004, r=480.647, b=248.07100000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=2, end_col_offset_idx=3, text='22.5 million hours', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=325.478, t=267.01199999999994, r=338.652, b=272.99800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=0, end_col_offset_idx=1, text='IBM 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=267.01199999999994, r=378.049, b=272.99800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=1, end_col_offset_idx=2, text='What was the rate of fatalities in 2021?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=267.01199999999994, r=479.287, b=272.99800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=2, end_col_offset_idx=3, text='The rate of fatalities in 2021 was 0.0016.', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=325.478, t=291.939, r=338.652, b=297.925, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=0, end_col_offset_idx=1, text='IBM 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=291.939, r=376.327, b=297.925, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=1, end_col_offset_idx=2, text='How many full audits were con- ducted in 2022 in India?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=291.939, r=471.93, b=297.925, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=2, end_col_offset_idx=3, text='2', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=325.478, t=316.867, r=352.843, b=322.853, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=0, end_col_offset_idx=1, text='Starbucks 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=316.867, r=378.049, b=322.853, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=1, end_col_offset_idx=2, text='What is the percentage of women in the Board of Directors?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=316.867, r=481.226, b=322.853, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=2, end_col_offset_idx=3, text='25%', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=325.478, t=341.794, r=352.843, b=347.78, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=5, end_row_offset_idx=6, start_col_offset_idx=0, end_col_offset_idx=1, text='Starbucks 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=341.794, r=378.049, b=347.78, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=5, end_row_offset_idx=6, start_col_offset_idx=1, end_col_offset_idx=2, text='What was the total energy con- sumption in 2021?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=341.794, r=497.879, b=347.78, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=5, end_row_offset_idx=6, start_col_offset_idx=2, end_col_offset_idx=3, text='According to the table, the total energy consumption in 2021 was 2,491,543 MWh.', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=325.478, t=376.684, r=352.843, b=382.67, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=6, end_row_offset_idx=7, start_col_offset_idx=0, end_col_offset_idx=1, text='Starbucks 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=376.684, r=376.327, b=382.67, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=6, end_row_offset_idx=7, start_col_offset_idx=1, end_col_offset_idx=2, text='How much packaging material was made from renewable mate- rials?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=376.684, r=497.879, b=382.67, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=6, end_row_offset_idx=7, start_col_offset_idx=2, end_col_offset_idx=3, text='According to the given data, 31% of packaging materials were made from recycled or renewable materials in FY22.', column_header=False, row_header=False, row_section=False)], num_rows=7, num_cols=3, grid=[[TableCell(bbox=BoundingBox(l=325.478, t=226.84799999999996, r=346.392, b=233.11800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=0, end_col_offset_idx=1, text='Report', column_header=True, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=226.84799999999996, r=389.682, b=233.11800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=1, end_col_offset_idx=2, text='Question', column_header=True, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=226.84799999999996, r=491.296, b=233.11800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=2, end_col_offset_idx=3, text='Answer', column_header=True, row_header=False, row_section=False)], [TableCell(bbox=BoundingBox(l=325.478, t=242.08500000000004, r=338.652, b=248.07100000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=0, end_col_offset_idx=1, text='IBM 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=242.08500000000004, r=376.327, b=248.07100000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=1, end_col_offset_idx=2, text='How many hours were spent on employee learning in 2021?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=242.08500000000004, r=480.647, b=248.07100000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=2, end_col_offset_idx=3, text='22.5 million hours', column_header=False, row_header=False, row_section=False)], [TableCell(bbox=BoundingBox(l=325.478, t=267.01199999999994, r=338.652, b=272.99800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=0, end_col_offset_idx=1, text='IBM 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=267.01199999999994, r=378.049, b=272.99800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=1, end_col_offset_idx=2, text='What was the rate of fatalities in 2021?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=267.01199999999994, r=479.287, b=272.99800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=2, end_col_offset_idx=3, text='The rate of fatalities in 2021 was 0.0016.', column_header=False, row_header=False, row_section=False)], [TableCell(bbox=BoundingBox(l=325.478, t=291.939, r=338.652, b=297.925, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=0, end_col_offset_idx=1, text='IBM 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=291.939, r=376.327, b=297.925, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=1, end_col_offset_idx=2, text='How many full audits were con- ducted in 2022 in India?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=291.939, r=471.93, b=297.925, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=2, end_col_offset_idx=3, text='2', column_header=False, row_header=False, row_section=False)], [TableCell(bbox=BoundingBox(l=325.478, t=316.867, r=352.843, b=322.853, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=0, end_col_offset_idx=1, text='Starbucks 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=316.867, r=378.049, b=322.853, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=1, end_col_offset_idx=2, text='What is the percentage of women in the Board of Directors?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=316.867, r=481.226, b=322.853, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=2, end_col_offset_idx=3, text='25%', column_header=False, row_header=False, row_section=False)], [TableCell(bbox=BoundingBox(l=325.478, t=341.794, r=352.843, b=347.78, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=5, end_row_offset_idx=6, start_col_offset_idx=0, end_col_offset_idx=1, text='Starbucks 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=341.794, r=378.049, b=347.78, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=5, end_row_offset_idx=6, start_col_offset_idx=1, end_col_offset_idx=2, text='What was the total energy con- sumption in 2021?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=341.794, r=497.879, b=347.78, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=5, end_row_offset_idx=6, start_col_offset_idx=2, end_col_offset_idx=3, text='According to the table, the total energy consumption in 2021 was 2,491,543 MWh.', column_header=False, row_header=False, row_section=False)], [TableCell(bbox=BoundingBox(l=325.478, t=376.684, r=352.843, b=382.67, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=6, end_row_offset_idx=7, start_col_offset_idx=0, end_col_offset_idx=1, text='Starbucks 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=376.684, r=376.327, b=382.67, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=6, end_row_offset_idx=7, start_col_offset_idx=1, end_col_offset_idx=2, text='How much packaging material was made from renewable mate- rials?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=376.684, r=497.879, b=382.67, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=6, end_row_offset_idx=7, start_col_offset_idx=2, end_col_offset_idx=3, text='According to the given data, 31% of packaging materials were made from recycled or renewable materials in FY22.', column_header=False, row_header=False, row_section=False)]]), annotations=[])), Span(item=TextItem(self_ref='#/texts/15', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=319.5, t=364.239, r=558.005, b=344.728, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 107))], orig='Table 1: Example question answers from the ESG reports of IBM and Starbucks using Deep Search DocQA system.', text='Table 1: Example question answers from the ESG reports of IBM and Starbucks using Deep Search DocQA system.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/16', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=319.5, t=320.006, r=558.005, b=278.577, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 211))], orig='ESG report in our library via our QA conversational assistant. Our assistant generates answers and also presents the information (paragraph or table), in the ESG report, from which it has generated the response.', text='ESG report in our library via our QA conversational assistant. Our assistant generates answers and also presents the information (paragraph or table), in the ESG report, from which it has generated the response.', formatting=None, hyperlink=None)), Span(item=SectionHeaderItem(self_ref='#/texts/17', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=403.172, t=265.818, r=474.329, b=255.06999999999994, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 12))], orig='Related Work', text='Related Work', formatting=None, hyperlink=None, level=1)), Span(item=TextItem(self_ref='#/texts/18', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=319.5, t=249.96000000000004, r=548.182, b=241.40800000000002, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 54))], orig='The DocQA integrates multiple AI technologies, namely:', text='The DocQA integrates multiple AI technologies, namely:', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/19', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=319.5, t=239.34000000000003, r=558.005, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 792))], orig='Document Conversion: Converting unstructured documents, such as PDF files, into a machine-readable format is a challenging task in AI. Early strategies for document conversion were based on geometric layout analysis (Cattoni et al. 2000; Breuel 2002). Thanks to the availability of large annotated datasets (PubLayNet (Zhong et al. 2019), DocBank (Li et al. 2020), DocLayNet (Pfitzmann et al. 2022; Auer et al. 2023), deep learning-based methods are routinely used. Modern approaches for recovering the structure of a document can be broadly divided into two categories: image-based or PDF representation-based . Imagebased methods usually employ Transformer or CNN architectures on the images of pages (Zhang et al. 2023; Li et al. 2022; Huang et al. 2022). On the other hand, deep learning-', text='Document Conversion: Converting unstructured documents, such as PDF files, into a machine-readable format is a challenging task in AI. Early strategies for document conversion were based on geometric layout analysis (Cattoni et al. 2000; Breuel 2002). Thanks to the availability of large annotated datasets (PubLayNet (Zhong et al. 2019), DocBank (Li et al. 2020), DocLayNet (Pfitzmann et al. 2022; Auer et al. 2023), deep learning-based methods are routinely used. Modern approaches for recovering the structure of a document can be broadly divided into two categories: image-based or PDF representation-based . Imagebased methods usually employ Transformer or CNN architectures on the images of pages (Zhang et al. 2023; Li et al. 2022; Huang et al. 2022). On the other hand, deep learning-', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/20', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.CAPTION: 'caption'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=124.802, t=610.166, r=487.202, b=601.614, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 89))], orig='Figure 1: System architecture: Simplified sketch of document question-answering pipeline.', text='Figure 1: System architecture: Simplified sketch of document question-answering pipeline.', formatting=None, hyperlink=None)), Span(item=PictureItem(self_ref='#/pictures/0', parent=RefItem(cref='#/body'), children=[RefItem(cref='#/texts/20'), RefItem(cref='#/texts/21'), RefItem(cref='#/texts/22'), RefItem(cref='#/texts/23'), RefItem(cref='#/texts/24'), RefItem(cref='#/texts/25'), RefItem(cref='#/texts/26'), RefItem(cref='#/texts/27'), RefItem(cref='#/texts/28'), RefItem(cref='#/texts/29'), RefItem(cref='#/texts/30'), RefItem(cref='#/texts/31'), RefItem(cref='#/texts/32'), RefItem(cref='#/texts/33'), RefItem(cref='#/texts/34'), RefItem(cref='#/texts/35'), RefItem(cref='#/texts/36'), RefItem(cref='#/texts/37'), RefItem(cref='#/texts/38'), RefItem(cref='#/texts/39'), RefItem(cref='#/texts/40'), RefItem(cref='#/texts/41'), RefItem(cref='#/texts/42'), RefItem(cref='#/texts/43')], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.PICTURE: 'picture'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=77.60360717773438, t=737.9423828125, r=534.0112915039062, b=620.3168182373047, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 0))], captions=[RefItem(cref='#/texts/20')], references=[], footnotes=[], image=None, annotations=[])), Span(item=TextItem(self_ref='#/texts/44', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=54.0, t=576.99, r=292.505, b=546.52, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 179))], orig='based language processing methods are applied on the native PDF content (generated by a single PDF printing command) (Auer et al. 2022; Livathinos et al. 2021; Staar et al. 2018).', text='based language processing methods are applied on the native PDF content (generated by a single PDF printing command) (Auer et al. 2022; Livathinos et al. 2021; Staar et al. 2018).', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/45', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=54.0, t=543.93, r=292.505, b=425.401, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 610))], orig='Application of NLP to ESG: ESG reports contain large amount of useful data in textual and tabular format. There have been some attempts to use NLP on this data. Luccioni, Baylor, and Duchene (2020) developed ClimateQA, a model trained to classify whether a sentence from an ESG report answers regulatory questions. In addition, there are several works which aim to mine information from ESG reports for financial predictions (Guo et al. 2020; Goel et al. 2020). Nevertheless, to the best of our knowledge, no QA system which can extract data directly from an ESG report PDF has been reported in the literature.', text='Application of NLP to ESG: ESG reports contain large amount of useful data in textual and tabular format. There have been some attempts to use NLP on this data. Luccioni, Baylor, and Duchene (2020) developed ClimateQA, a model trained to classify whether a sentence from an ESG report answers regulatory questions. In addition, there are several works which aim to mine information from ESG reports for financial predictions (Guo et al. 2020; Goel et al. 2020). Nevertheless, to the best of our knowledge, no QA system which can extract data directly from an ESG report PDF has been reported in the literature.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/46', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=319.5, t=576.99, r=558.005, b=524.603, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 293))], orig='OCR, 2) analyze layout and segment it (Auer et al. 2022; Livathinos et al. 2021; Staar et al. 2018) and 3) extract table structures (Lysak et al. 2023; Nassar et al. 2022). Finally, the data from multiple pages is assembled together, preserving the reading order, in a machine-readable format.', text='OCR, 2) analyze layout and segment it (Auer et al. 2022; Livathinos et al. 2021; Staar et al. 2018) and 3) extract table structures (Lysak et al. 2023; Nassar et al. 2022). Finally, the data from multiple pages is assembled together, preserving the reading order, in a machine-readable format.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/47', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=54.0, t=422.81, r=292.505, b=260.446, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 805))], orig='LLM & RAG: Due to the increasing scale of training data and model size, large language models (LLMs) demonstrate surprising emergent properties (Wei et al. 2022). For example, the behaviour of the GPT-3 model, with 175 billion parameters, could be modified with in-context learning (Brown et al. 2020; Bommasani et al. 2022; Raffel et al. 2020). Such LLMs are adaptable to a variety of downstream tasks via prompting and can be fine-tuned to better perform in a specific ESG domain (Webersinke et al. 2022). The Retrieval Augmented Generation (RAG) approach aims at improving the performance of these models on knowledge intensive tasks (Lewis et al. 2020). In this approach, the capabilities of natural language generation are combined with a knowledge index, from which relevant documents are retrieved.', text='LLM & RAG: Due to the increasing scale of training data and model size, large language models (LLMs) demonstrate surprising emergent properties (Wei et al. 2022). For example, the behaviour of the GPT-3 model, with 175 billion parameters, could be modified with in-context learning (Brown et al. 2020; Bommasani et al. 2022; Raffel et al. 2020). Such LLMs are adaptable to a variety of downstream tasks via prompting and can be fine-tuned to better perform in a specific ESG domain (Webersinke et al. 2022). The Retrieval Augmented Generation (RAG) approach aims at improving the performance of these models on knowledge intensive tasks (Lewis et al. 2020). In this approach, the capabilities of natural language generation are combined with a knowledge index, from which relevant documents are retrieved.', formatting=None, hyperlink=None)), Span(item=SectionHeaderItem(self_ref='#/texts/48', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=121.18, t=245.99, r=225.322, b=235.24199999999996, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 19))], orig='System Architecture', text='System Architecture', formatting=None, hyperlink=None, level=1)), Span(item=TextItem(self_ref='#/texts/49', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=54.0, t=228.56399999999996, r=292.505, b=176.17700000000002, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 292))], orig='In this section, we describe the AI technologies which are integrated into our document question-answering application. The architecture is described in Fig. 1. The pipeline works end-to-end from PDF documents to question-answering using LLMs. It consists of three components described below.', text='In this section, we describe the AI technologies which are integrated into our document question-answering application. The architecture is described in Fig. 1. The pipeline works end-to-end from PDF documents to question-answering using LLMs. It consists of three components described below.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/50', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=54.0, t=173.586, r=292.505, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 441))], orig='Document Conversion: The document conversion system is designed in an asynchronous task-based queueworker architecture. The user-facing API accepts documents in PDF format (both programmatically created and scanned). The client receives a task identifier, while an orchestrator enqueues several ML tasks to ephemeral workers. After splitting the document into pages, we: 1) depending on the nature of the PDF, we employ either PDF parsing or', text='Document Conversion: The document conversion system is designed in an asynchronous task-based queueworker architecture. The user-facing API accepts documents in PDF format (both programmatically created and scanned). The client receives a task identifier, while an orchestrator enqueues several ML tasks to ephemeral workers. After splitting the document into pages, we: 1) depending on the nature of the PDF, we employ either PDF parsing or', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/51', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=319.5, t=519.231, r=558.005, b=389.743, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 614))], orig='Information Retrieval: Using an encoder model, vector embeddings for the data in a document are computed and stored in a vector database. For text this is relatively straightforward, for tables the triplet of (cell content, column header, row header) is expressed as a sentence which gets encoded. The sentence expression is: string(column header) + string(row header) = string(cell content) 1 . We perform a k-nearest neighbour search to identify the top-k relevant passages for a user query. For sentence encoding, we use several encoding models from the Sentence Transformer library (Reimers and Gurevych 2019).', text='Information Retrieval: Using an encoder model, vector embeddings for the data in a document are computed and stored in a vector database. For text this is relatively straightforward, for tables the triplet of (cell content, column header, row header) is expressed as a sentence which gets encoded. The sentence expression is: string(column header) + string(row header) = string(cell content) 1 . We perform a k-nearest neighbour search to identify the top-k relevant passages for a user query. For sentence encoding, we use several encoding models from the Sentence Transformer library (Reimers and Gurevych 2019).', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/52', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=319.5, t=384.371, r=558.005, b=265.842, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 632))], orig='Response Generation: We employ a suite of LLMs like LLAMA 2 (Touvron et al. 2023), Flan-UL2 (Tay et al. 2023), or T5 (Raffel et al. 2020) for generating a response to the user query. The user query and relevant context (identified by the previous model) are packaged together in a prompt for the LLM. The response of the model is checked against hate speech, abuse, and profanity. Finally the response is grounded in the context and inspected for hallucinations. If all tests are passed, the response is presented to the user via a virtual assistant. Table 1 shows some examples of questions and the generated answers by the system.', text='Response Generation: We employ a suite of LLMs like LLAMA 2 (Touvron et al. 2023), Flan-UL2 (Tay et al. 2023), or T5 (Raffel et al. 2020) for generating a response to the user query. The user query and relevant context (identified by the previous model) are packaged together in a prompt for the LLM. The response of the model is checked against hate speech, abuse, and profanity. Finally the response is grounded in the context and inspected for hallucinations. If all tests are passed, the response is presented to the user via a virtual assistant. Table 1 shows some examples of questions and the generated answers by the system.', formatting=None, hyperlink=None)), Span(item=SectionHeaderItem(self_ref='#/texts/53', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=407.858, t=242.34699999999998, r=469.642, b=231.59899999999993, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 11))], orig='Conclusions', text='Conclusions', formatting=None, hyperlink=None, level=1)), Span(item=TextItem(self_ref='#/texts/54', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=319.5, t=216.577, r=558.005, b=120.35400000000004, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 514))], orig=\"In this paper, we presented our DocQA application targeting ESG reports. The DocQA system can be useful for anyone, from policy-makers to students, trying to find information from a large document. Our future work is focused on enabling querying on multiple documents at once to extract aggregated insights for questions like 'How have the Scope 1 emissions evolved over the last decade?'. In addition, we will expand this service to other types of documents like scientific papers, financial reports, and patents.\", text=\"In this paper, we presented our DocQA application targeting ESG reports. The DocQA system can be useful for anyone, from policy-makers to students, trying to find information from a large document. Our future work is focused on enabling querying on multiple documents at once to extract aggregated insights for questions like 'How have the Scope 1 emissions evolved over the last decade?'. In addition, we will expand this service to other types of documents like scientific papers, financial reports, and patents.\", formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/55', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.FOOTNOTE: 'footnote'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=332.153, t=97.70000000000005, r=546.799, b=88.13999999999999, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 64))], orig='1 Here, string() returns the string representation of an object.', text='1 Here, string() returns the string representation of an object.', formatting=None, hyperlink=None)), Span(item=SectionHeaderItem(self_ref='#/texts/56', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=145.478, t=736.286, r=201.022, b=725.538, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 10))], orig='References', text='References', formatting=None, hyperlink=None, level=1)), Span(item=TextItem(self_ref='#/texts/57', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=721.363, r=292.505, b=668.976, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 243))], orig='Auer, C.; Dolfi, M.; Carvalho, A.; Ramis, C. B.; and Staar, P. W. J. 2022. Delivering Document Conversion as a Cloud Service with High Throughput and Responsiveness. In 2022 IEEE 15th International Conference on Cloud Computing (CLOUD) . IEEE.', text='Auer, C.; Dolfi, M.; Carvalho, A.; Ramis, C. B.; and Staar, P. W. J. 2022. Delivering Document Conversion as a Cloud Service with High Throughput and Responsiveness. In 2022 IEEE 15th International Conference on Cloud Computing (CLOUD) . IEEE.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/58', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=664.866, r=292.505, b=623.437, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 176))], orig='Auer, C.; et al. 2023. ICDAR 2023 Competition on Robust Layout Segmentation in Corporate Documents. In Lecture Notes in Computer Science , 471-482. Springer Nature Switzerland.', text='Auer, C.; et al. 2023. ICDAR 2023 Competition on Robust Layout Segmentation in Corporate Documents. In Lecture Notes in Computer Science , 471-482. Springer Nature Switzerland.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/59', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=619.327, r=292.505, b=599.817, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 98))], orig='Bommasani, R.; et al. 2022. On the Opportunities and Risks of Foundation Models. arXiv:2108.07258.', text='Bommasani, R.; et al. 2022. On the Opportunities and Risks of Foundation Models. arXiv:2108.07258.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/60', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=595.707, r=292.505, b=554.278, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 222))], orig='Breuel, T. M. 2002. Two Geometric Algorithms for Layout Analysis. In Lopresti, D.; Hu, J.; and Kashi, R., eds., Document Analysis Systems V , 188-199. Berlin, Heidelberg: Springer Berlin Heidelberg. ISBN 978-3-540-45869-2.', text='Breuel, T. M. 2002. Two Geometric Algorithms for Layout Analysis. In Lopresti, D.; Hu, J.; and Kashi, R., eds., Document Analysis Systems V , 188-199. Berlin, Heidelberg: Springer Berlin Heidelberg. ISBN 978-3-540-45869-2.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/61', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=550.168, r=292.505, b=530.657, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 83))], orig='Brown, T. B.; et al. 2020. Language Models are Few-Shot Learners. arXiv:2005.14165.', text='Brown, T. B.; et al. 2020. Language Models are Few-Shot Learners. arXiv:2005.14165.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/62', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=526.548, r=292.505, b=439.58, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 454))], orig='Cattoni, R.; Coianiz, T.; Messelodi, S.; and Modena, C. 2000. Geometric Layout Analysis Techniques for Document Image Understanding: a Review. Technical Report TR970309, ITC-irst, Via Sommarive 18, I-38050 Povo, Trento, Italy. Goel, T.; Jain, P.; Verma, I.; Dey, L.; and Paliwal, S. 2020. Mining company sustainability reports to aid financial decision-making. In The AAAI-20 Workshop on Knowledge Discovery from Unstructured Data in Financial Services .', text='Cattoni, R.; Coianiz, T.; Messelodi, S.; and Modena, C. 2000. Geometric Layout Analysis Techniques for Document Image Understanding: a Review. Technical Report TR970309, ITC-irst, Via Sommarive 18, I-38050 Povo, Trento, Italy. Goel, T.; Jain, P.; Verma, I.; Dey, L.; and Paliwal, S. 2020. Mining company sustainability reports to aid financial decision-making. In The AAAI-20 Workshop on Knowledge Discovery from Unstructured Data in Financial Services .', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/63', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=435.471, r=292.505, b=405.001, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 121))], orig='Guo, T.; et al. 2020. ESG2Risk: A Deep Learning Framework from ESG News to Stock Volatility Prediction. arXiv:2005.02527.', text='Guo, T.; et al. 2020. ESG2Risk: A Deep Learning Framework from ESG News to Stock Volatility Prediction. arXiv:2005.02527.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/64', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=400.891, r=292.505, b=370.421, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 170))], orig='Huang, Y.; et al. 2022. LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking. Proceedings of the 30th ACM International Conference on Multimedia .', text='Huang, Y.; et al. 2022. LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking. Proceedings of the 30th ACM International Conference on Multimedia .', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/65', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=366.311, r=292.505, b=302.965, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 328))], orig='Lewis, P.; Perez, E.; Piktus, A.; Petroni, F.; Karpukhin, V.; Goyal, N.; K¨ uttler, H.; Lewis, M.; Yih, W.-t.; Rockt¨ aschel, T.; Riedel, S.; and Kiela, D. 2020. Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. In Advances in Neural Information Processing Systems , volume 33, 9459-9474. Curran Associates, Inc.', text='Lewis, P.; Perez, E.; Piktus, A.; Petroni, F.; Karpukhin, V.; Goyal, N.; K¨ uttler, H.; Lewis, M.; Yih, W.-t.; Rockt¨ aschel, T.; Riedel, S.; and Kiela, D. 2020. Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. In Advances in Neural Information Processing Systems , volume 33, 9459-9474. Curran Associates, Inc.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/66', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=298.855, r=292.505, b=268.385, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 155))], orig='Li, J.; et al. 2022. DiT: Self-supervised Pre-training for Document Image Transformer. Proceedings of the 30th ACM International Conference on Multimedia .', text='Li, J.; et al. 2022. DiT: Self-supervised Pre-training for Document Image Transformer. Proceedings of the 30th ACM International Conference on Multimedia .', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/67', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=264.275, r=292.505, b=200.92899999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 343))], orig='Li, M.; Xu, Y.; Cui, L.; Huang, S.; Wei, F.; Li, Z.; and Zhou, M. 2020. DocBank: A Benchmark Dataset for Document Layout Analysis. In Scott, D.; Bel, N.; and Zong, C., eds., Proceedings of the 28th International Conference on Computational Linguistics , 949-960. Barcelona, Spain (Online): International Committee on Computational Linguistics.', text='Li, M.; Xu, Y.; Cui, L.; Huang, S.; Wei, F.; Li, Z.; and Zhou, M. 2020. DocBank: A Benchmark Dataset for Document Layout Analysis. In Scott, D.; Bel, N.; and Zong, C., eds., Proceedings of the 28th International Conference on Computational Linguistics , 949-960. Barcelona, Spain (Online): International Committee on Computational Linguistics.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/68', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=196.81899999999996, r=292.505, b=133.47299999999996, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 297))], orig='Livathinos, N.; Berrospi, C.; Lysak, M.; Kuropiatnyk, V.; Nassar, A.; Carvalho, A.; Dolfi, M.; Auer, C.; Dinkla, K.; and Staar, P. 2021. Robust PDF Document Conversion using Recurrent Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence , 35(17): 15137-15145. Number: 17.', text='Livathinos, N.; Berrospi, C.; Lysak, M.; Kuropiatnyk, V.; Nassar, A.; Carvalho, A.; Dolfi, M.; Auer, C.; Dinkla, K.; and Staar, P. 2021. Robust PDF Document Conversion using Recurrent Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence , 35(17): 15137-15145. Number: 17.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/69', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=129.36300000000006, r=292.505, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 191))], orig='Luccioni, S.; Baylor, E.; and Duchene, N. 2020. Analyzing Sustainability Reports Using Natural Language Processing. In NeurIPS 2020 Workshop on Tackling Climate Change with Machine Learning .', text='Luccioni, S.; Baylor, E.; and Duchene, N. 2020. Analyzing Sustainability Reports Using Natural Language Processing. In NeurIPS 2020 Workshop on Tackling Climate Change with Machine Learning .', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/70', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=734.523, r=558.005, b=660.218, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 342))], orig='Lysak, M.; Nassar, A.; Livathinos, N.; Auer, C.; and Staar, P. 2023. Optimized Table Tokenization for Table Structure Recognition. In Document Analysis and Recognition - ICDAR 2023: 17th International Conference, San Jos´ e, CA, USA, August 21-26, 2023, Proceedings, Part II , 3750. Berlin, Heidelberg: Springer-Verlag. ISBN 978-3-03141678-1.', text='Lysak, M.; Nassar, A.; Livathinos, N.; Auer, C.; and Staar, P. 2023. Optimized Table Tokenization for Table Structure Recognition. In Document Analysis and Recognition - ICDAR 2023: 17th International Conference, San Jos´ e, CA, USA, August 21-26, 2023, Proceedings, Part II , 3750. Berlin, Heidelberg: Springer-Verlag. ISBN 978-3-03141678-1.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/71', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=655.32, r=558.005, b=602.933, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 257))], orig='Nassar, A.; Livathinos, N.; Lysak, M.; and Staar, P. 2022. TableFormer: Table Structure Understanding with Transformers. In 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 4604-4613. Los Alamitos, CA, USA: IEEE Computer Society.', text='Nassar, A.; Livathinos, N.; Lysak, M.; and Staar, P. 2022. TableFormer: Table Structure Understanding with Transformers. In 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 4604-4613. Los Alamitos, CA, USA: IEEE Computer Society.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/72', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=598.035, r=558.005, b=578.524, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 103))], orig='Pfitzmann, B.; et al. 2022. DocLayNet: A Large HumanAnnotated Dataset for Document-Layout Segmentation.', text='Pfitzmann, B.; et al. 2022. DocLayNet: A Large HumanAnnotated Dataset for Document-Layout Segmentation.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/73', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=573.627, r=558.005, b=521.239, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 245))], orig='Raffel, C.; Shazeer, N.; Roberts, A.; Lee, K.; Narang, S.; Matena, M.; Zhou, Y.; Li, W.; and Liu, P. J. 2020. Exploring the Limits of Transfer Learning with a Unified Text-toText Transformer. Journal of Machine Learning Research , 21(140): 1-67.', text='Raffel, C.; Shazeer, N.; Roberts, A.; Lee, K.; Narang, S.; Matena, M.; Zhou, Y.; Li, W.; and Liu, P. J. 2020. Exploring the Limits of Transfer Learning with a Unified Text-toText Transformer. Journal of Machine Learning Research , 21(140): 1-67.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/74', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=516.342, r=558.005, b=431.077, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 400))], orig='Reimers, N.; and Gurevych, I. 2019. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In Inui, K.; Jiang, J.; Ng, V.; and Wan, X., eds., Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) , 3982-3992. Hong Kong, China: Association for Computational Linguistics.', text='Reimers, N.; and Gurevych, I. 2019. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In Inui, K.; Jiang, J.; Ng, V.; and Wan, X., eds., Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) , 3982-3992. Hong Kong, China: Association for Computational Linguistics.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/75', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=426.18, r=558.005, b=395.71, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 163))], orig='Staar, P. W. J.; et al. 2018. Corpus Conversion Service. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . ACM.', text='Staar, P. W. J.; et al. 2018. Corpus Conversion Service. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . ACM.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/76', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=390.812, r=558.005, b=338.425, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 275))], orig='Tay, Y.; Dehghani, M.; Tran, V. Q.; Garcia, X.; Wei, J.; Wang, X.; Chung, H. W.; Bahri, D.; Schuster, T.; Zheng, S.; Zhou, D.; Houlsby, N.; and Metzler, D. 2023. UL2: Unifying Language Learning Paradigms. In The Eleventh International Conference on Learning Representations .', text='Tay, Y.; Dehghani, M.; Tran, V. Q.; Garcia, X.; Wei, J.; Wang, X.; Chung, H. W.; Bahri, D.; Schuster, T.; Zheng, S.; Zhou, D.; Houlsby, N.; and Metzler, D. 2023. UL2: Unifying Language Learning Paradigms. In The Eleventh International Conference on Learning Representations .', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/77', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=333.527, r=558.005, b=314.016, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 96))], orig='Touvron, H.; et al. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models. arXiv:2307.09288.', text='Touvron, H.; et al. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models. arXiv:2307.09288.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/78', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=309.119, r=558.005, b=256.731, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 226))], orig='Webersinke, N.; Kraus, M.; Bingler, J.; and Leippold, M. 2022. ClimateBERT: A Pretrained Language Model for Climate-Related Text. In Proceedings of AAAI 2022 Fall Symposium: The Role of AI in Responding to Climate Challenges .', text='Webersinke, N.; Kraus, M.; Bingler, J.; and Leippold, M. 2022. ClimateBERT: A Pretrained Language Model for Climate-Related Text. In Proceedings of AAAI 2022 Fall Symposium: The Role of AI in Responding to Climate Challenges .', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/79', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=251.83400000000006, r=558.005, b=188.48699999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 308))], orig='Wei, J.; Tay, Y.; Bommasani, R.; Raffel, C.; Zoph, B.; Borgeaud, S.; Yogatama, D.; Bosma, M.; Zhou, D.; Metzler, D.; Chi, E. H.; Hashimoto, T.; Vinyals, O.; Liang, P.; Dean, J.; and Fedus, W. 2022. Emergent Abilities of Large Language Models. Transactions on Machine Learning Research . Survey Certification.', text='Wei, J.; Tay, Y.; Bommasani, R.; Raffel, C.; Zoph, B.; Borgeaud, S.; Yogatama, D.; Bosma, M.; Zhou, D.; Metzler, D.; Chi, E. H.; Hashimoto, T.; Vinyals, O.; Liang, P.; Dean, J.; and Fedus, W. 2022. Emergent Abilities of Large Language Models. Transactions on Machine Learning Research . Survey Certification.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/80', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=183.59000000000003, r=558.005, b=142.16100000000006, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 172))], orig='Zhang, M.; et al. 2023. WeLayout: WeChat Layout Analysis System for the ICDAR 2023 Competition on Robust Layout Segmentation in Corporate Documents. ArXiv , abs/2305.06553.', text='Zhang, M.; et al. 2023. WeLayout: WeChat Layout Analysis System for the ICDAR 2023 Competition on Robust Layout Segmentation in Corporate Documents. ArXiv , abs/2305.06553.', formatting=None, hyperlink=None)), Span(item=TextItem(self_ref='#/texts/81', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=137.26300000000003, r=558.005, b=95.83500000000004, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 176))], orig='Zhong, X.; et al. 2019. PubLayNet: Largest Dataset Ever for Document Layout Analysis. In 2019 International Conference on Document Analysis and Recognition (ICDAR) , 1015-1022.', text='Zhong, X.; et al. 2019. PubLayNet: Largest Dataset Ever for Document Layout Analysis. In 2019 International Conference on Document Analysis and Recognition (ICDAR) , 1015-1022.', formatting=None, hyperlink=None))])\n"
     ]
    }
   ],
   "source": [
    "for result in ser_result:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a55945",
   "metadata": {},
   "source": [
    "## testing weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbf4eddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "docling_core.types.doc.document.DoclingDocument"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.datamodel.accelerator_options import AcceleratorDevice, AcceleratorOptions\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.pipeline.simple_pipeline import SimplePipeline\n",
    "from docling.pipeline.standard_pdf_pipeline import StandardPdfPipeline\n",
    "from docling.backend.pypdfium2_backend import PyPdfiumDocumentBackend\n",
    "from docling.document_converter import (\n",
    "    DocumentConverter,\n",
    "    PdfFormatOption,\n",
    "    WordFormatOption,\n",
    ")\n",
    "file_path = \"text.md\"\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_ocr = False\n",
    "pipeline_options.do_table_structure = True\n",
    "pipeline_options.table_structure_options.do_cell_matching = True\n",
    "pipeline_options.do_picture_description = False\n",
    "pipeline_options.ocr_options.lang = [\"ja\", \"en\"]\n",
    "pipeline_options.do_formula_enrichment = False\n",
    "pipeline_options.force_backend_text = False\n",
    "pipeline_options.generate_picture_images = True\n",
    "pipeline_options.images_scale = 2\n",
    "pipeline_options.do_picture_classification = True\n",
    "pipeline_options.accelerator_options = AcceleratorOptions(\n",
    "    num_threads=8, device=AcceleratorDevice.AUTO\n",
    ")\n",
    "converter= DocumentConverter(\n",
    "            allowed_formats=[\n",
    "                InputFormat.PDF,\n",
    "                InputFormat.IMAGE,\n",
    "                InputFormat.DOCX,\n",
    "                InputFormat.HTML,\n",
    "                InputFormat.PPTX,\n",
    "                InputFormat.ASCIIDOC,\n",
    "                InputFormat.CSV,\n",
    "                InputFormat.MD,\n",
    "                InputFormat.XLSX,\n",
    "            ],\n",
    "            format_options={\n",
    "                InputFormat.PDF: PdfFormatOption(\n",
    "                    pipeline_options=pipeline_options,\n",
    "                    pipeline_cls=StandardPdfPipeline,\n",
    "                    backend=PyPdfiumDocumentBackend,\n",
    "                ),\n",
    "                InputFormat.DOCX: WordFormatOption(\n",
    "                    pipeline_cls=SimplePipeline,\n",
    "                ),\n",
    "            },\n",
    "        )\n",
    "\n",
    "doc = converter.convert(source=file_path).document\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37b48601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "docling_core.types.doc.document.DoclingDocument"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7062e708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (911 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from docling.chunking import HybridChunker\n",
    "\n",
    "chunker = HybridChunker()\n",
    "chunk_iter = chunker.chunk(dl_doc=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82d7b561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 0 ===\n",
      "chunk.text:\n",
      "'উপন্যাস হিসেবে ‘রাজমোহনের স্ত্রী’র (Rajmohan’s Wife) মূল্য যাহাই হউক ইহার ঐতিহাসিক মূল্য অসামান্য। বাংলাদেশের প্রথম ও শ্রেষ্ঠ ঔপন্যাসিকের প্রথম উপন্যাস বাঙালী পাঠকের কাছে চিরদিনই কৌতুক ও কৌতূহলের বিষয় হইয়া থাকিবে। বঙ্কিমচন্দ্রের বাল্য ও কৈশোরের সাহিত্য-সাধনার যে মুদ্রিত ইতিহাস পাওয়া যায় তাহাতে দ…'\n",
      "chunker.contextualize(chunk):\n",
      "'উপন্যাস হিসেবে ‘রাজমোহনের স্ত্রী’র (Rajmohan’s Wife) মূল্য যাহাই হউক ইহার ঐতিহাসিক মূল্য অসামান্য। বাংলাদেশের প্রথম ও শ্রেষ্ঠ ঔপন্যাসিকের প্রথম উপন্যাস বাঙালী পাঠকের কাছে চিরদিনই কৌতুক ও কৌতূহলের বিষয় হইয়া থাকিবে। বঙ্কিমচন্দ্রের বাল্য ও কৈশোরের সাহিত্য-সাধনার যে মুদ্রিত ইতিহাস পাওয়া যায় তাহাতে দ…'\n",
      "\n",
      "=== 1 ===\n",
      "chunk.text:\n",
      "'লিখিতে আরম্ভ করেন এবং প্রায় দুই বৎসরকাল ওই পত্রিকাতেই নানাবিধ গদ্য-পদ্য রচনা প্রকাশ করেন। তাঁহার প্রথম গ্রন্থ ‘ললিতা। পুরাকালিক গল্প। ‘তথা মানস’ ১৮৫৩ খ্রীষ্টাব্দেই রচিত হইয়াছিল। ইহা পুস্তকাকারে প্রকাশিত হয় ১৮৫৬ খ্রীষ্টাব্দে। ওই সালে বঙ্কিমচন্দ্র কদর্য্য বাংলা গদ্যে ওই পুস্তকের এক পৃষ্ঠা ভূমিকা মা…'\n",
      "chunker.contextualize(chunk):\n",
      "'লিখিতে আরম্ভ করেন এবং প্রায় দুই বৎসরকাল ওই পত্রিকাতেই নানাবিধ গদ্য-পদ্য রচনা প্রকাশ করেন। তাঁহার প্রথম গ্রন্থ ‘ললিতা। পুরাকালিক গল্প। ‘তথা মানস’ ১৮৫৩ খ্রীষ্টাব্দেই রচিত হইয়াছিল। ইহা পুস্তকাকারে প্রকাশিত হয় ১৮৫৬ খ্রীষ্টাব্দে। ওই সালে বঙ্কিমচন্দ্র কদর্য্য বাংলা গদ্যে ওই পুস্তকের এক পৃষ্ঠা ভূমিকা মা…'\n",
      "\n",
      "=== 2 ===\n",
      "chunk.text:\n",
      "'ইতিহাস আমরা অবগত নই। এই কালের মধ্যে তিনি এণ্ট্রান্স হইতে বি. এ. পর্য্যন্ত পাঠ সমাপ্ত করিয়াছেন এবং ১৮৫৮ খ্রীষ্টাব্দের ৭ আগস্ট হইতে ডেপুটিগিরি চাকুরিতে বহাল হইয়া যশোহর-মেদিনীপুর-খুলনা-বারুইপুর করিয়া ফিরিতেছেন। এই সময়ে তিনি খাঁটি ইংরেজীনবিশ; মাতা বঙ্গবীণাপাণির প্রতি উপেক্ষা প্রদর্শন করিয়া বিমাতার …'\n",
      "chunker.contextualize(chunk):\n",
      "'ইতিহাস আমরা অবগত নই। এই কালের মধ্যে তিনি এণ্ট্রান্স হইতে বি. এ. পর্য্যন্ত পাঠ সমাপ্ত করিয়াছেন এবং ১৮৫৮ খ্রীষ্টাব্দের ৭ আগস্ট হইতে ডেপুটিগিরি চাকুরিতে বহাল হইয়া যশোহর-মেদিনীপুর-খুলনা-বারুইপুর করিয়া ফিরিতেছেন। এই সময়ে তিনি খাঁটি ইংরেজীনবিশ; মাতা বঙ্গবীণাপাণির প্রতি উপেক্ষা প্রদর্শন করিয়া বিমাতার …'\n",
      "\n",
      "=== 3 ===\n",
      "chunk.text:\n",
      "'ফীল্ড’ নামক ইংরেজী সাপ্তাহিকে বাংলাভাষার শ্রেষ্ঠ ঔপন্যাসিকের প্রথম উপন্যাস ইংরেজী ভাষায় লিখিত Rajmohan’s Wife ধারাবাহিকভাবে বাহির হইতে থাকে। ‘ইণ্ডিয়ান ফীল্ডে’ সম্পূর্ণ হইলেও এই পুস্তক বঙ্কিমচন্দ্রের জীবিতকালে পুস্তকাকারে বাহির হয় নাই।…'\n",
      "chunker.contextualize(chunk):\n",
      "'ফীল্ড’ নামক ইংরেজী সাপ্তাহিকে বাংলাভাষার শ্রেষ্ঠ ঔপন্যাসিকের প্রথম উপন্যাস ইংরেজী ভাষায় লিখিত Rajmohan’s Wife ধারাবাহিকভাবে বাহির হইতে থাকে। ‘ইণ্ডিয়ান ফীল্ডে’ সম্পূর্ণ হইলেও এই পুস্তক বঙ্কিমচন্দ্রের জীবিতকালে পুস্তকাকারে বাহির হয় নাই।…'\n",
      "\n",
      "=== 4 ===\n",
      "chunk.text:\n",
      "'কারণ অনুমান করা যায় যে, মাতৃভাষার প্রতি বঙ্কিমচন্দ্রের আকর্ষণ এই বৎসরেই প্রবল হইয়া থাকিবে। তিনি সম্ভবত ইংরেজীতে মৌলিক সৃষ্টির আশা পরিত্যাগ করিয়া মাতৃভাষার সাহায্যই গ্রহণ করিতে মনস্থ করিয়াছিলেন। নিজের রচিত ইংরেজী উপন্যাসেরই অনুবাদ করিয়া তিনি এই সঙ্কল্প কাজে পরিণত করিতে চাহিলেন। এক অধ্যায় দুই অধ…'\n",
      "chunker.contextualize(chunk):\n",
      "'কারণ অনুমান করা যায় যে, মাতৃভাষার প্রতি বঙ্কিমচন্দ্রের আকর্ষণ এই বৎসরেই প্রবল হইয়া থাকিবে। তিনি সম্ভবত ইংরেজীতে মৌলিক সৃষ্টির আশা পরিত্যাগ করিয়া মাতৃভাষার সাহায্যই গ্রহণ করিতে মনস্থ করিয়াছিলেন। নিজের রচিত ইংরেজী উপন্যাসেরই অনুবাদ করিয়া তিনি এই সঙ্কল্প কাজে পরিণত করিতে চাহিলেন। এক অধ্যায় দুই অধ…'\n",
      "\n",
      "=== 5 ===\n",
      "chunk.text:\n",
      "'বাকি ছিল) অনুবাদ করিয়া তিনি আর পারিলেন না। তাঁহার মত মৌলিক সৃষ্টি-প্রতিভা যাঁহার, তিনি অনুবাদ বা অনুসরণে তৃপ্তিলাভ করিতে পারেন না, তা সে হউক না নিজেরই অনুসরণ। সুতরাং ‘রাজমোহনের স্ত্রী’র বঙ্কিমকৃত বাংলারূপ আর প্রকাশ পাইল না, প্রায় সূত্রপাতেই বিনষ্ট হইল।…'\n",
      "chunker.contextualize(chunk):\n",
      "'বাকি ছিল) অনুবাদ করিয়া তিনি আর পারিলেন না। তাঁহার মত মৌলিক সৃষ্টি-প্রতিভা যাঁহার, তিনি অনুবাদ বা অনুসরণে তৃপ্তিলাভ করিতে পারেন না, তা সে হউক না নিজেরই অনুসরণ। সুতরাং ‘রাজমোহনের স্ত্রী’র বঙ্কিমকৃত বাংলারূপ আর প্রকাশ পাইল না, প্রায় সূত্রপাতেই বিনষ্ট হইল।…'\n",
      "\n",
      "=== 6 ===\n",
      "chunk.text:\n",
      "'কিন্তু সৌভাগ্যের বিষয়, সেই পাতা কয়টা রহিয়া গিয়াছে। বঙ্কিমচন্দ্রের মৃত্যুর পর তাঁহার দপ্তর ঘাঁটিয়া ভ্রাতুষ্পুত্র ও জীবনীকার শচীশচন্দ্র চট্টোপাধ্যায় মহাশয় সেই খণ্ডিত অনুবাদের পাণ্ডুলিপিটি সংগ্রহ করেন। শচীশচন্দ্র যদিও জানিতেন যে, বঙ্কিমচন্দ্র একদা Rajmohan’s Wife লিখিয়াছিলেন[১] তথাপি কেন জানি ন…'\n",
      "chunker.contextualize(chunk):\n",
      "'কিন্তু সৌভাগ্যের বিষয়, সেই পাতা কয়টা রহিয়া গিয়াছে। বঙ্কিমচন্দ্রের মৃত্যুর পর তাঁহার দপ্তর ঘাঁটিয়া ভ্রাতুষ্পুত্র ও জীবনীকার শচীশচন্দ্র চট্টোপাধ্যায় মহাশয় সেই খণ্ডিত অনুবাদের পাণ্ডুলিপিটি সংগ্রহ করেন। শচীশচন্দ্র যদিও জানিতেন যে, বঙ্কিমচন্দ্র একদা Rajmohan’s Wife লিখিয়াছিলেন[১] তথাপি কেন জানি ন…'\n",
      "\n",
      "=== 7 ===\n",
      "chunk.text:\n",
      "'রাজমোহন ও রাজমোহনের স্ত্রীর বারংবার উল্লেখ থাকা সত্ত্বেও। যাহা হউক, তিনি সেই পাণ্ডুলিপিটিকে বঙ্কিমচন্দ্রের সর্ব্বশেষ উপন্যাসের সূত্রপাত কল্পনা করিয়া নিজের খেয়ালমত তাহা সম্পূর্ণ করেন এবং ‘বারি-বাহিনী’ নাম দিয়া ১৩২৫ বঙ্গাব্দে পুস্তকাকারে প্রকাশ করেন। এই পুস্তকে বঙ্কিমচন্দ্র-অনূদিত প্রথম সাত পরিচ্ছে…'\n",
      "chunker.contextualize(chunk):\n",
      "'রাজমোহন ও রাজমোহনের স্ত্রীর বারংবার উল্লেখ থাকা সত্ত্বেও। যাহা হউক, তিনি সেই পাণ্ডুলিপিটিকে বঙ্কিমচন্দ্রের সর্ব্বশেষ উপন্যাসের সূত্রপাত কল্পনা করিয়া নিজের খেয়ালমত তাহা সম্পূর্ণ করেন এবং ‘বারি-বাহিনী’ নাম দিয়া ১৩২৫ বঙ্গাব্দে পুস্তকাকারে প্রকাশ করেন। এই পুস্তকে বঙ্কিমচন্দ্র-অনূদিত প্রথম সাত পরিচ্ছে…'\n",
      "\n",
      "=== 8 ===\n",
      "chunk.text:\n",
      "'‘বারি-বাহিনী’র শেষ অংশের কোনই মিল নাই। শচীশচন্দ্র পুস্তকের “ভূমিকা”য় লেখেন—\\nপরমারাধ্য বঙ্কিমচন্দ্র মৃত্যুর অনতিপূর্ব্বে—১৩০০ বঙ্গাব্দে—এই আখ্যায়িকা লিখিতে আরম্ভ করেন; কিন্তু শেষ করিয়া যাইতে পারেন নাই। তাঁহার পুত্র ও শিষ্য আজ তাহা ছাব্বিশ বৎসর পরে শেষ করিল।\\n‘বঙ্কিম-জীবনী’তেও “জীবনের শেষ কয়েক বৎসর…'\n",
      "chunker.contextualize(chunk):\n",
      "'‘বারি-বাহিনী’র শেষ অংশের কোনই মিল নাই। শচীশচন্দ্র পুস্তকের “ভূমিকা”য় লেখেন—\\nপরমারাধ্য বঙ্কিমচন্দ্র মৃত্যুর অনতিপূর্ব্বে—১৩০০ বঙ্গাব্দে—এই আখ্যায়িকা লিখিতে আরম্ভ করেন; কিন্তু শেষ করিয়া যাইতে পারেন নাই। তাঁহার পুত্র ও শিষ্য আজ তাহা ছাব্বিশ বৎসর পরে শেষ করিল।\\n‘বঙ্কিম-জীবনী’তেও “জীবনের শেষ কয়েক বৎসর…'\n",
      "\n",
      "=== 9 ===\n",
      "chunk.text:\n",
      "'কিছু করেন নাই বলিলে চলিবে না। তিনি একখানি সামাজিক উপন্যাস লিখিতেছিলেন। কিন্তু তাহা সম্পূর্ণ করিয়া যাইতে পারেন নাই—কয়েকটি পরিচ্ছেদ লিখিত হইতে না হইতে কাল তাঁহাকে কাড়িয়া লইয়া গেল। তাহার কয়েক বৎসর পরে উপন্যাসখানি সম্পূর্ণ করিয়া প্রকাশ করিয়াছি। তৃতীয় সংস্করণ, পৃ. ১৫২…'\n",
      "chunker.contextualize(chunk):\n",
      "'কিছু করেন নাই বলিলে চলিবে না। তিনি একখানি সামাজিক উপন্যাস লিখিতেছিলেন। কিন্তু তাহা সম্পূর্ণ করিয়া যাইতে পারেন নাই—কয়েকটি পরিচ্ছেদ লিখিত হইতে না হইতে কাল তাঁহাকে কাড়িয়া লইয়া গেল। তাহার কয়েক বৎসর পরে উপন্যাসখানি সম্পূর্ণ করিয়া প্রকাশ করিয়াছি। তৃতীয় সংস্করণ, পৃ. ১৫২…'\n",
      "\n",
      "=== 10 ===\n",
      "chunk.text:\n",
      "'এইরূপ ভ্রমের প্রধান কারণ সম্ভবত এই যে, ‘ইণ্ডিয়ান ফীল্ড’ হইতে Rajmohan’s Wife তখন পর্য্যন্ত আবিষ্কৃত হয় নাই। শ্রীযুক্ত ব্রজেন্দ্রনাথ বন্দ্যোপাধ্যায় পরে ইহা আবিষ্কার করেন ও ১৯৩৫ খ্রীষ্টাব্দে পুস্তকাকারে প্রকাশ করেন। ‘ইণ্ডিয়ান ফীল্ডে’র যে যে সংখ্যায় প্রথম তিন অধ্যায় বাহির হইয়াছিল, সেই সেই সংখ্যা…'\n",
      "chunker.contextualize(chunk):\n",
      "'এইরূপ ভ্রমের প্রধান কারণ সম্ভবত এই যে, ‘ইণ্ডিয়ান ফীল্ড’ হইতে Rajmohan’s Wife তখন পর্য্যন্ত আবিষ্কৃত হয় নাই। শ্রীযুক্ত ব্রজেন্দ্রনাথ বন্দ্যোপাধ্যায় পরে ইহা আবিষ্কার করেন ও ১৯৩৫ খ্রীষ্টাব্দে পুস্তকাকারে প্রকাশ করেন। ‘ইণ্ডিয়ান ফীল্ডে’র যে যে সংখ্যায় প্রথম তিন অধ্যায় বাহির হইয়াছিল, সেই সেই সংখ্যা…'\n",
      "\n",
      "=== 11 ===\n",
      "chunk.text:\n",
      "'অনুবাদ দিয়া পুস্তক সম্পূর্ণ করা হইয়াছে। অর্থাং প্রথম তিন অধ্যায় বঙ্কিমচন্দ্রের বাংলা অনুবাদের ইংরেজী অনুবাদ। পরে বঙ্গীয়-সাহিত্য-পরিষৎ কর্ত্তৃক প্রকাশিত বঙ্কিমচন্দ্রের সম্পূর্ণ রচনাবলীর ইংরেজী খণ্ডে Rajmohan’s Wife এবং “বিবিধ” খণ্ডে ‘বারি-বাহিনী’ হইতে বঙ্কিমচন্দ্র-কৃত সাত পরিচ্ছেদের অনুবাদ প্রকাশ…'\n",
      "chunker.contextualize(chunk):\n",
      "'অনুবাদ দিয়া পুস্তক সম্পূর্ণ করা হইয়াছে। অর্থাং প্রথম তিন অধ্যায় বঙ্কিমচন্দ্রের বাংলা অনুবাদের ইংরেজী অনুবাদ। পরে বঙ্গীয়-সাহিত্য-পরিষৎ কর্ত্তৃক প্রকাশিত বঙ্কিমচন্দ্রের সম্পূর্ণ রচনাবলীর ইংরেজী খণ্ডে Rajmohan’s Wife এবং “বিবিধ” খণ্ডে ‘বারি-বাহিনী’ হইতে বঙ্কিমচন্দ্র-কৃত সাত পরিচ্ছেদের অনুবাদ প্রকাশ…'\n",
      "\n",
      "=== 12 ===\n",
      "chunk.text:\n",
      "'Rajmohan’s Wifeএর মৎকৃত অনুবাদ। চতুর্থ পরিচ্ছেদ হইতে) ‘বঙ্গশ্রী’ পত্রিকায় ১৩৩৯ বঙ্গাব্দের মাঘ হইতে ১৩৪০ বঙ্গাব্দের মাঘ পর্য্যন্ত ১৩ মাস ধরিয়া বাহির হয়। এই পুস্তকে ‘বারি-বাহিনী’র সহায়তায় প্রথম তিন পরিচ্ছেদও যুক্ত হইয়াছে। এই তিন পরিচ্ছেদে কোটেশন-মার্কা দেওয়া অংশ বঙ্কিমচন্দ্রের অনুবাদ। বঙ্কিমচন্…'\n",
      "chunker.contextualize(chunk):\n",
      "'Rajmohan’s Wifeএর মৎকৃত অনুবাদ। চতুর্থ পরিচ্ছেদ হইতে) ‘বঙ্গশ্রী’ পত্রিকায় ১৩৩৯ বঙ্গাব্দের মাঘ হইতে ১৩৪০ বঙ্গাব্দের মাঘ পর্য্যন্ত ১৩ মাস ধরিয়া বাহির হয়। এই পুস্তকে ‘বারি-বাহিনী’র সহায়তায় প্রথম তিন পরিচ্ছেদও যুক্ত হইয়াছে। এই তিন পরিচ্ছেদে কোটেশন-মার্কা দেওয়া অংশ বঙ্কিমচন্দ্রের অনুবাদ। বঙ্কিমচন্…'\n",
      "\n",
      "=== 13 ===\n",
      "chunk.text:\n",
      "'ইংরেজীরই যথাযথ অনুসরণ করিয়াছি। বঙ্কিমচন্দ্রের স্বহস্ত-লিখিত পাণ্ডুলিপির একটি পৃষ্ঠা শচীশচন্দ্র ‘বারি-বাহিনী’তে প্রকাশ করিয়াছেন। আমরা এই পুস্তকে তাহারই একটি প্রতিলিপি দিলাম।…'\n",
      "chunker.contextualize(chunk):\n",
      "'ইংরেজীরই যথাযথ অনুসরণ করিয়াছি। বঙ্কিমচন্দ্রের স্বহস্ত-লিখিত পাণ্ডুলিপির একটি পৃষ্ঠা শচীশচন্দ্র ‘বারি-বাহিনী’তে প্রকাশ করিয়াছেন। আমরা এই পুস্তকে তাহারই একটি প্রতিলিপি দিলাম।…'\n",
      "\n",
      "=== 14 ===\n",
      "chunk.text:\n",
      "'‘রাজমোহনের স্ত্রী’র বঙ্কিম-কৃত অনুবাদ-অংশের ভাষা লইয়া কিছু আলোচনা আবশ্যক, কারণ বাংলা সাহিত্যের ইতিহাসে এই অনুবাদটুকু বঙ্কিমের ভাষার ক্রমপরিণতির পরিচয় বহন করিতেছে। এই কাঁচা-পাকা ভাষার সংমিশ্রণ দৃষ্টে শচীশচন্দ্রের মনেও সংশয় জাগিয়াছিল। সেই কারণেই তিনি ‘বারি-বাহিনী’র “ভূমিকা”য় লিখিয়াছিলেন—…'\n",
      "chunker.contextualize(chunk):\n",
      "'‘রাজমোহনের স্ত্রী’র বঙ্কিম-কৃত অনুবাদ-অংশের ভাষা লইয়া কিছু আলোচনা আবশ্যক, কারণ বাংলা সাহিত্যের ইতিহাসে এই অনুবাদটুকু বঙ্কিমের ভাষার ক্রমপরিণতির পরিচয় বহন করিতেছে। এই কাঁচা-পাকা ভাষার সংমিশ্রণ দৃষ্টে শচীশচন্দ্রের মনেও সংশয় জাগিয়াছিল। সেই কারণেই তিনি ‘বারি-বাহিনী’র “ভূমিকা”য় লিখিয়াছিলেন—…'\n",
      "\n",
      "=== 15 ===\n",
      "chunk.text:\n",
      "'বঙ্কিমচন্দ্র তাঁহার সাধারণ ভাষা পরিত্যাগপূর্ব্বক এক অভিনব ভাষায় এই পুস্তকখানির রচনায় প্রবৃত্ত হইয়া ছিলেন।…'\n",
      "chunker.contextualize(chunk):\n",
      "'বঙ্কিমচন্দ্র তাঁহার সাধারণ ভাষা পরিত্যাগপূর্ব্বক এক অভিনব ভাষায় এই পুস্তকখানির রচনায় প্রবৃত্ত হইয়া ছিলেন।…'\n",
      "\n",
      "=== 16 ===\n",
      "chunk.text:\n",
      "'আসলে ঈশ্বরচন্দ্র গুপ্তের প্রভাববর্জ্জিত ভাবে এই কয়টি পৃষ্ঠাই বঙ্কিমচন্দ্রের প্রথম বাংলা-গদ্যরচনা। ইতিপূর্ব্বে ‘সংবাদ প্রভাকরে’ তাঁহার যে গদ্যরচনা বাহির হইয়াছিল, তাহাকে অপাঠ্য গদ্য বলিলে অপরাধ হয় না। ‘রাজমোহনের স্ত্রী’ অনুবাদ করিতে বসিয়া বঙ্কিমচন্দ্র সেই ভাষাকে নির্ম্মমভাবে ত্যাগ করিতে চেষ্টা করি…'\n",
      "chunker.contextualize(chunk):\n",
      "'আসলে ঈশ্বরচন্দ্র গুপ্তের প্রভাববর্জ্জিত ভাবে এই কয়টি পৃষ্ঠাই বঙ্কিমচন্দ্রের প্রথম বাংলা-গদ্যরচনা। ইতিপূর্ব্বে ‘সংবাদ প্রভাকরে’ তাঁহার যে গদ্যরচনা বাহির হইয়াছিল, তাহাকে অপাঠ্য গদ্য বলিলে অপরাধ হয় না। ‘রাজমোহনের স্ত্রী’ অনুবাদ করিতে বসিয়া বঙ্কিমচন্দ্র সেই ভাষাকে নির্ম্মমভাবে ত্যাগ করিতে চেষ্টা করি…'\n",
      "\n",
      "=== 17 ===\n",
      "chunk.text:\n",
      "'‘হুতোম প্যাঁচার নক্\\u200cশা’ তখন প্রকাশিত হইয়াছে। বিদ্যাসাগরী-রীতি ও আলালী-রীতির পার্থক্য তিনি ধরিতে পারিয়াছেন এবং নিজের অসাধারণ প্রতিভাবলে বুঝিয়াছেন যে, এই দুই রীতির সমন্বয় ব্যতিরেকে বাংলা ভাষার উন্নতি সম্ভব নহে। তিনিই এই সমন্বয়সাধনে সচেষ্ট হইলেন। ‘রাজমোহনের স্ত্রী’র তৎকৃত অনুবাদে এই দুই রীতির দ্বন…'\n",
      "chunker.contextualize(chunk):\n",
      "'‘হুতোম প্যাঁচার নক্\\u200cশা’ তখন প্রকাশিত হইয়াছে। বিদ্যাসাগরী-রীতি ও আলালী-রীতির পার্থক্য তিনি ধরিতে পারিয়াছেন এবং নিজের অসাধারণ প্রতিভাবলে বুঝিয়াছেন যে, এই দুই রীতির সমন্বয় ব্যতিরেকে বাংলা ভাষার উন্নতি সম্ভব নহে। তিনিই এই সমন্বয়সাধনে সচেষ্ট হইলেন। ‘রাজমোহনের স্ত্রী’র তৎকৃত অনুবাদে এই দুই রীতির দ্বন…'\n",
      "\n",
      "=== 18 ===\n",
      "chunk.text:\n",
      "'এই সর্ব্বাঙ্গসুন্দর রমণীকুসুম মধুমতী তীরজ নহে— ভাগীরথী কূলে রাজধানীসন্নিহিত কোনও স্থানে জাতাও প্রতিপালিতা হইয়া থাকিবেক।—ইত্যাদি। প্রথম পরিচ্ছেদ দ্রষ্টব্য। এবং ইহারই পাশে আলালী-রীতির দৃষ্টান্ত—…'\n",
      "chunker.contextualize(chunk):\n",
      "'এই সর্ব্বাঙ্গসুন্দর রমণীকুসুম মধুমতী তীরজ নহে— ভাগীরথী কূলে রাজধানীসন্নিহিত কোনও স্থানে জাতাও প্রতিপালিতা হইয়া থাকিবেক।—ইত্যাদি। প্রথম পরিচ্ছেদ দ্রষ্টব্য। এবং ইহারই পাশে আলালী-রীতির দৃষ্টান্ত—…'\n",
      "\n",
      "=== 19 ===\n",
      "chunk.text:\n",
      "'মথুর। কাজ ত সব জানি।— কাজের মধ্যে নূতন ঘোড়া নূতন গাড়ি—ঠক বেটাদের দোকানে টো টো করা—টাকা উড়ান—তেল পুড়ান—ইংরাজিনবিশ ইয়ার বক্\\u200cশিকে মদ খাওয়ান—আর হয়ত রসের তরঙ্গে ঢলাঢল। ইত্যাদি। ঐ।…'\n",
      "chunker.contextualize(chunk):\n",
      "'মথুর। কাজ ত সব জানি।— কাজের মধ্যে নূতন ঘোড়া নূতন গাড়ি—ঠক বেটাদের দোকানে টো টো করা—টাকা উড়ান—তেল পুড়ান—ইংরাজিনবিশ ইয়ার বক্\\u200cশিকে মদ খাওয়ান—আর হয়ত রসের তরঙ্গে ঢলাঢল। ইত্যাদি। ঐ।…'\n",
      "\n",
      "=== 20 ===\n",
      "chunk.text:\n",
      "'প্রাচীন ও নবীন রীতির এই দ্বন্দ্বের মধ্যেই বঙ্কিমচন্দ্রের সাহিত্যজীবনের আদিপর্ব্বের সমাপ্তি এবং যথার্থ বঙ্কিম-প্রতিভার অভ্যুদয়। ‘দুর্গেশনন্দিনী’তে (১৮৬৫) সার্থকভাবে এই ভাষাসমন্বয়ের সূত্রপাত দেখিতে পাই। ‘বঙ্গদর্শনে’র যুগে দেখি বঙ্কিমচন্দ্র তাঁহার পথ খুঁজিয়া পাইয়াছেন।\\nশ্রীসজনীকান্ত দাস…'\n",
      "chunker.contextualize(chunk):\n",
      "'প্রাচীন ও নবীন রীতির এই দ্বন্দ্বের মধ্যেই বঙ্কিমচন্দ্রের সাহিত্যজীবনের আদিপর্ব্বের সমাপ্তি এবং যথার্থ বঙ্কিম-প্রতিভার অভ্যুদয়। ‘দুর্গেশনন্দিনী’তে (১৮৬৫) সার্থকভাবে এই ভাষাসমন্বয়ের সূত্রপাত দেখিতে পাই। ‘বঙ্গদর্শনে’র যুগে দেখি বঙ্কিমচন্দ্র তাঁহার পথ খুঁজিয়া পাইয়াছেন।\\nশ্রীসজনীকান্ত দাস…'\n",
      "\n",
      "=== 21 ===\n",
      "chunk.text:\n",
      "'বরদা বাংলা সাহিত্যের কাল্পনিক চরিত্রগুলির মধ্যে অন্যতম। এই চরিত্রটি তৈরি করেন প্রখ্যাত সাহিত্যিক শরদিন্দু বন্দ্যোপাধ্যায়। প্রেতপুরী (১৯১৫) গল্পে ভূতান্বেষী বরদা-র প্রথম আবির্ভাব। বরদা সিরিজের কাহিনীগুলি প্রধানত ভৌতিক বা অলৌকিক রসের।…'\n",
      "chunker.contextualize(chunk):\n",
      "'বরদা বাংলা সাহিত্যের কাল্পনিক চরিত্রগুলির মধ্যে অন্যতম। এই চরিত্রটি তৈরি করেন প্রখ্যাত সাহিত্যিক শরদিন্দু বন্দ্যোপাধ্যায়। প্রেতপুরী (১৯১৫) গল্পে ভূতান্বেষী বরদা-র প্রথম আবির্ভাব। বরদা সিরিজের কাহিনীগুলি প্রধানত ভৌতিক বা অলৌকিক রসের।…'\n",
      "\n",
      "=== 22 ===\n",
      "chunk.text:\n",
      "'শরদিন্দু বন্দ্যোপাধ্যায়ের প্রথম ছোটোগল্পই ‘ভূতজ্ঞানী’ বরদাকে নিয়ে – প্রেতপুরী। জানা যায়, বরদা একজন প্রবাসী বাঙালী যুবক, বিবাহিত, পৈতৃক সম্পত্তির কৃপায় অবস্থা মোটামুটি সচ্ছল, চেহারা “নৈনিতাল আলুর কথা স্মরণ করাইয়া দেয়।” সে তার সম্পত্তি দেখাশোনা করে, ভূত নিয়ে নাড়াচাড়া করে আর অবসর সময়ে ক্লাবে …'\n",
      "chunker.contextualize(chunk):\n",
      "'শরদিন্দু বন্দ্যোপাধ্যায়ের প্রথম ছোটোগল্পই ‘ভূতজ্ঞানী’ বরদাকে নিয়ে – প্রেতপুরী। জানা যায়, বরদা একজন প্রবাসী বাঙালী যুবক, বিবাহিত, পৈতৃক সম্পত্তির কৃপায় অবস্থা মোটামুটি সচ্ছল, চেহারা “নৈনিতাল আলুর কথা স্মরণ করাইয়া দেয়।” সে তার সম্পত্তি দেখাশোনা করে, ভূত নিয়ে নাড়াচাড়া করে আর অবসর সময়ে ক্লাবে …'\n",
      "\n",
      "=== 23 ===\n",
      "chunk.text:\n",
      "'আছে বলেও দাবী করে, ঝামেলা হয় তখনই, যখন সে ক্লাবে তার অত্যন্ত অনিচ্ছুক শ্রোতাদের জোর করে সেই অভিজ্ঞতার কথা শোনাতে চায় – “বরদার আষাঢ়ে গল্পের আসর”। তার প্রধান গুণ হল যে সে নাছোড়বান্দা, সে জোর করে তার ভূতের গল্পটা শুনিয়ে ছাড়ে, আর তার প্রধান হাতিয়ার হলো জমিয়ে গল্প বলার অসাধারণ ক্ষমতা, ব্যোমকেশ ও …'\n",
      "chunker.contextualize(chunk):\n",
      "'আছে বলেও দাবী করে, ঝামেলা হয় তখনই, যখন সে ক্লাবে তার অত্যন্ত অনিচ্ছুক শ্রোতাদের জোর করে সেই অভিজ্ঞতার কথা শোনাতে চায় – “বরদার আষাঢ়ে গল্পের আসর”। তার প্রধান গুণ হল যে সে নাছোড়বান্দা, সে জোর করে তার ভূতের গল্পটা শুনিয়ে ছাড়ে, আর তার প্রধান হাতিয়ার হলো জমিয়ে গল্প বলার অসাধারণ ক্ষমতা, ব্যোমকেশ ও …'\n",
      "\n",
      "=== 24 ===\n",
      "chunk.text:\n",
      "'একবার শুনতে শুরু করলে আর ছাড়া যায না। আবার শরদিন্দুর গল্প বলার অসাধারণ কৌশল হলো, বরদার গল্পের আশেপাশে এমন দুয়েকটা সন্দেহের বীজ ছড়িয়ে দেওয়া যাতে গল্প শেষ হবার পরে বরদা সত্যি বলছে কিনা তা নিয়ে পাঠকদের মনে একটু সংশয় থেকেই যায়। বরদা নিজেই বলেছে যে সেও একসময়ে নাস্তিক ছিলো, কিন্তু এক মারাত্মক অভি…'\n",
      "chunker.contextualize(chunk):\n",
      "'একবার শুনতে শুরু করলে আর ছাড়া যায না। আবার শরদিন্দুর গল্প বলার অসাধারণ কৌশল হলো, বরদার গল্পের আশেপাশে এমন দুয়েকটা সন্দেহের বীজ ছড়িয়ে দেওয়া যাতে গল্প শেষ হবার পরে বরদা সত্যি বলছে কিনা তা নিয়ে পাঠকদের মনে একটু সংশয় থেকেই যায়। বরদা নিজেই বলেছে যে সেও একসময়ে নাস্তিক ছিলো, কিন্তু এক মারাত্মক অভি…'\n",
      "\n",
      "=== 25 ===\n",
      "chunk.text:\n",
      "'অনুযায়ী, সে নিজে ভূত দেখেছে, প্ল্যানচেট করেছে, ভূতের লেখা ডায়েরী পড়েছে, পিণ্ড দিয়েছে এবং অন্তত দুবার তার অবিশ্বাসী বন্ধুবান্ধবদেরও ভূত দেখিয়েছে বা দেখতে সাহায্য করেছে। ব্যোমকেশ বক্সীর সঙ্গে একটি গল্পে তাকে পাওয়া যায়, সেটির নাম ব্যোমকেশ ও বরদা।…'\n",
      "chunker.contextualize(chunk):\n",
      "'অনুযায়ী, সে নিজে ভূত দেখেছে, প্ল্যানচেট করেছে, ভূতের লেখা ডায়েরী পড়েছে, পিণ্ড দিয়েছে এবং অন্তত দুবার তার অবিশ্বাসী বন্ধুবান্ধবদেরও ভূত দেখিয়েছে বা দেখতে সাহায্য করেছে। ব্যোমকেশ বক্সীর সঙ্গে একটি গল্পে তাকে পাওয়া যায়, সেটির নাম ব্যোমকেশ ও বরদা।…'\n",
      "\n",
      "=== 26 ===\n",
      "chunk.text:\n",
      "'বরদাকে নিয়ে শরদিন্দু বন্দ্যোপাধ্যায় মোট ১৩টি ব্যোমকেশ ও বরদা সহ ১৪টি গল্প লিখেছেন। ব্যোমকেশ ও বরদা কাহিনীতে বরদার সাথে শরদিন্দুর অপর সৃষ্টি সত্যান্বেষী ব্যোমকেশ বক্সীর মোলাকাত হয়। যদিও এই কাহিনীটিকে ব্যোমকেশ বক্সী সিরিজের অন্তর্ভুক্ত করা হয়েছে।…'\n",
      "chunker.contextualize(chunk):\n",
      "'বরদাকে নিয়ে শরদিন্দু বন্দ্যোপাধ্যায় মোট ১৩টি ব্যোমকেশ ও বরদা সহ ১৪টি গল্প লিখেছেন। ব্যোমকেশ ও বরদা কাহিনীতে বরদার সাথে শরদিন্দুর অপর সৃষ্টি সত্যান্বেষী ব্যোমকেশ বক্সীর মোলাকাত হয়। যদিও এই কাহিনীটিকে ব্যোমকেশ বক্সী সিরিজের অন্তর্ভুক্ত করা হয়েছে।…'\n",
      "\n",
      "=== 27 ===\n",
      "chunk.text:\n",
      "'শীতের সন্ধ্যায় আমরা কয়েকজন ক্লাবে বসিয়া রাজনৈতিক আলোচনা করিতেছিলাম, যদিও ক্লাবে বসিয়া উক্তরূপ আলোচনা করা ক্লাবের আইনবিরুদ্ধ। বেহার প্রদেশে বাস করিয়া বাঙালীর ক্লাব করিতে হইলে ঐ রকম গুটিকয়েক আইন খাতায় লিপিবদ্ধ করিয়া রাখিতে হয়।\\nআলোচনা ক্রমশ দুইজন সভ্যের মধ্যে বাগ্\\u200cযুদ্ধে দাঁড়াইয়াছিল। আমরা অব…'\n",
      "chunker.contextualize(chunk):\n",
      "'শীতের সন্ধ্যায় আমরা কয়েকজন ক্লাবে বসিয়া রাজনৈতিক আলোচনা করিতেছিলাম, যদিও ক্লাবে বসিয়া উক্তরূপ আলোচনা করা ক্লাবের আইনবিরুদ্ধ। বেহার প্রদেশে বাস করিয়া বাঙালীর ক্লাব করিতে হইলে ঐ রকম গুটিকয়েক আইন খাতায় লিপিবদ্ধ করিয়া রাখিতে হয়।\\nআলোচনা ক্রমশ দুইজন সভ্যের মধ্যে বাগ্\\u200cযুদ্ধে দাঁড়াইয়াছিল। আমরা অব…'\n",
      "\n",
      "=== 28 ===\n",
      "chunk.text:\n",
      "'পৃথ্বী বলিল, যাই বল, গান্ধীটুপি পরলেই দেশভক্ত হওয়া যায় না।\\nগান্ধীটুপি পরিহিত চুনী বলিল, হওয়া যায়। বাংলাদেশের সাতকোটি লোক যদি গান্ধীটুপি পরে তাহলে অন্তত এককোটি গজ খদ্দর বিক্রি হয়, তার দাম নিদেন পক্ষে ত্রিশ লক্ষ টাকা। ঐ টাকাটা দেশের লোকের পেটে যায়।…'\n",
      "chunker.contextualize(chunk):\n",
      "'পৃথ্বী বলিল, যাই বল, গান্ধীটুপি পরলেই দেশভক্ত হওয়া যায় না।\\nগান্ধীটুপি পরিহিত চুনী বলিল, হওয়া যায়। বাংলাদেশের সাতকোটি লোক যদি গান্ধীটুপি পরে তাহলে অন্তত এককোটি গজ খদ্দর বিক্রি হয়, তার দাম নিদেন পক্ষে ত্রিশ লক্ষ টাকা। ঐ টাকাটা দেশের লোকের পেটে যায়।…'\n",
      "\n",
      "=== 29 ===\n",
      "chunk.text:\n",
      "'পৃথ্বী বলিল, হতে পারে। কিন্তু টুপি পরলে বাঙালীর বিশেষত্ব নষ্ট হয়, তা সে যে-টুপিই হোক। ‘লাঙ্গা শির’ হচ্ছে বাঙালীর বিশেষত্ব!\\nচুনী চটিয়া উঠিয়া বলিল, কেবল ওই বিশেষত্বের জোরে যদি বাঙালী বেঁচে থাকতে চায়, তাহলে তার গলায় দড়ি দিয়ে মরা উচিত।\\nদূরে টেবিলের এক কোণে বরদা কড়িকাঠের দিকে চোখ তুলিয়া বসিয়াছি…'\n",
      "chunker.contextualize(chunk):\n",
      "'পৃথ্বী বলিল, হতে পারে। কিন্তু টুপি পরলে বাঙালীর বিশেষত্ব নষ্ট হয়, তা সে যে-টুপিই হোক। ‘লাঙ্গা শির’ হচ্ছে বাঙালীর বিশেষত্ব!\\nচুনী চটিয়া উঠিয়া বলিল, কেবল ওই বিশেষত্বের জোরে যদি বাঙালী বেঁচে থাকতে চায়, তাহলে তার গলায় দড়ি দিয়ে মরা উচিত।\\nদূরে টেবিলের এক কোণে বরদা কড়িকাঠের দিকে চোখ তুলিয়া বসিয়াছি…'\n",
      "\n",
      "=== 30 ===\n",
      "chunk.text:\n",
      "'অপ্রত্যাশিত প্রশ্নে তার্কিক দু’জনে কিছুক্ষণের জন্য গুম হইয়া গেল; তারপর সবাই একসঙ্গে হাসিয়া উঠিল।…'\n",
      "chunker.contextualize(chunk):\n",
      "'অপ্রত্যাশিত প্রশ্নে তার্কিক দু’জনে কিছুক্ষণের জন্য গুম হইয়া গেল; তারপর সবাই একসঙ্গে হাসিয়া উঠিল।…'\n",
      "\n",
      "=== 31 ===\n",
      "chunk.text:\n",
      "'হাসি থামিলে বরদা বলিল, হাসির কথা নয়। মিথ্যে মিথ্যে গল্প বানিয়ে বলি আমার একটা দুর্নাম আছে; সেটা কিন্তু নিন্দুকের অখ্যাতি। স্রেফ গান্ধীটুপি পরলে দেশ উদ্ধার হয় কিনা বলতে পারি না কিন্তু গয়ায় পিণ্ডি দিলে যে বদ্ধ জীবাত্মার মুক্তি হয় তার সদ্য সদ্য প্রমাণ যদি চাও তো আমি দিতে পারি।…'\n",
      "chunker.contextualize(chunk):\n",
      "'হাসি থামিলে বরদা বলিল, হাসির কথা নয়। মিথ্যে মিথ্যে গল্প বানিয়ে বলি আমার একটা দুর্নাম আছে; সেটা কিন্তু নিন্দুকের অখ্যাতি। স্রেফ গান্ধীটুপি পরলে দেশ উদ্ধার হয় কিনা বলতে পারি না কিন্তু গয়ায় পিণ্ডি দিলে যে বদ্ধ জীবাত্মার মুক্তি হয় তার সদ্য সদ্য প্রমাণ যদি চাও তো আমি দিতে পারি।…'\n",
      "\n",
      "=== 32 ===\n",
      "chunk.text:\n",
      "'সকলেই বুঝিল একটা গল্প আসন্ন হইয়াছে। অমূল্য উঠিয়া দাঁড়াইয়া বলিল, এইবার গাঁজার শ্রাদ্ধ হবে, আমি বাড়ি চললুম—। দরজা পর্যন্ত গিয়া ফিরিয়া দাঁড়াইয়া বলিল, দেখ, তোমরা ভাল চাও তো বরদাকে ক্লাব থেকে তাড়াও বলছি; নইলে শুদ্ধ গাঁজার ধোঁয়ায় এ ক্লাব একদিন বেলুনের মতো শূন্যে উড়ে যাবে, বলিয়া হনহন করিয়া ব…'\n",
      "chunker.contextualize(chunk):\n",
      "'সকলেই বুঝিল একটা গল্প আসন্ন হইয়াছে। অমূল্য উঠিয়া দাঁড়াইয়া বলিল, এইবার গাঁজার শ্রাদ্ধ হবে, আমি বাড়ি চললুম—। দরজা পর্যন্ত গিয়া ফিরিয়া দাঁড়াইয়া বলিল, দেখ, তোমরা ভাল চাও তো বরদাকে ক্লাব থেকে তাড়াও বলছি; নইলে শুদ্ধ গাঁজার ধোঁয়ায় এ ক্লাব একদিন বেলুনের মতো শূন্যে উড়ে যাবে, বলিয়া হনহন করিয়া ব…'\n",
      "\n",
      "=== 33 ===\n",
      "chunk.text:\n",
      "'বরদা একটা নিঃশ্বাস ফেলিয়া বলিল, সত্যি কথা যারা বলে তাদের এমনিই হয়, যীশুকে তো ক্রুশে চড়তে হয়েছিল। যাক, হৃষী, একটা সিগার দাও তো।\\nহৃষী বলিল, সিগার নেই। বিড়ি খাও তো দিতে পারি।\\nবরদা আর একটা দীর্ঘশ্বাস মোচন করিয়া বলিল, থাক, দরকার নেই। দেখি যদি আমার পকেটে—…'\n",
      "chunker.contextualize(chunk):\n",
      "'বরদা একটা নিঃশ্বাস ফেলিয়া বলিল, সত্যি কথা যারা বলে তাদের এমনিই হয়, যীশুকে তো ক্রুশে চড়তে হয়েছিল। যাক, হৃষী, একটা সিগার দাও তো।\\nহৃষী বলিল, সিগার নেই। বিড়ি খাও তো দিতে পারি।\\nবরদা আর একটা দীর্ঘশ্বাস মোচন করিয়া বলিল, থাক, দরকার নেই। দেখি যদি আমার পকেটে—…'\n",
      "\n",
      "=== 34 ===\n",
      "chunk.text:\n",
      "'নিজের পকেট হইতে সিগার বাহির করিয়া সযত্নে ধরাইয়া বরদা বলিতে আরম্ভ করিল,—ব্যাপারটা এতই তুচ্ছ যে বলতে আমারই সঙ্কোচ বোধ হচ্ছে। কিন্তু তোমরা যখন শুনবে বলে ঠিক করেছ তখন বলেই ফেলি। দেখ, শুধু যে মানুষ মরেই ভূত হয় তা নয়, পশুপক্ষী এমন কি কীটপতঙ্গ পর্যন্ত মৃত্যুর পর প্রেতযোনি প্রাপ্ত হয়। তার প্রমাণ আমি এক…'\n",
      "chunker.contextualize(chunk):\n",
      "'নিজের পকেট হইতে সিগার বাহির করিয়া সযত্নে ধরাইয়া বরদা বলিতে আরম্ভ করিল,—ব্যাপারটা এতই তুচ্ছ যে বলতে আমারই সঙ্কোচ বোধ হচ্ছে। কিন্তু তোমরা যখন শুনবে বলে ঠিক করেছ তখন বলেই ফেলি। দেখ, শুধু যে মানুষ মরেই ভূত হয় তা নয়, পশুপক্ষী এমন কি কীটপতঙ্গ পর্যন্ত মৃত্যুর পর প্রেতযোনি প্রাপ্ত হয়। তার প্রমাণ আমি এক…'\n",
      "\n",
      "=== 35 ===\n",
      "chunk.text:\n",
      "'ছুটির সময়, কাজের তাড়া নেই, তাই নিশ্চিন্ত মনে গী-দ্য মোপাসাঁর গল্পগুলো আর একবার পড়ে নিচ্ছি। আমাদের দেশের অকালপক্ক তরুণ সাহিত্যিকেরা দ্য-মোপাসাঁর দোষটি ষোলো আনা নিয়েছেন কিন্তু তার গুণের কড়াক্রান্তিও পাননি। যাকে বলে, বিষের সঙ্গে খোঁজ নেই কুলোপানা চক্কর।…'\n",
      "chunker.contextualize(chunk):\n",
      "'ছুটির সময়, কাজের তাড়া নেই, তাই নিশ্চিন্ত মনে গী-দ্য মোপাসাঁর গল্পগুলো আর একবার পড়ে নিচ্ছি। আমাদের দেশের অকালপক্ক তরুণ সাহিত্যিকেরা দ্য-মোপাসাঁর দোষটি ষোলো আনা নিয়েছেন কিন্তু তার গুণের কড়াক্রান্তিও পাননি। যাকে বলে, বিষের সঙ্গে খোঁজ নেই কুলোপানা চক্কর।…'\n",
      "\n",
      "=== 36 ===\n",
      "chunk.text:\n",
      "'সে যাক। সে-রাত্রে টেবিলে বসে একমনে পড়ছি, কেরাসিনের বাতিটা উজ্জ্বলভাবে জ্বলছে। হঠাৎ এক সময় চোখ তুলে দেখি একটা প্রকাণ্ড টিকটিকি কখন টেবিলের ওপর উঠে পোকা ধরে খাচ্ছে। টিকটিকিটার স্পর্ধা দেখে একেবারে অবাক হয়ে গেলুম।…'\n",
      "chunker.contextualize(chunk):\n",
      "'সে যাক। সে-রাত্রে টেবিলে বসে একমনে পড়ছি, কেরাসিনের বাতিটা উজ্জ্বলভাবে জ্বলছে। হঠাৎ এক সময় চোখ তুলে দেখি একটা প্রকাণ্ড টিকটিকি কখন টেবিলের ওপর উঠে পোকা ধরে খাচ্ছে। টিকটিকিটার স্পর্ধা দেখে একেবারে অবাক হয়ে গেলুম।…'\n",
      "\n",
      "=== 37 ===\n",
      "chunk.text:\n",
      "'জগতে যত রকম জানোয়ার আছে, আমার বিশ্বাস তার মধ্যে সব চেয়ে টিকটিকি বীভৎস। মাকড়শা, আরশোলা, শুঁয়োপোকা, কচ্ছপ, এমন কি ব্যাং পর্যন্ত আমি সহ্য করতে পারি, কিন্তু টিকটিকি! জানো, টিকটিকির এক কানের ভেতর দিয়ে আর এক কান পর্যন্ত পরিষ্কার দেখা যায়? তার ল্যাজ কেটে দিলে ল্যাজটা বিচ্ছিন্ন হয়ে আপনা-আপনি লাফাতে থ…'\n",
      "chunker.contextualize(chunk):\n",
      "'জগতে যত রকম জানোয়ার আছে, আমার বিশ্বাস তার মধ্যে সব চেয়ে টিকটিকি বীভৎস। মাকড়শা, আরশোলা, শুঁয়োপোকা, কচ্ছপ, এমন কি ব্যাং পর্যন্ত আমি সহ্য করতে পারি, কিন্তু টিকটিকি! জানো, টিকটিকির এক কানের ভেতর দিয়ে আর এক কান পর্যন্ত পরিষ্কার দেখা যায়? তার ল্যাজ কেটে দিলে ল্যাজটা বিচ্ছিন্ন হয়ে আপনা-আপনি লাফাতে থ…'\n",
      "\n",
      "=== 38 ===\n",
      "chunk.text:\n",
      "'প্রাণে একটা অহেতুক আতঙ্কের সঞ্চার হয়, পেটের ভেতরটা কেমন যেন খালি হয়ে যায়, শিরদাঁড়া শিরশির করতে থাকে। হাসির কথা মনে হচ্ছে কিন্তু তা নয়; ডিউক অফ্\\u200c ওয়েলিংটনের বেরাল দেখলে ঐ রকম হত।*…'\n",
      "chunker.contextualize(chunk):\n",
      "'প্রাণে একটা অহেতুক আতঙ্কের সঞ্চার হয়, পেটের ভেতরটা কেমন যেন খালি হয়ে যায়, শিরদাঁড়া শিরশির করতে থাকে। হাসির কথা মনে হচ্ছে কিন্তু তা নয়; ডিউক অফ্\\u200c ওয়েলিংটনের বেরাল দেখলে ঐ রকম হত।*…'\n",
      "\n",
      "=== 39 ===\n",
      "chunk.text:\n",
      "'যা হোক, টিকটিকিটাকে আমার টেবিলের ওপর স্বচ্ছন্দে বিচরণ করতে দেখেই আমি তড়াক করে চেয়ার ছেড়ে উঠে দাঁড়ালুম, তারপর দূর থেকে তাকে একটা তাড়া দিলুম। সে ঘাড় বেঁকিয়ে আমার দিকে কটমট করে কিছুক্ষণ চেয়ে থেকে সব দাঁতগুলো বার করে একবার হেসে নিলে।…'\n",
      "chunker.contextualize(chunk):\n",
      "'যা হোক, টিকটিকিটাকে আমার টেবিলের ওপর স্বচ্ছন্দে বিচরণ করতে দেখেই আমি তড়াক করে চেয়ার ছেড়ে উঠে দাঁড়ালুম, তারপর দূর থেকে তাকে একটা তাড়া দিলুম। সে ঘাড় বেঁকিয়ে আমার দিকে কটমট করে কিছুক্ষণ চেয়ে থেকে সব দাঁতগুলো বার করে একবার হেসে নিলে।…'\n",
      "\n",
      "=== 40 ===\n",
      "chunk.text:\n",
      "'তাই তোমাদের জিজ্ঞাসা করছিলুম যে টিকটিকিকে হাসতে দেখেছ কিনা। কুকুরের হাসি, বেরালের হাসি, শিম্পাঞ্জীর হাসি সম্বন্ধে অনেক বৈজ্ঞানিক গবেষণা পড়েছি কিন্তু টিকটিকি সম্বন্ধে এরকম একটা জনশ্রুতি পর্যন্ত কোথাও শুনেছি বলে স্মরণ হয় না।…'\n",
      "chunker.contextualize(chunk):\n",
      "'তাই তোমাদের জিজ্ঞাসা করছিলুম যে টিকটিকিকে হাসতে দেখেছ কিনা। কুকুরের হাসি, বেরালের হাসি, শিম্পাঞ্জীর হাসি সম্বন্ধে অনেক বৈজ্ঞানিক গবেষণা পড়েছি কিন্তু টিকটিকি সম্বন্ধে এরকম একটা জনশ্রুতি পর্যন্ত কোথাও শুনেছি বলে স্মরণ হয় না।…'\n",
      "\n",
      "=== 41 ===\n",
      "chunk.text:\n",
      "'এই টিকটিকিটার মুখে বোধহয় পঞ্চাশ হাজার দাঁত ছিল; তার হাসিটা নিরতিশয় অবজ্ঞার হাসি। সে হাসির অর্থ—দেখেই তো চেয়ার ছেড়ে পালালে, দূর থেকে বীরত্ব ফলাতে লজ্জা করে না।…'\n",
      "chunker.contextualize(chunk):\n",
      "'এই টিকটিকিটার মুখে বোধহয় পঞ্চাশ হাজার দাঁত ছিল; তার হাসিটা নিরতিশয় অবজ্ঞার হাসি। সে হাসির অর্থ—দেখেই তো চেয়ার ছেড়ে পালালে, দূর থেকে বীরত্ব ফলাতে লজ্জা করে না।…'\n",
      "\n",
      "=== 42 ===\n",
      "chunk.text:\n",
      "'বড় রাগ হল। একটা টিকটিকি—হোক না সে ছয় ইঞ্চি লম্বা, আমারই টেবিলের ওপর উঠে আমাকেই কিনা তুচ্ছ-তাচ্ছিল্য করে? ভারী দেখে একটা অভিধান, বোধহয় সেটা ওয়েব্\\u200cস্টারের, হাত বাড়িয়ে তুলে নিয়ে তাই দিয়ে টেবিলের কোণায় দমাস্\\u200c করে এক-ঘা বসিয়ে দিলুম। টিকটিকিটা বিদ্যুতের মতো ফিরে গোল গোল চোখ পাকিয়ে আমার পানে চেয…'\n",
      "chunker.contextualize(chunk):\n",
      "'বড় রাগ হল। একটা টিকটিকি—হোক না সে ছয় ইঞ্চি লম্বা, আমারই টেবিলের ওপর উঠে আমাকেই কিনা তুচ্ছ-তাচ্ছিল্য করে? ভারী দেখে একটা অভিধান, বোধহয় সেটা ওয়েব্\\u200cস্টারের, হাত বাড়িয়ে তুলে নিয়ে তাই দিয়ে টেবিলের কোণায় দমাস্\\u200c করে এক-ঘা বসিয়ে দিলুম। টিকটিকিটা বিদ্যুতের মতো ফিরে গোল গোল চোখ পাকিয়ে আমার পানে চেয…'\n",
      "\n",
      "=== 43 ===\n",
      "chunk.text:\n",
      "'হাজার দাঁত বার করে হাসি।\\nআমার গিন্নী পর্দা ফাঁক করে পাশের ঘর থেকে আমাদের এই শব্দভেদী যুদ্ধ দেখছিলেন, চুড়ির শব্দে চেয়ে দেখি তিনিও নিঃশব্দে হাসছেন। টিকটিকি সম্বন্ধে আমার দুর্বলতা তিনি আগে থেকেই জানতেন।\\nরাগে সর্বাঙ্গ জ্বলে গেল। অভিধানখানা হাতেই ছিল, দু’হাতে সেটা তুলে ধরে দিলুম টিকটিকি লক্ষ্য করে টেবি…'\n",
      "chunker.contextualize(chunk):\n",
      "'হাজার দাঁত বার করে হাসি।\\nআমার গিন্নী পর্দা ফাঁক করে পাশের ঘর থেকে আমাদের এই শব্দভেদী যুদ্ধ দেখছিলেন, চুড়ির শব্দে চেয়ে দেখি তিনিও নিঃশব্দে হাসছেন। টিকটিকি সম্বন্ধে আমার দুর্বলতা তিনি আগে থেকেই জানতেন।\\nরাগে সর্বাঙ্গ জ্বলে গেল। অভিধানখানা হাতেই ছিল, দু’হাতে সেটা তুলে ধরে দিলুম টিকটিকি লক্ষ্য করে টেবি…'\n",
      "\n",
      "=== 44 ===\n",
      "chunk.text:\n",
      "'হুলস্থূল কাণ্ড। ল্যাম্পটা উল্টে গিয়ে ডোম-চিম্\\u200cনি ঝন্\\u200c ঝন্\\u200c শব্দে ভেঙে ঘর অন্ধকার হয়ে গেল। মা রান্নাঘর থেকে শব্দ শুনে রান্না ফেলে ছুটে এলেন; আমার ছোট ভাই পাঁচুর হিন্দুস্থানী মাস্টার বাইরের ঘরে বসে পড়াচ্ছিল, ‘ক্যা হুয়া ক্যা হুয়া’ করে চেঁচাতে লাগল।\\nআমি চিৎকার করে ডাকলুম, রঘুয়া, জল্\\u200cদি একঠো লণ্ঠন …'\n",
      "chunker.contextualize(chunk):\n",
      "'হুলস্থূল কাণ্ড। ল্যাম্পটা উল্টে গিয়ে ডোম-চিম্\\u200cনি ঝন্\\u200c ঝন্\\u200c শব্দে ভেঙে ঘর অন্ধকার হয়ে গেল। মা রান্নাঘর থেকে শব্দ শুনে রান্না ফেলে ছুটে এলেন; আমার ছোট ভাই পাঁচুর হিন্দুস্থানী মাস্টার বাইরের ঘরে বসে পড়াচ্ছিল, ‘ক্যা হুয়া ক্যা হুয়া’ করে চেঁচাতে লাগল।\\nআমি চিৎকার করে ডাকলুম, রঘুয়া, জল্\\u200cদি একঠো লণ্ঠন …'\n",
      "\n",
      "=== 45 ===\n",
      "chunk.text:\n",
      "'অন্ধকারে দাঁড়িয়ে কেবলি ভয় হচ্ছিল পাছে টিকটিকিটা টেবিল থেকে নেমে এসে আমার পা বেয়ে উঠতে আরম্ভ করে!…'\n",
      "chunker.contextualize(chunk):\n",
      "'অন্ধকারে দাঁড়িয়ে কেবলি ভয় হচ্ছিল পাছে টিকটিকিটা টেবিল থেকে নেমে এসে আমার পা বেয়ে উঠতে আরম্ভ করে!…'\n",
      "\n",
      "=== 46 ===\n",
      "chunk.text:\n",
      "'রঘুয়া ঊর্ধ্বশ্বাসে লণ্ঠন নিয়ে হাজির হল। তখন দেখা গেল, ভাঙা কাচের মাঝখানে, বিরাট অভিধানের তলা থেকে টিকটিকির মুণ্ডটা কেবল বেরিয়ে আছে, ধড়টা পিষে ছাতু হয়ে গেছে। মুণ্ডটা একেবারে অক্ষত, যেন অভিধানের তলা থেকে গলা বাড়িয়ে আমাকে দেখছে আর অসংখ্য দাঁত বার করে একটা অত্যন্ত পৈশাচিক হাসি হাসছে!…'\n",
      "chunker.contextualize(chunk):\n",
      "'রঘুয়া ঊর্ধ্বশ্বাসে লণ্ঠন নিয়ে হাজির হল। তখন দেখা গেল, ভাঙা কাচের মাঝখানে, বিরাট অভিধানের তলা থেকে টিকটিকির মুণ্ডটা কেবল বেরিয়ে আছে, ধড়টা পিষে ছাতু হয়ে গেছে। মুণ্ডটা একেবারে অক্ষত, যেন অভিধানের তলা থেকে গলা বাড়িয়ে আমাকে দেখছে আর অসংখ্য দাঁত বার করে একটা অত্যন্ত পৈশাচিক হাসি হাসছে!…'\n",
      "\n",
      "=== 47 ===\n",
      "chunk.text:\n",
      "'আমার পা থেকে মাথা পর্যন্ত দু-চার বার শিউরে উঠল। বীভৎস মৃত দেহটাকে ফেলে দেবার হুকুম দিয়ে বিছানায় গিয়ে শুয়ে পড়লুম। সে রাত্রে আর ভাত খাবার রুচি হল না।\\nসমস্ত রাত্রি ঘুমের মধ্যে কতকগুলো দুঃস্বপ্ন ঘুরে ঘুরে বেড়াতে লাগল, সেগুলোকে চেতনা দিয়ে ধরাও যায় না অথচ কিছু নয় বলে উড়িয়ে দেওয়াও চলে না। সকালে…'\n",
      "chunker.contextualize(chunk):\n",
      "'আমার পা থেকে মাথা পর্যন্ত দু-চার বার শিউরে উঠল। বীভৎস মৃত দেহটাকে ফেলে দেবার হুকুম দিয়ে বিছানায় গিয়ে শুয়ে পড়লুম। সে রাত্রে আর ভাত খাবার রুচি হল না।\\nসমস্ত রাত্রি ঘুমের মধ্যে কতকগুলো দুঃস্বপ্ন ঘুরে ঘুরে বেড়াতে লাগল, সেগুলোকে চেতনা দিয়ে ধরাও যায় না অথচ কিছু নয় বলে উড়িয়ে দেওয়াও চলে না। সকালে…'\n",
      "\n",
      "=== 48 ===\n",
      "chunk.text:\n",
      "'বিরস মনে বাইরের ঘরে বসে চা খাচ্ছি, হঠাৎ চোখ পড়ল টেবিলের ওপর। দেখি, দু’টি ছোট ছোট ডিম পাশাপাশি রাখা রয়েছে। দেখতে ঠিক খড়ি-মাখানো করমচার মতো। ইতিপূর্বে টিকটিকির ডিম কখনো দেখিনি কিন্তু বুঝতে বাকী রইল না যে এ দু’টি সেই বস্তু। হাঁকাহাঁকি করে চাকরদের জেরা করলুম, কে এখানে ডিম রেখেছে? কিন্তু কেউ কিছু বলতে…'\n",
      "chunker.contextualize(chunk):\n",
      "'বিরস মনে বাইরের ঘরে বসে চা খাচ্ছি, হঠাৎ চোখ পড়ল টেবিলের ওপর। দেখি, দু’টি ছোট ছোট ডিম পাশাপাশি রাখা রয়েছে। দেখতে ঠিক খড়ি-মাখানো করমচার মতো। ইতিপূর্বে টিকটিকির ডিম কখনো দেখিনি কিন্তু বুঝতে বাকী রইল না যে এ দু’টি সেই বস্তু। হাঁকাহাঁকি করে চাকরদের জেরা করলুম, কে এখানে ডিম রেখেছে? কিন্তু কেউ কিছু বলতে…'\n",
      "\n",
      "=== 49 ===\n",
      "chunk.text:\n",
      "'তাদের কাছ থেকে কোনও কথা বার করা গেল না। তখন পেঁচোর ওপর ঘোর সন্দেহ হল। পেঁচোকে নিয়ে পড়লুম, সে শেষ পর্যন্ত কেঁদে ফেললে, কিন্তু অপরাধ স্বীকার করলে না। শাস্তি-স্বরূপ তাকে ডিম দুটো বাইরে ফেলে দেবার হুকুম দিলুম।…'\n",
      "chunker.contextualize(chunk):\n",
      "'তাদের কাছ থেকে কোনও কথা বার করা গেল না। তখন পেঁচোর ওপর ঘোর সন্দেহ হল। পেঁচোকে নিয়ে পড়লুম, সে শেষ পর্যন্ত কেঁদে ফেললে, কিন্তু অপরাধ স্বীকার করলে না। শাস্তি-স্বরূপ তাকে ডিম দুটো বাইরে ফেলে দেবার হুকুম দিলুম।…'\n",
      "\n",
      "=== 50 ===\n",
      "chunk.text:\n",
      "'এ-যে আমাকে ভয় দেখাবার উদ্দেশ্যে কোনও লোকের বজ্জাতি এই কথাই গোড়া থেকে আমার মনে বদ্ধমূল হয়ে গিয়েছিল। কিন্তু কিছুক্ষণ পরে চাবি-দেয়া দেরাজ খুলেও যখন দেখলুম তার মধ্যে শাদা শাদা ক্ষুদ্রাকৃতি দু’টি ডিম বিরাজ করছে তখন কেমন ধোঁকা লাগল। তাইতো! এখানে ডিম কে রাখে?…'\n",
      "chunker.contextualize(chunk):\n",
      "'এ-যে আমাকে ভয় দেখাবার উদ্দেশ্যে কোনও লোকের বজ্জাতি এই কথাই গোড়া থেকে আমার মনে বদ্ধমূল হয়ে গিয়েছিল। কিন্তু কিছুক্ষণ পরে চাবি-দেয়া দেরাজ খুলেও যখন দেখলুম তার মধ্যে শাদা শাদা ক্ষুদ্রাকৃতি দু’টি ডিম বিরাজ করছে তখন কেমন ধোঁকা লাগল। তাইতো! এখানে ডিম কে রাখে?…'\n",
      "\n",
      "=== 51 ===\n",
      "chunk.text:\n",
      "'তারপর দেখতে দেখতে বাড়িময় যেন টিকটিকির ডিমের হরির লুঠ পড়ে গেল। যেদিকে তাকাই, যেখানে হাত দিই, সেইখানেই দু’টি করে ডিম। হঠাৎ যেন জগতের যত স্ত্রী-টিকটিকি সবাই সঙ্কল্প করে আমার চারিপাশে ডিম পাড়তে শুরু করে দিয়েছে।…'\n",
      "chunker.contextualize(chunk):\n",
      "'তারপর দেখতে দেখতে বাড়িময় যেন টিকটিকির ডিমের হরির লুঠ পড়ে গেল। যেদিকে তাকাই, যেখানে হাত দিই, সেইখানেই দু’টি করে ডিম। হঠাৎ যেন জগতের যত স্ত্রী-টিকটিকি সবাই সঙ্কল্প করে আমার চারিপাশে ডিম পাড়তে শুরু করে দিয়েছে।…'\n",
      "\n",
      "=== 52 ===\n",
      "chunk.text:\n",
      "'এমনি ব্যাপার দু’দিন ধরে চলল। মন এমন সন্ত্রস্ত এবং বিভ্রান্ত হয়ে উঠল যে, সহসা কোনও একটা জায়গায় হাত দিতে পর্যন্ত ভয় করতে লাগল, পাছে সেখান থেকে টিকটিকির ডিম বেরিয়ে পড়ে।…'\n",
      "chunker.contextualize(chunk):\n",
      "'এমনি ব্যাপার দু’দিন ধরে চলল। মন এমন সন্ত্রস্ত এবং বিভ্রান্ত হয়ে উঠল যে, সহসা কোনও একটা জায়গায় হাত দিতে পর্যন্ত ভয় করতে লাগল, পাছে সেখান থেকে টিকটিকির ডিম বেরিয়ে পড়ে।…'\n",
      "\n",
      "=== 53 ===\n",
      "chunk.text:\n",
      "'কিন্তু সাধারণ পাঁচজনের কাছে এ ব্যাপার এতই অকিঞ্চিত্বর যে মনের কথা কাউকে খোলসা করে বলাও যায় না। টিকটিকির ডিম দেখেছে তার আর হয়েছে কি? এ প্রশ্ন করলে তার সদুত্তর দেওয়া কঠিন। আমিও নিজেকে বোঝাবার চেষ্টা করলুম, কিন্তু বিশেষ ফল হল না। বরঞ্চ সর্বদা মনের মধ্যে এই কথাটাই আনাগোনা করতে লাগল যে, এ ঠিক নয়, স্ব…'\n",
      "chunker.contextualize(chunk):\n",
      "'কিন্তু সাধারণ পাঁচজনের কাছে এ ব্যাপার এতই অকিঞ্চিত্বর যে মনের কথা কাউকে খোলসা করে বলাও যায় না। টিকটিকির ডিম দেখেছে তার আর হয়েছে কি? এ প্রশ্ন করলে তার সদুত্তর দেওয়া কঠিন। আমিও নিজেকে বোঝাবার চেষ্টা করলুম, কিন্তু বিশেষ ফল হল না। বরঞ্চ সর্বদা মনের মধ্যে এই কথাটাই আনাগোনা করতে লাগল যে, এ ঠিক নয়, স্ব…'\n",
      "\n",
      "=== 54 ===\n",
      "chunk.text:\n",
      "'কিন্তু একটা টিকটিকিকে অপঘাত মেরে ফেলার ফলেই এই সমস্ত ব্যাপার ঘটছে সহজ বুদ্ধিতে একথাও মেনে নেওয়া যায় না। তবে কি এ? অনেক ভেবেচিন্তে স্থির করলুম, সম্ভবত যে টিকটিকিকে সেদিন অত্যন্ত অন্যায়ভাবে বধ করেছিলুম তারই গর্ভবতী বিধবা বিরহ যন্ত্রণায় অস্থির হয়ে কেবলি ডিম পেড়ে বেড়াচ্ছে। এছাড়া আর যে কি হতে পার…'\n",
      "chunker.contextualize(chunk):\n",
      "'কিন্তু একটা টিকটিকিকে অপঘাত মেরে ফেলার ফলেই এই সমস্ত ব্যাপার ঘটছে সহজ বুদ্ধিতে একথাও মেনে নেওয়া যায় না। তবে কি এ? অনেক ভেবেচিন্তে স্থির করলুম, সম্ভবত যে টিকটিকিকে সেদিন অত্যন্ত অন্যায়ভাবে বধ করেছিলুম তারই গর্ভবতী বিধবা বিরহ যন্ত্রণায় অস্থির হয়ে কেবলি ডিম পেড়ে বেড়াচ্ছে। এছাড়া আর যে কি হতে পার…'\n",
      "\n",
      "=== 55 ===\n",
      "chunk.text:\n",
      "'বাড়িতে যখন মন অত্যন্ত বিভ্রান্ত হয়ে উঠেছে, তখন একদিন সন্ধ্যাবেলা ভাবলুম—যাই ক্লাবে। ছুটির সময়, তোমরা কেউ এখানে ছিলে না; ক্লাব একরকম বন্ধ; তবু চাকরটাকে দিয়ে ঘর খুলিয়ে আলো জ্বালিয়ে এই ঘরেই এসে বসলুম। টেবিলের উপর পাতলা একপুরু ধুলো পড়েছে; অন্যমনস্কভাবে একটা সিগারেট ধরিয়ে দেশলাই-এর কাঠিটা অ্যাশ্\\u200c…'\n",
      "chunker.contextualize(chunk):\n",
      "'বাড়িতে যখন মন অত্যন্ত বিভ্রান্ত হয়ে উঠেছে, তখন একদিন সন্ধ্যাবেলা ভাবলুম—যাই ক্লাবে। ছুটির সময়, তোমরা কেউ এখানে ছিলে না; ক্লাব একরকম বন্ধ; তবু চাকরটাকে দিয়ে ঘর খুলিয়ে আলো জ্বালিয়ে এই ঘরেই এসে বসলুম। টেবিলের উপর পাতলা একপুরু ধুলো পড়েছে; অন্যমনস্কভাবে একটা সিগারেট ধরিয়ে দেশলাই-এর কাঠিটা অ্যাশ্\\u200c…'\n",
      "\n",
      "=== 56 ===\n",
      "chunk.text:\n",
      "'দু’টি ডিম।\\nতৎক্ষণাৎ উঠে বাড়ি চলে এলুম।\\nমা আমার মুখের দিকে তাকিয়ে বললেন, হাঁ রে, ক’দিন থেকে তোর মুখখানা কেমন শুকনো শুকনো দেখছি—শরীর কি ভাল নেই?\\nআমি বললুম, হ্যাঁ—ঐ একরকম; বলে বাইরের ঘরে গিয়ে বসলুম।…'\n",
      "chunker.contextualize(chunk):\n",
      "'দু’টি ডিম।\\nতৎক্ষণাৎ উঠে বাড়ি চলে এলুম।\\nমা আমার মুখের দিকে তাকিয়ে বললেন, হাঁ রে, ক’দিন থেকে তোর মুখখানা কেমন শুকনো শুকনো দেখছি—শরীর কি ভাল নেই?\\nআমি বললুম, হ্যাঁ—ঐ একরকম; বলে বাইরের ঘরে গিয়ে বসলুম।…'\n",
      "\n",
      "=== 57 ===\n",
      "chunk.text:\n",
      "'ব্যাপার যে ক্রমে ঘনীভূত হয়ে আসছে তাতে আর সন্দেহ নেই। টিকটিকি-বধূর অতি-প্রসবিতা বলে উড়িয়ে দেওয়া আর অসম্ভব। এ আর কিছু নয়—ভূত, ডিমভূত! সেই প্রতিহিংসাপরায়ণ টিকটিকিটা প্রেতযোনি প্রাপ্ত হয়ে আমাকে ভয় দেখাচ্ছে; এবং ঐ ডিম ছাড়া আর কিছুতেই যে আমি ভয় পাবার লোক নয়, তা সে তার ভৌতিক বুদ্ধি দিয়ে ঠিক বুঝ…'\n",
      "chunker.contextualize(chunk):\n",
      "'ব্যাপার যে ক্রমে ঘনীভূত হয়ে আসছে তাতে আর সন্দেহ নেই। টিকটিকি-বধূর অতি-প্রসবিতা বলে উড়িয়ে দেওয়া আর অসম্ভব। এ আর কিছু নয়—ভূত, ডিমভূত! সেই প্রতিহিংসাপরায়ণ টিকটিকিটা প্রেতযোনি প্রাপ্ত হয়ে আমাকে ভয় দেখাচ্ছে; এবং ঐ ডিম ছাড়া আর কিছুতেই যে আমি ভয় পাবার লোক নয়, তা সে তার ভৌতিক বুদ্ধি দিয়ে ঠিক বুঝ…'\n",
      "\n",
      "=== 58 ===\n",
      "chunk.text:\n",
      "'ইতর প্রাণীর ওপর কেন যে আমাদের শাস্ত্রে দয়া-দাক্ষিণ্য দেখাতে আদেশ করে গেছেন এবং কেন যে বুদ্ধদেব সামান্য ছাগলের প্রাণ বাঁচাবার জন্যে নিজের জীবন বিসর্জন দিতে চেয়েছিলেন, আমার দৃষ্টান্ত দেখেও সে জ্ঞান যদি তোমাদের না হয়ে থাকে, তাহলে তোমাদের অদৃষ্টে কুম্ভীপাক নরক অনিবার্য। আসল কথা, আমার মনে ঘোর অনুতাপ উ…'\n",
      "chunker.contextualize(chunk):\n",
      "'ইতর প্রাণীর ওপর কেন যে আমাদের শাস্ত্রে দয়া-দাক্ষিণ্য দেখাতে আদেশ করে গেছেন এবং কেন যে বুদ্ধদেব সামান্য ছাগলের প্রাণ বাঁচাবার জন্যে নিজের জীবন বিসর্জন দিতে চেয়েছিলেন, আমার দৃষ্টান্ত দেখেও সে জ্ঞান যদি তোমাদের না হয়ে থাকে, তাহলে তোমাদের অদৃষ্টে কুম্ভীপাক নরক অনিবার্য। আসল কথা, আমার মনে ঘোর অনুতাপ উ…'\n",
      "\n",
      "=== 59 ===\n",
      "chunk.text:\n",
      "'গতাসু টিকটিকিকে উদ্দেশ্য করে কেবলি বলছিলুম, হে প্রেত! হে নিরালম্ব বায়ুভূত! যথেষ্ট হয়েছে, এইবার তোমার ডিম্ব সম্বরণ কর!\\nকিন্তু সম্বরণ করে কে? রাত্রে খেতে বসে ভাত ভেঙেই দেখলুম ভাতের মধ্যে দু’টি সুসিদ্ধ ডিম্ব! কম্পিত কলেবরে আসন ছেড়ে উঠে দাঁড়ালুম। মা বললেন, কি হল, উঠলি যে?\\nশরীরের প্রবল কম্পন দমন করে …'\n",
      "chunker.contextualize(chunk):\n",
      "'গতাসু টিকটিকিকে উদ্দেশ্য করে কেবলি বলছিলুম, হে প্রেত! হে নিরালম্ব বায়ুভূত! যথেষ্ট হয়েছে, এইবার তোমার ডিম্ব সম্বরণ কর!\\nকিন্তু সম্বরণ করে কে? রাত্রে খেতে বসে ভাত ভেঙেই দেখলুম ভাতের মধ্যে দু’টি সুসিদ্ধ ডিম্ব! কম্পিত কলেবরে আসন ছেড়ে উঠে দাঁড়ালুম। মা বললেন, কি হল, উঠলি যে?\\nশরীরের প্রবল কম্পন দমন করে …'\n",
      "\n",
      "=== 60 ===\n",
      "chunk.text:\n",
      "'বিছানায় শুয়ে শুনতে পেলুম মা বধূকে তিরস্কার করছেন, বোকা মেয়ে, করমচা কখনো ভাতে দিতে আছে! ওর যা ঘেন্নাটে স্বভাব, দেখেই হয়তো না খেয়ে উঠে গেল।\\nরাত্রে এক অপূর্ব স্বপ্ন দেখলুম। অপূর্ব এই হিসাবে যে, তার পূর্বে কখনো অমন স্বপ্ন দেখিনি, এবং পরেও আর দেখবার ইচ্ছে নেই।…'\n",
      "chunker.contextualize(chunk):\n",
      "'বিছানায় শুয়ে শুনতে পেলুম মা বধূকে তিরস্কার করছেন, বোকা মেয়ে, করমচা কখনো ভাতে দিতে আছে! ওর যা ঘেন্নাটে স্বভাব, দেখেই হয়তো না খেয়ে উঠে গেল।\\nরাত্রে এক অপূর্ব স্বপ্ন দেখলুম। অপূর্ব এই হিসাবে যে, তার পূর্বে কখনো অমন স্বপ্ন দেখিনি, এবং পরেও আর দেখবার ইচ্ছে নেই।…'\n",
      "\n",
      "=== 61 ===\n",
      "chunk.text:\n",
      "'স্বপ্ন দেখলুম যেন অত্যন্ত ক্লান্ত হয়ে বিছানায় শুয়ে পড়েছি। শোবামাত্র বুঝতে পারলুম যে, বিছানায় চাদর পাতা নেই—তার বদলে আগাগোড়া টিকটিকির ডিম দিয়ে ঢাকা। আমার শরীরের চাপে ডিমগুলো ভেঙে যেতে লাগল আর তার ভেতর থেকে কালো কালো কঙ্কালসার সরীসৃপের মতো লক্ষ লক্ষ টিকটিকির ছানা বেরিয়ে আমার সর্বাঙ্গে চলে বেড়…'\n",
      "chunker.contextualize(chunk):\n",
      "'স্বপ্ন দেখলুম যেন অত্যন্ত ক্লান্ত হয়ে বিছানায় শুয়ে পড়েছি। শোবামাত্র বুঝতে পারলুম যে, বিছানায় চাদর পাতা নেই—তার বদলে আগাগোড়া টিকটিকির ডিম দিয়ে ঢাকা। আমার শরীরের চাপে ডিমগুলো ভেঙে যেতে লাগল আর তার ভেতর থেকে কালো কালো কঙ্কালসার সরীসৃপের মতো লক্ষ লক্ষ টিকটিকির ছানা বেরিয়ে আমার সর্বাঙ্গে চলে বেড়…'\n",
      "\n",
      "=== 62 ===\n",
      "chunk.text:\n",
      "'পালানো যায় না। সেইখানে পড়ে গোঁ গোঁ করতে লাগলুম আর সেই ধেড়ে টিকটিকিটা—যাকে আমি মেরে ফেলেছিলুম—আমার ঘাড় বেয়ে নাকের ওপর উঠে বসে একদৃষ্টে আমার পানে চেয়ে রইল।\\nগিন্নীর ঠেলায় ঘুম ভেঙে দেখলুম, গা দিয়ে ঘাম ঝরছে এবং তখনো যেন টিকটিকির বীভৎস ছানাগুলো গা-ময় কিলবিল করে বেড়াচ্ছে।…'\n",
      "chunker.contextualize(chunk):\n",
      "'পালানো যায় না। সেইখানে পড়ে গোঁ গোঁ করতে লাগলুম আর সেই ধেড়ে টিকটিকিটা—যাকে আমি মেরে ফেলেছিলুম—আমার ঘাড় বেয়ে নাকের ওপর উঠে বসে একদৃষ্টে আমার পানে চেয়ে রইল।\\nগিন্নীর ঠেলায় ঘুম ভেঙে দেখলুম, গা দিয়ে ঘাম ঝরছে এবং তখনো যেন টিকটিকির বীভৎস ছানাগুলো গা-ময় কিলবিল করে বেড়াচ্ছে।…'\n",
      "\n",
      "=== 63 ===\n",
      "chunk.text:\n",
      "'ভাই, অনেক রকম দুঃস্বপ্ন আজ পর্যন্ত দেখেছি এবং আরো অনেক রকম দেখব সন্দেহ নেই। কিন্তু ভগবানের কাছে প্রার্থনা, এমনটি যেন আর দেখতে না হয়।…'\n",
      "chunker.contextualize(chunk):\n",
      "'ভাই, অনেক রকম দুঃস্বপ্ন আজ পর্যন্ত দেখেছি এবং আরো অনেক রকম দেখব সন্দেহ নেই। কিন্তু ভগবানের কাছে প্রার্থনা, এমনটি যেন আর দেখতে না হয়।…'\n",
      "\n",
      "=== 64 ===\n",
      "chunk.text:\n",
      "'ভয়ের যে বস্তুটা চোখ দিয়ে দেখা যায় না, যার ভয়ানকত্ব যুক্তির দ্বারা খণ্ডন করা যায় না এবং যার হাত থেকে উদ্ধার পাবার কোনো জানিত উপায় নেই, সেই বস্তুই বোধ করি জগতে সব চেয়ে ভয়ঙ্কর। ভূতের ভয় ঐ জাতীয়। তাই প্রাণের মধ্যে আমার বিভীষিকা যতই বেড়ে চলল তার হাত থেকে পরিত্রাণ পাবার পন্থাটাও আমার কাছে তেমনি…'\n",
      "chunker.contextualize(chunk):\n",
      "'ভয়ের যে বস্তুটা চোখ দিয়ে দেখা যায় না, যার ভয়ানকত্ব যুক্তির দ্বারা খণ্ডন করা যায় না এবং যার হাত থেকে উদ্ধার পাবার কোনো জানিত উপায় নেই, সেই বস্তুই বোধ করি জগতে সব চেয়ে ভয়ঙ্কর। ভূতের ভয় ঐ জাতীয়। তাই প্রাণের মধ্যে আমার বিভীষিকা যতই বেড়ে চলল তার হাত থেকে পরিত্রাণ পাবার পন্থাটাও আমার কাছে তেমনি…'\n",
      "\n",
      "=== 65 ===\n",
      "chunk.text:\n",
      "'কিছু কিনারা পেলুম না।\\nএই রকম যখন মনের অবস্থা তখন একদিন ডাকে একখানা চিঠি এল। শুভেন্দু গয়া থেকে লিখেছে; চিঠি এমন কিছু নয়, “তুমি কেমন আছ, আমি ভাল আছি” গোছের, কিন্তু হঠাৎ যেন আমার দিব্যদৃষ্টি খুলে গেল। মনে হল এ চিঠি নয়—দৈববাণী।\\nতৎক্ষণাৎ শুভেন্দুকে ‘তার’ করে দিলুম। আজই যাচ্ছি।…'\n",
      "chunker.contextualize(chunk):\n",
      "'কিছু কিনারা পেলুম না।\\nএই রকম যখন মনের অবস্থা তখন একদিন ডাকে একখানা চিঠি এল। শুভেন্দু গয়া থেকে লিখেছে; চিঠি এমন কিছু নয়, “তুমি কেমন আছ, আমি ভাল আছি” গোছের, কিন্তু হঠাৎ যেন আমার দিব্যদৃষ্টি খুলে গেল। মনে হল এ চিঠি নয়—দৈববাণী।\\nতৎক্ষণাৎ শুভেন্দুকে ‘তার’ করে দিলুম। আজই যাচ্ছি।…'\n",
      "\n",
      "=== 66 ===\n",
      "chunk.text:\n",
      "'তারপর যথাকালে গয়ায় পৌঁছে টিকটিকির প্রেতাত্মার সদগতি সঙ্কল্প করে পিণ্ডি দিলুম। গয়াতে আজ পর্যন্ত টিকটিকির পিণ্ডদান কেউ করেছে কি না জানি না, কিন্তু সেই থেকে আমার ওপর আর কোনও উপদ্রব হয়নি।\\nসেই মায়ামুক্ত জীবাত্মা বোধ করি এখন দিব্যলোকে বৈকুণ্ঠের দেয়ালে উঠে পোকা ধরে ধরে খাচ্ছেন!\\n১৩৩৬\\n- বরদা ভুল করিয়া…'\n",
      "chunker.contextualize(chunk):\n",
      "'তারপর যথাকালে গয়ায় পৌঁছে টিকটিকির প্রেতাত্মার সদগতি সঙ্কল্প করে পিণ্ডি দিলুম। গয়াতে আজ পর্যন্ত টিকটিকির পিণ্ডদান কেউ করেছে কি না জানি না, কিন্তু সেই থেকে আমার ওপর আর কোনও উপদ্রব হয়নি।\\nসেই মায়ামুক্ত জীবাত্মা বোধ করি এখন দিব্যলোকে বৈকুণ্ঠের দেয়ালে উঠে পোকা ধরে ধরে খাচ্ছেন!\\n১৩৩৬\\n- বরদা ভুল করিয়া…'\n",
      "\n",
      "=== 67 ===\n",
      "chunk.text:\n",
      "'এটা বরদার গল্প হইলে কখনই বিশ্বাস করিতাম না। কিন্তু দুঃখের সহিত বলিতে হইতেছে যে, ব্যাপারটা আমার চোখের সম্মুখেই ঘটিয়াছিল, সুতরাং হাসিয়া উড়াইয়া দিবার আর পথ নাই। যদিও বরদা মূলত এই ঘটনার সহিত ঘনিষ্ঠভাবে জড়িত ছিল, তবু এত বড় ভোজবাজি তাহার মতো মিথ্যেবাদীর পক্ষেও অসম্ভব বলিয়া মনে করি।…'\n",
      "chunker.contextualize(chunk):\n",
      "'এটা বরদার গল্প হইলে কখনই বিশ্বাস করিতাম না। কিন্তু দুঃখের সহিত বলিতে হইতেছে যে, ব্যাপারটা আমার চোখের সম্মুখেই ঘটিয়াছিল, সুতরাং হাসিয়া উড়াইয়া দিবার আর পথ নাই। যদিও বরদা মূলত এই ঘটনার সহিত ঘনিষ্ঠভাবে জড়িত ছিল, তবু এত বড় ভোজবাজি তাহার মতো মিথ্যেবাদীর পক্ষেও অসম্ভব বলিয়া মনে করি।…'\n",
      "\n",
      "=== 68 ===\n",
      "chunk.text:\n",
      "'গত শীতকালে বরদার মস্তকে হঠাৎ বিষয়বুদ্ধি চাগাড় দিয়া উঠিয়াছিল। শহর হইতে মাইল পনের দূরে—বেহারের গ্রাম্য ভাষায় যাহাকে দেহাত বলে—সেই অজ পাড়াগাঁয়ে বরদার কিছু ধান জমি ও কয়েক ঘর কায়েমী প্রজা ছিল। এতকাল ফৌজদার সিং নামক জনৈক শিশোদীয়বংশীয় রাজপুত এই সকল বিষয়সম্পত্তির তত্ত্বাবধানে নিযুক্ত ছিলেন; কিন্…'\n",
      "chunker.contextualize(chunk):\n",
      "'গত শীতকালে বরদার মস্তকে হঠাৎ বিষয়বুদ্ধি চাগাড় দিয়া উঠিয়াছিল। শহর হইতে মাইল পনের দূরে—বেহারের গ্রাম্য ভাষায় যাহাকে দেহাত বলে—সেই অজ পাড়াগাঁয়ে বরদার কিছু ধান জমি ও কয়েক ঘর কায়েমী প্রজা ছিল। এতকাল ফৌজদার সিং নামক জনৈক শিশোদীয়বংশীয় রাজপুত এই সকল বিষয়সম্পত্তির তত্ত্বাবধানে নিযুক্ত ছিলেন; কিন্…'\n",
      "\n",
      "=== 69 ===\n",
      "chunk.text:\n",
      "'দুর্জয় শীতে ধান কাটাইবার জন্য প্রস্থান করিল। দশদিনের মধ্যে তাহার আর কোনও খবরই পাওয়া গেল না।…'\n",
      "chunker.contextualize(chunk):\n",
      "'দুর্জয় শীতে ধান কাটাইবার জন্য প্রস্থান করিল। দশদিনের মধ্যে তাহার আর কোনও খবরই পাওয়া গেল না।…'\n",
      "\n",
      "=== 70 ===\n",
      "chunk.text:\n",
      "'প্রত্যহ সন্ধ্যার পর ক্লাবে বসিয়া অনর্গল মিথ্যা কথা না বলিলে যাহার স্বাস্থ্য খারাপ হইয়া যায়, সঙ্গীহীন পাড়াগাঁয়ে তাহার এই দীর্ঘ প্রবাস কি করিয়া কাটিতেছে, এই প্রশ্ন আমাদের উদ্বিগ্ন করিয়া তুলিল। সেখানে বরদা কাহাকে আষাঢ়ে গল্প শুনাইতেছে? আমরা ভাবিয়াছিলাম, দু’দিন যাইতে না যাইতেই সে পলাইয়া আসিবে—ক…'\n",
      "chunker.contextualize(chunk):\n",
      "'প্রত্যহ সন্ধ্যার পর ক্লাবে বসিয়া অনর্গল মিথ্যা কথা না বলিলে যাহার স্বাস্থ্য খারাপ হইয়া যায়, সঙ্গীহীন পাড়াগাঁয়ে তাহার এই দীর্ঘ প্রবাস কি করিয়া কাটিতেছে, এই প্রশ্ন আমাদের উদ্বিগ্ন করিয়া তুলিল। সেখানে বরদা কাহাকে আষাঢ়ে গল্প শুনাইতেছে? আমরা ভাবিয়াছিলাম, দু’দিন যাইতে না যাইতেই সে পলাইয়া আসিবে—ক…'\n",
      "\n",
      "=== 71 ===\n",
      "chunk.text:\n",
      "'বাড়িতে অনুসন্ধান করিয়া জানা গেল, বরদা নিজের কাছারি বাড়িতে পরম সুখে কালাতিপাত করিতেছে, শীঘ্র গৃহে ফিরিবার ইচ্ছা নাই; ধান কাটানো যে কিরূপ আনন্দদায়ক কার্য তাহাই উচ্ছ্বসিত ভাষায় বর্ণনা করিয়া লম্বা চিঠি লিখিয়াছে। শুনিয়া আমরা স্তম্ভিত হইয়া গেলাম।…'\n",
      "chunker.contextualize(chunk):\n",
      "'বাড়িতে অনুসন্ধান করিয়া জানা গেল, বরদা নিজের কাছারি বাড়িতে পরম সুখে কালাতিপাত করিতেছে, শীঘ্র গৃহে ফিরিবার ইচ্ছা নাই; ধান কাটানো যে কিরূপ আনন্দদায়ক কার্য তাহাই উচ্ছ্বসিত ভাষায় বর্ণনা করিয়া লম্বা চিঠি লিখিয়াছে। শুনিয়া আমরা স্তম্ভিত হইয়া গেলাম।…'\n",
      "\n",
      "=== 72 ===\n",
      "chunk.text:\n",
      "'অমূল্য বলিল, ‘ধান-টান সব মিছে কথা, যা হয়েছে আমি বুঝেছি। বরদার বৌ ওকে বাড়ি থেকে তাড়িয়ে দিয়েছে। বঙ্গ-মহিলা হলেও ধৈর্যের একটা সীমা আছে তো।’…'\n",
      "chunker.contextualize(chunk):\n",
      "'অমূল্য বলিল, ‘ধান-টান সব মিছে কথা, যা হয়েছে আমি বুঝেছি। বরদার বৌ ওকে বাড়ি থেকে তাড়িয়ে দিয়েছে। বঙ্গ-মহিলা হলেও ধৈর্যের একটা সীমা আছে তো।’…'\n",
      "\n",
      "=== 73 ===\n",
      "chunk.text:\n",
      "'তা সে কারণ যাহাই হোক, বরদার অভাবে ক্লাবের সান্ধ্য অধিবেশনগুলি নিঝুম ও ম্রিয়মাণ হইয়া পড়িতে লাগিল। বরদা যতই মিছে কথা বলুক, সে একজন সত্যকার মজলিশি লোক তা ক্রমশ সকলেই হৃদয়ঙ্গম করিতে লাগিলাম; এমন কি অমূল্যকে দেখিয়াও মনে হইতে লাগিল, তর্ক করিবার একজন প্রতিপক্ষের অভাবে সে ভিতরে ভিতরে বিশেষ মুড়িয়া পড়…'\n",
      "chunker.contextualize(chunk):\n",
      "'তা সে কারণ যাহাই হোক, বরদার অভাবে ক্লাবের সান্ধ্য অধিবেশনগুলি নিঝুম ও ম্রিয়মাণ হইয়া পড়িতে লাগিল। বরদা যতই মিছে কথা বলুক, সে একজন সত্যকার মজলিশি লোক তা ক্রমশ সকলেই হৃদয়ঙ্গম করিতে লাগিলাম; এমন কি অমূল্যকে দেখিয়াও মনে হইতে লাগিল, তর্ক করিবার একজন প্রতিপক্ষের অভাবে সে ভিতরে ভিতরে বিশেষ মুড়িয়া পড়…'\n",
      "\n",
      "=== 74 ===\n",
      "chunk.text:\n",
      "'অবশেষে চৌদ্দ দিনের দিন বরদার চিঠি আসিল; তাহার বাড়ির চাকর রঘুয়া চিঠিখানা ক্লাবে দিয়া গেল। ক্লাবের সভ্যগণকে সম্বোধন করিয়া বরদা চিঠি দিয়াছে; পাঠ করিয়া তাহার দীর্ঘ অজ্ঞাতবাসের যথার্থ কারণ অজ্ঞাত রহিল না। বরদা লিখিয়াছে—…'\n",
      "chunker.contextualize(chunk):\n",
      "'অবশেষে চৌদ্দ দিনের দিন বরদার চিঠি আসিল; তাহার বাড়ির চাকর রঘুয়া চিঠিখানা ক্লাবে দিয়া গেল। ক্লাবের সভ্যগণকে সম্বোধন করিয়া বরদা চিঠি দিয়াছে; পাঠ করিয়া তাহার দীর্ঘ অজ্ঞাতবাসের যথার্থ কারণ অজ্ঞাত রহিল না। বরদা লিখিয়াছে—…'\n",
      "\n",
      "=== 75 ===\n",
      "chunk.text:\n",
      "'বন্ধুগণ, তোমরা প্রেতযোনিতে বিশ্বাস কর না; আমি কাল্পনিক ভূতের গল্প বানাইয়া বলি এরূপ ইঙ্গিতও মাঝে মাঝে করিয়া থাক। তোমাদের মতো অন্ধ নাস্তিকের বিশ্বাস জন্মাইতে হইলে প্রত্যক্ষ প্রমাণ চাই; তাই জিজ্ঞাসা করিতেছি, নিজের চোখে ভূত দেখিতে চাও? স্বকর্ণে ভূতের কথা শুনিতে চাও? ভূতের সহিত করকম্পন করিতে চাও?…'\n",
      "chunker.contextualize(chunk):\n",
      "'বন্ধুগণ, তোমরা প্রেতযোনিতে বিশ্বাস কর না; আমি কাল্পনিক ভূতের গল্প বানাইয়া বলি এরূপ ইঙ্গিতও মাঝে মাঝে করিয়া থাক। তোমাদের মতো অন্ধ নাস্তিকের বিশ্বাস জন্মাইতে হইলে প্রত্যক্ষ প্রমাণ চাই; তাই জিজ্ঞাসা করিতেছি, নিজের চোখে ভূত দেখিতে চাও? স্বকর্ণে ভূতের কথা শুনিতে চাও? ভূতের সহিত করকম্পন করিতে চাও?…'\n",
      "\n",
      "=== 76 ===\n",
      "chunk.text:\n",
      "'আমি এখানে আসিবার পর আমার কাছারি বাড়িতে একটি অশরীরী আত্মার সহিত পরিচয় হইয়াছে। অত্যন্ত মিশুক লোক, প্রত্যহ অনেক রাত্রি পর্যন্ত আমাদের গল্প-গুজব আলাপ-আলোচনা হয়। তিনি তোমাদের সহিত আলাপ করিতে রাজী হইয়াছেন। যদি তোমাদের আপত্তি না থাকে, সকলে মিলিয়া এখানে চলিয়া এস। এক রাত্রি থাকিলেই চক্ষু-কর্ণের বিবাদ …'\n",
      "chunker.contextualize(chunk):\n",
      "'আমি এখানে আসিবার পর আমার কাছারি বাড়িতে একটি অশরীরী আত্মার সহিত পরিচয় হইয়াছে। অত্যন্ত মিশুক লোক, প্রত্যহ অনেক রাত্রি পর্যন্ত আমাদের গল্প-গুজব আলাপ-আলোচনা হয়। তিনি তোমাদের সহিত আলাপ করিতে রাজী হইয়াছেন। যদি তোমাদের আপত্তি না থাকে, সকলে মিলিয়া এখানে চলিয়া এস। এক রাত্রি থাকিলেই চক্ষু-কর্ণের বিবাদ …'\n",
      "\n",
      "=== 77 ===\n",
      "chunk.text:\n",
      "'কবে আসিতেছ জানাইও। এখানে আসিতে হইলে তারাপুর পর্যন্ত বাসে আসিতে হয়, সেখান হইতে আমার আস্তানা পদব্রজে আড়াই মাইল। রাস্তাঘাট নাই বটে, কিন্তু এসময়ে কোনও কষ্ট হইবে না। তারাপুর থানায় খোঁজ লইলে সেখানকার চৌকিদার পথ দেখাইয়া দিবে। ইতি\\nতোমাদের বরদা\\nচিঠি পড়িয়া অমুল্য বলিল, ‘হুঁ, এই চৌদ্দ দিন জিরিয়ে নিয়েছ…'\n",
      "chunker.contextualize(chunk):\n",
      "'কবে আসিতেছ জানাইও। এখানে আসিতে হইলে তারাপুর পর্যন্ত বাসে আসিতে হয়, সেখান হইতে আমার আস্তানা পদব্রজে আড়াই মাইল। রাস্তাঘাট নাই বটে, কিন্তু এসময়ে কোনও কষ্ট হইবে না। তারাপুর থানায় খোঁজ লইলে সেখানকার চৌকিদার পথ দেখাইয়া দিবে। ইতি\\nতোমাদের বরদা\\nচিঠি পড়িয়া অমুল্য বলিল, ‘হুঁ, এই চৌদ্দ দিন জিরিয়ে নিয়েছ…'\n",
      "\n",
      "=== 78 ===\n",
      "chunk.text:\n",
      "'আমি বলিলাম, ‘কিন্তু ভূতের সঙ্গে করকম্পনটা হবে কি করে?’\\nপৃথ্বী বলিল, ‘সেটা যথাস্থানে পৌঁছে পরীক্ষা করে দেখা যাবে। তা হলে কবে যাওয়া স্থির করছ?’…'\n",
      "chunker.contextualize(chunk):\n",
      "'আমি বলিলাম, ‘কিন্তু ভূতের সঙ্গে করকম্পনটা হবে কি করে?’\\nপৃথ্বী বলিল, ‘সেটা যথাস্থানে পৌঁছে পরীক্ষা করে দেখা যাবে। তা হলে কবে যাওয়া স্থির করছ?’…'\n",
      "\n",
      "=== 79 ===\n",
      "chunk.text:\n",
      "'গবেষণার পর স্থির হইল আগামী মঙ্গলবার আমি, অমূল্য, পৃঙ্খী ও চুনী এই চারজন, পূর্বাহ্নে কোনও খবর না দিয়াই বরদার আড্ডায় গিয়া হানা দিব। বড়দিনের ছুটি আসিয়া পড়িয়াছে, প্রেতাত্মার সহিত করকম্পনের মহাসৌভাগ্য যদি নাও ঘটে তবু একটা আউটিং তো হইবে। ওদিকটাতে শিকারও ভাল পাওয়া যায়।…'\n",
      "chunker.contextualize(chunk):\n",
      "'গবেষণার পর স্থির হইল আগামী মঙ্গলবার আমি, অমূল্য, পৃঙ্খী ও চুনী এই চারজন, পূর্বাহ্নে কোনও খবর না দিয়াই বরদার আড্ডায় গিয়া হানা দিব। বড়দিনের ছুটি আসিয়া পড়িয়াছে, প্রেতাত্মার সহিত করকম্পনের মহাসৌভাগ্য যদি নাও ঘটে তবু একটা আউটিং তো হইবে। ওদিকটাতে শিকারও ভাল পাওয়া যায়।…'\n",
      "\n",
      "=== 80 ===\n",
      "chunk.text:\n",
      "'নির্দিষ্ট দিনে আমরা চারিজন বৈকালে আন্দাজ সাড়ে তিনটার সময় বাস হইতে অবতরণ করিয়া হাঁটা পথ ধরিলাম। ধানক্ষেতের আলের উপর দিয়া যাহাদের চলা অভ্যাস নাই তাহাদের পক্ষে এই পথে পদক্ষেপ সর্বদা নিরুদ্বেগ নয়,—মাঝে মাঝে অতর্কিতভাবে পথিপার্শ্বস্থ পঙ্কশয্যায় বিশ্রাম করিবার সুযোগ ঘটিয়া যায়। কিন্তু সে যাহাই হোক,…'\n",
      "chunker.contextualize(chunk):\n",
      "'নির্দিষ্ট দিনে আমরা চারিজন বৈকালে আন্দাজ সাড়ে তিনটার সময় বাস হইতে অবতরণ করিয়া হাঁটা পথ ধরিলাম। ধানক্ষেতের আলের উপর দিয়া যাহাদের চলা অভ্যাস নাই তাহাদের পক্ষে এই পথে পদক্ষেপ সর্বদা নিরুদ্বেগ নয়,—মাঝে মাঝে অতর্কিতভাবে পথিপার্শ্বস্থ পঙ্কশয্যায় বিশ্রাম করিবার সুযোগ ঘটিয়া যায়। কিন্তু সে যাহাই হোক,…'\n",
      "\n",
      "=== 81 ===\n",
      "chunk.text:\n",
      "'নাই! অমূল্য শ্লেষ করিয়া বলিল, মাইলগুলা সম্ভবত ভৌতিক মাইল, তাই তাহাদের আদি অন্ত খুঁজিয়া পাওয়া যাইতেছে না।\\nএই অতি-প্রাকৃত আড়াই মাইলের শেষে যখন বরদার আস্তানায় আসিয়া পৌঁছিলাম তখন পৃথিবীপৃষ্ঠে দিনের আলো আর নাই, কেবল পশ্চিম আকাশে শীর্ণ সন্ধ্যালোক মুমূর্ষূর প্রাণশক্তির মতো নির্বাণোন্মুখ হইয়া আসিতেছে…'\n",
      "chunker.contextualize(chunk):\n",
      "'নাই! অমূল্য শ্লেষ করিয়া বলিল, মাইলগুলা সম্ভবত ভৌতিক মাইল, তাই তাহাদের আদি অন্ত খুঁজিয়া পাওয়া যাইতেছে না।\\nএই অতি-প্রাকৃত আড়াই মাইলের শেষে যখন বরদার আস্তানায় আসিয়া পৌঁছিলাম তখন পৃথিবীপৃষ্ঠে দিনের আলো আর নাই, কেবল পশ্চিম আকাশে শীর্ণ সন্ধ্যালোক মুমূর্ষূর প্রাণশক্তির মতো নির্বাণোন্মুখ হইয়া আসিতেছে…'\n",
      "\n",
      "=== 82 ===\n",
      "chunk.text:\n",
      "'চারিদিকে কোথাও মানুষের বসতি নাই, আবছায়া ধানক্ষেতের মাঝখানে বিঘাখানেক পতিত জমি, তাহারই একপ্রান্তে একটি জীর্ণ ইটের ঘর—চারিপাশে অপরিসর একটু বারান্দা, মাথার উপর খড়ের ছাউনি। পতিত জমির উপর স্থানে স্থানে খড়ের স্তূপ রাখা আছে। প্রথমটা লোকজন কাহাকেও দেখিতে পাইলাম না, ঠিক স্থানে পৌঁছিয়াছি কি না সন্দেহ হইতে…'\n",
      "chunker.contextualize(chunk):\n",
      "'চারিদিকে কোথাও মানুষের বসতি নাই, আবছায়া ধানক্ষেতের মাঝখানে বিঘাখানেক পতিত জমি, তাহারই একপ্রান্তে একটি জীর্ণ ইটের ঘর—চারিপাশে অপরিসর একটু বারান্দা, মাথার উপর খড়ের ছাউনি। পতিত জমির উপর স্থানে স্থানে খড়ের স্তূপ রাখা আছে। প্রথমটা লোকজন কাহাকেও দেখিতে পাইলাম না, ঠিক স্থানে পৌঁছিয়াছি কি না সন্দেহ হইতে…'\n",
      "\n",
      "=== 83 ===\n",
      "chunk.text:\n",
      "'শুইয়া ছিল, কাছে গিয়া দেখিলাম বরদার কুকুর—খোক্কস। খোক্কসের সহিত আমাদের প্রণয় ছিল, কিন্তু সে বিশেষ উৎসাহ প্রদর্শন করিল না, নিদ্রালুভাবে একবার তাকাইয়া আবার থাবার মধ্যে মুখ খুঁজিয়া ঘুমাইতে লাগিল।…'\n",
      "chunker.contextualize(chunk):\n",
      "'শুইয়া ছিল, কাছে গিয়া দেখিলাম বরদার কুকুর—খোক্কস। খোক্কসের সহিত আমাদের প্রণয় ছিল, কিন্তু সে বিশেষ উৎসাহ প্রদর্শন করিল না, নিদ্রালুভাবে একবার তাকাইয়া আবার থাবার মধ্যে মুখ খুঁজিয়া ঘুমাইতে লাগিল।…'\n",
      "\n",
      "=== 84 ===\n",
      "chunk.text:\n",
      "'কিন্তু বরদা কোথায়? ঘরের মধ্যে আলো জ্বলিতেছে না; এদিক ওদিক চাহিতে দেখি খড়ের একটি গাদার তলা হইতে হামাগুড়ি দিয়া একটি প্রাণী বাহির হইয়া আসিতেছে। মূর্তিটি ক্রমে খাড়া হইয়া আমাদের সম্মুখে আসিয়া ফৌজী সেলাম করিয়া দাঁড়াইল। প্রথমটা ভাবিয়াছিলাম বুঝি বরদার শিশোদীয়বংশীয় রাজপুত; কিন্তু দেখিলাম—তাহা নয…'\n",
      "chunker.contextualize(chunk):\n",
      "'কিন্তু বরদা কোথায়? ঘরের মধ্যে আলো জ্বলিতেছে না; এদিক ওদিক চাহিতে দেখি খড়ের একটি গাদার তলা হইতে হামাগুড়ি দিয়া একটি প্রাণী বাহির হইয়া আসিতেছে। মূর্তিটি ক্রমে খাড়া হইয়া আমাদের সম্মুখে আসিয়া ফৌজী সেলাম করিয়া দাঁড়াইল। প্রথমটা ভাবিয়াছিলাম বুঝি বরদার শিশোদীয়বংশীয় রাজপুত; কিন্তু দেখিলাম—তাহা নয…'\n",
      "\n",
      "=== 85 ===\n",
      "chunk.text:\n",
      "'ক্ষত্রিয়। সম্ভবত বরদার দেউড়ি পাহারা দিবার জন্য নিযুক্ত হইয়াছেন। পরিধানে খাকি পোষাক, পায়ে বুট জুতা, কোমরে কুক্\\u200cরি—রীতিমত যোদ্ধৃবেশ। তাঁহাকে বরদার কুশল প্রশ্ন জিজ্ঞাসা করায় তিনি চন্দ্রবংশীয় ভাষায় যাহা বলিলেন তাহার বিন্দুবিসর্গও বুঝিতে পারিলাম না।…'\n",
      "chunker.contextualize(chunk):\n",
      "'ক্ষত্রিয়। সম্ভবত বরদার দেউড়ি পাহারা দিবার জন্য নিযুক্ত হইয়াছেন। পরিধানে খাকি পোষাক, পায়ে বুট জুতা, কোমরে কুক্\\u200cরি—রীতিমত যোদ্ধৃবেশ। তাঁহাকে বরদার কুশল প্রশ্ন জিজ্ঞাসা করায় তিনি চন্দ্রবংশীয় ভাষায় যাহা বলিলেন তাহার বিন্দুবিসর্গও বুঝিতে পারিলাম না।…'\n",
      "\n",
      "=== 86 ===\n",
      "chunk.text:\n",
      "'শীতে এতখানি পথ হাঁটিয়া শরীর অবসন্ন হইয়া পড়িয়াছিল; আমরা আর বাক্যব্যয় না করিয়া ঘরের দিকে অগ্রসর হইলাম। চন্দ্রবংশীয় ক্ষত্রিয় নির্বিকার মুখে আবার খড়ের গাদার মধ্যে প্রবেশ করিলেন।…'\n",
      "chunker.contextualize(chunk):\n",
      "'শীতে এতখানি পথ হাঁটিয়া শরীর অবসন্ন হইয়া পড়িয়াছিল; আমরা আর বাক্যব্যয় না করিয়া ঘরের দিকে অগ্রসর হইলাম। চন্দ্রবংশীয় ক্ষত্রিয় নির্বিকার মুখে আবার খড়ের গাদার মধ্যে প্রবেশ করিলেন।…'\n",
      "\n",
      "=== 87 ===\n",
      "chunk.text:\n",
      "'আমরা যেখানে ছিলাম সেখান হইতে ঘরটি বোধ করি ত্রিশ কদম দূরে। বারান্দাসুদ্ধ ঘরের ভিত মাটি হইতে হাত দুই উঁচুতে অবস্থিত। বারান্দায় উঠিয়া সম্মুখেই ঘরের দ্বার; আমি সর্বপ্রথম উপরে উঠিয়া দ্বারের দিকে পা বাড়াইয়াই চমকাইয়া উঠিলাম!—অন্ধকার দরজার মুখে কে দাঁড়াইয়া রহিয়াছে।\\nপরক্ষণেই বরদা সশব্দে হাসিয়া উঠিল…'\n",
      "chunker.contextualize(chunk):\n",
      "'আমরা যেখানে ছিলাম সেখান হইতে ঘরটি বোধ করি ত্রিশ কদম দূরে। বারান্দাসুদ্ধ ঘরের ভিত মাটি হইতে হাত দুই উঁচুতে অবস্থিত। বারান্দায় উঠিয়া সম্মুখেই ঘরের দ্বার; আমি সর্বপ্রথম উপরে উঠিয়া দ্বারের দিকে পা বাড়াইয়াই চমকাইয়া উঠিলাম!—অন্ধকার দরজার মুখে কে দাঁড়াইয়া রহিয়াছে।\\nপরক্ষণেই বরদা সশব্দে হাসিয়া উঠিল…'\n",
      "\n",
      "=== 88 ===\n",
      "chunk.text:\n",
      "'আমরা ঘরে প্রবেশ করিলাম। বরদা একটা তেলের ল্যাম্প জ্বালিয়া টেবিলের উপর রাখিল।\\nঅমূল্য ঈষৎ বিরক্তির স্বরে বলিল, ‘ঘরেই ছিলে তো—সাড়া দিচ্ছিলে না কেন?—দেয়ালা হচ্ছিল বুঝি?’\\nউত্তরে বরদা কেবল হাসিল। বলিল, ‘বসো সবাই। শীতে নিশ্চয় কালিয়ে গিয়েছ। চা তৈরি আছে—দিচ্ছি।’ বলিয়া প্রকাণ্ড একটা থার্মোফ্লাস্ক, হইতে …'\n",
      "chunker.contextualize(chunk):\n",
      "'আমরা ঘরে প্রবেশ করিলাম। বরদা একটা তেলের ল্যাম্প জ্বালিয়া টেবিলের উপর রাখিল।\\nঅমূল্য ঈষৎ বিরক্তির স্বরে বলিল, ‘ঘরেই ছিলে তো—সাড়া দিচ্ছিলে না কেন?—দেয়ালা হচ্ছিল বুঝি?’\\nউত্তরে বরদা কেবল হাসিল। বলিল, ‘বসো সবাই। শীতে নিশ্চয় কালিয়ে গিয়েছ। চা তৈরি আছে—দিচ্ছি।’ বলিয়া প্রকাণ্ড একটা থার্মোফ্লাস্ক, হইতে …'\n",
      "\n",
      "=== 89 ===\n",
      "chunk.text:\n",
      "'চা খাইতে খাইতে বরদার ঘরের চর্তুদিকে চক্ষু ফিরাইয়া দেখিতে লাগিলাম। ঘরের কোথাও এতটুকু প্লাস্টার নাই, নোনাধরা লাল ইটগুলি সারি সারি দাঁত বাহির করিয়া আছে; মেঝে মাটির, গোময় দিয়া লিপ্ত। এক কোণে একটি ক্ষুদ্র চারপাইয়ের উপর বরদার লেপ-বিছানা স্থূপীকৃত রহিয়াছে। আর এককোণে একটি বড় কাঠের সিন্দুক, তাহার উপর …'\n",
      "chunker.contextualize(chunk):\n",
      "'চা খাইতে খাইতে বরদার ঘরের চর্তুদিকে চক্ষু ফিরাইয়া দেখিতে লাগিলাম। ঘরের কোথাও এতটুকু প্লাস্টার নাই, নোনাধরা লাল ইটগুলি সারি সারি দাঁত বাহির করিয়া আছে; মেঝে মাটির, গোময় দিয়া লিপ্ত। এক কোণে একটি ক্ষুদ্র চারপাইয়ের উপর বরদার লেপ-বিছানা স্থূপীকৃত রহিয়াছে। আর এককোণে একটি বড় কাঠের সিন্দুক, তাহার উপর …'\n",
      "\n",
      "=== 90 ===\n",
      "chunk.text:\n",
      "'টেবিল, এবং তাহাই ঘিরিয়া কয়েকটি কঞ্চির মোড়ার উপর বসিয়া অনুজ্জ্বল ল্যাম্পের আলোয় আমরা কয়জন চা পান করিতেছি।…'\n",
      "chunker.contextualize(chunk):\n",
      "'টেবিল, এবং তাহাই ঘিরিয়া কয়েকটি কঞ্চির মোড়ার উপর বসিয়া অনুজ্জ্বল ল্যাম্পের আলোয় আমরা কয়জন চা পান করিতেছি।…'\n",
      "\n",
      "=== 91 ===\n",
      "chunk.text:\n",
      "'খোলা দরজা দিয়া ঠাণ্ডা বাতাস আসিতেছিল, বরদা সেটা বন্ধ করিয়া দিয়া আমাদের মধ্যে আসিয়া বসিল; তৃপ্তভাবে দুই হাত ঘষিতে ঘষিতে বলিল, ‘আমার ঘরটি কেমন দেখছ? ঘর ছিল না, কেবল চারিটি পুরানো দেওয়াল দাঁড়িয়ে ছিল; আমি এসে খড়ের চাল তুলে বাসের উপযোগী করে নিয়েছি।—বেশ হয়নি?’\\n‘খাসা হয়েছে!’…'\n",
      "chunker.contextualize(chunk):\n",
      "'খোলা দরজা দিয়া ঠাণ্ডা বাতাস আসিতেছিল, বরদা সেটা বন্ধ করিয়া দিয়া আমাদের মধ্যে আসিয়া বসিল; তৃপ্তভাবে দুই হাত ঘষিতে ঘষিতে বলিল, ‘আমার ঘরটি কেমন দেখছ? ঘর ছিল না, কেবল চারিটি পুরানো দেওয়াল দাঁড়িয়ে ছিল; আমি এসে খড়ের চাল তুলে বাসের উপযোগী করে নিয়েছি।—বেশ হয়নি?’\\n‘খাসা হয়েছে!’…'\n",
      "\n",
      "=== 92 ===\n",
      "chunk.text:\n",
      "'‘পেয়াদা সেপাই চিরকাল বাইরে খড়ের ছাপ্পর তৈরি করে তার মধ্যে থাকে; এবারও তাই আছে। কিন্তু আমি ভাই পারলুম না। তেরপলের তলায় এক রাত্তির শুয়েছিলুম—বাপ কি শীত! ঘরের মধ্যে এক রকম ভালই আছি। আচ্ছা, ঘরটা তোমাদের বেশ ইয়ে বোধ হচ্ছে না?’…'\n",
      "chunker.contextualize(chunk):\n",
      "'‘পেয়াদা সেপাই চিরকাল বাইরে খড়ের ছাপ্পর তৈরি করে তার মধ্যে থাকে; এবারও তাই আছে। কিন্তু আমি ভাই পারলুম না। তেরপলের তলায় এক রাত্তির শুয়েছিলুম—বাপ কি শীত! ঘরের মধ্যে এক রকম ভালই আছি। আচ্ছা, ঘরটা তোমাদের বেশ ইয়ে বোধ হচ্ছে না?’…'\n",
      "\n",
      "=== 93 ===\n",
      "chunk.text:\n",
      "'আমরা সকলেই ঘাড় নাড়িয়া সায় দিলাম। ‘ইয়ে’ বলিয়া বরদা ঠিক কি বুঝাইতে চাহিল জানি না, কিন্তু এই ঘরে পদার্পণ করিবার পর হইতেই আমার মনের উপর কেমন একটা ছায়া পড়িতে আরম্ভ করিয়াছিল, মনের সে পরিহাস-তরল ভাব আর ছিল না। কোথায় এ ঘরের কি গলদ আছে—বুঝিতে পারিতেছিলাম না, অথচ অপরিচিত অন্ধকার পথে চলিবার সময় যেমন…'\n",
      "chunker.contextualize(chunk):\n",
      "'আমরা সকলেই ঘাড় নাড়িয়া সায় দিলাম। ‘ইয়ে’ বলিয়া বরদা ঠিক কি বুঝাইতে চাহিল জানি না, কিন্তু এই ঘরে পদার্পণ করিবার পর হইতেই আমার মনের উপর কেমন একটা ছায়া পড়িতে আরম্ভ করিয়াছিল, মনের সে পরিহাস-তরল ভাব আর ছিল না। কোথায় এ ঘরের কি গলদ আছে—বুঝিতে পারিতেছিলাম না, অথচ অপরিচিত অন্ধকার পথে চলিবার সময় যেমন…'\n",
      "\n",
      "=== 94 ===\n",
      "chunk.text:\n",
      "'অবাস্তবতার সংশয় আমার ইন্দ্রিয়গুলিকে অতিশয় সতর্ক ও সচেতন করিয়া তুলিয়াছিল।\\nচায়ের পেয়ালা নামাইয়া রাখিয়া অমূল্য বলিল, ‘তারপর, তোমার ভূত কই?’\\nবরদার হাসিমুখ আস্তে আস্তে গম্ভীর হইয়া গেল। সে যেন কয়েক মুহূর্ত উৎকর্ণ হইয়া কি শুনিল, তারপর অমূল্যর দিকে ফিরিয়া ঈষৎ ক্ষুব্ধ স্বরে বলিল, ‘ভয় নেই, তাঁর …'\n",
      "chunker.contextualize(chunk):\n",
      "'অবাস্তবতার সংশয় আমার ইন্দ্রিয়গুলিকে অতিশয় সতর্ক ও সচেতন করিয়া তুলিয়াছিল।\\nচায়ের পেয়ালা নামাইয়া রাখিয়া অমূল্য বলিল, ‘তারপর, তোমার ভূত কই?’\\nবরদার হাসিমুখ আস্তে আস্তে গম্ভীর হইয়া গেল। সে যেন কয়েক মুহূর্ত উৎকর্ণ হইয়া কি শুনিল, তারপর অমূল্যর দিকে ফিরিয়া ঈষৎ ক্ষুব্ধ স্বরে বলিল, ‘ভয় নেই, তাঁর …'\n",
      "\n",
      "=== 95 ===\n",
      "chunk.text:\n",
      "'চুনী জিজ্ঞাসা করিল, ‘কতক্ষণে তাঁর দর্শন পাওয়া যাবে? তাঁর আসার সময়ের কিছু স্থিরতা আছে কি?’\\nবরদা বলিল, ‘কিছু না। শুধু তাই নয়, কোন্ রূপে তিনি আসবেন, তারও স্থিরতা নেই।’\\nআমরা মোড়া টানিয়া আরও ঘনিষ্ঠ হইয়া বসিলাম। পৃথ্বী হাসিবার চেষ্টা করিয়া বলিল, ‘সেটা কি রকম!’\\nবরদা বলিল, ‘তিনি মানুষের রূপ ধারণ করে …'\n",
      "chunker.contextualize(chunk):\n",
      "'চুনী জিজ্ঞাসা করিল, ‘কতক্ষণে তাঁর দর্শন পাওয়া যাবে? তাঁর আসার সময়ের কিছু স্থিরতা আছে কি?’\\nবরদা বলিল, ‘কিছু না। শুধু তাই নয়, কোন্ রূপে তিনি আসবেন, তারও স্থিরতা নেই।’\\nআমরা মোড়া টানিয়া আরও ঘনিষ্ঠ হইয়া বসিলাম। পৃথ্বী হাসিবার চেষ্টা করিয়া বলিল, ‘সেটা কি রকম!’\\nবরদা বলিল, ‘তিনি মানুষের রূপ ধারণ করে …'\n",
      "\n",
      "=== 96 ===\n",
      "chunk.text:\n",
      "'‘তার মানে কি?’\\n‘তার মানে—’ বরদা যেন একটু ইতস্তত করিল—‘অশরীরী আত্মাকে স্থূল দেহ ধারণ করতে হলে কিছু জান্তব মাল-মশলার দরকার হয়, তার নাম বিজ্ঞানের ভাষায় এক্\\u200cটোপ্লাজম্। এই এক্\\u200cটোপ্লাজম্\\u200c প্রয়োজন মতো না পেলে চেহারা একটু অন্যরকম হয়ে যায়।’\\nঅমূল্য বলিল, ‘ও, তোমার সেই পুরাতন থিওরি! কিন্তু তোমার ইনি এক্\\u200cট…'\n",
      "chunker.contextualize(chunk):\n",
      "'‘তার মানে কি?’\\n‘তার মানে—’ বরদা যেন একটু ইতস্তত করিল—‘অশরীরী আত্মাকে স্থূল দেহ ধারণ করতে হলে কিছু জান্তব মাল-মশলার দরকার হয়, তার নাম বিজ্ঞানের ভাষায় এক্\\u200cটোপ্লাজম্। এই এক্\\u200cটোপ্লাজম্\\u200c প্রয়োজন মতো না পেলে চেহারা একটু অন্যরকম হয়ে যায়।’\\nঅমূল্য বলিল, ‘ও, তোমার সেই পুরাতন থিওরি! কিন্তু তোমার ইনি এক্\\u200cট…'\n",
      "\n",
      "=== 97 ===\n",
      "chunk.text:\n",
      "'বরদা একটু চুপ করিয়া থাকিয়া শেষে ধীরে ধীরে বলিল, ‘বোধ হয় খোক্কসের গা থেকে। তিনি যতক্ষণ থাকেন, কুকুরটা নির্জীব হয়ে পড়ে থাকে,—নড়েচড়ে না, ডাকেও না—তবে শুধু যে এক্\\u200cটোপ্লাজমের তারতম্যে চেহারার তারতম্য হয় তা নয়, অন্য কারণও আছে।’\\n‘অন্য কারণটি কি?’…'\n",
      "chunker.contextualize(chunk):\n",
      "'বরদা একটু চুপ করিয়া থাকিয়া শেষে ধীরে ধীরে বলিল, ‘বোধ হয় খোক্কসের গা থেকে। তিনি যতক্ষণ থাকেন, কুকুরটা নির্জীব হয়ে পড়ে থাকে,—নড়েচড়ে না, ডাকেও না—তবে শুধু যে এক্\\u200cটোপ্লাজমের তারতম্যে চেহারার তারতম্য হয় তা নয়, অন্য কারণও আছে।’\\n‘অন্য কারণটি কি?’…'\n",
      "\n",
      "=== 98 ===\n",
      "chunk.text:\n",
      "'‘ইচ্ছা। প্রেতযোনি ইচ্ছা করলেই চেহারা বদল করতে পারে; কারণ, তাদের দেহের উপাদান মানুষের দেহের উপাদানের মতো কঠিন বস্তু নয়।’…'\n",
      "chunker.contextualize(chunk):\n",
      "'‘ইচ্ছা। প্রেতযোনি ইচ্ছা করলেই চেহারা বদল করতে পারে; কারণ, তাদের দেহের উপাদান মানুষের দেহের উপাদানের মতো কঠিন বস্তু নয়।’…'\n",
      "\n",
      "=== 99 ===\n",
      "chunk.text:\n",
      "'এই সময়ে বরদাকে একটু বিশেষভাবে লক্ষ্য করিলাম। এ কয়দিনে তাহার কি একটা পরিবর্তন ঘটিয়াছে। পরোক্ষ বিশ্বাসের গণ্ডী ছাড়াইয়া যেন সে সাক্ষাৎ উপলব্ধির দৃঢ়তর ভিত্তির উপর পা দিয়া দাঁড়াইয়াছে। তার্কিকের যুযুৎসা একেবারেই নাই, মুখে একটা নিঃসংশয় প্রসন্নতার ভাব, ঠোঁটের কোণে একটু সকৌতুক কোমলতা ক্রীড়া করিতেছ…'\n",
      "chunker.contextualize(chunk):\n",
      "'এই সময়ে বরদাকে একটু বিশেষভাবে লক্ষ্য করিলাম। এ কয়দিনে তাহার কি একটা পরিবর্তন ঘটিয়াছে। পরোক্ষ বিশ্বাসের গণ্ডী ছাড়াইয়া যেন সে সাক্ষাৎ উপলব্ধির দৃঢ়তর ভিত্তির উপর পা দিয়া দাঁড়াইয়াছে। তার্কিকের যুযুৎসা একেবারেই নাই, মুখে একটা নিঃসংশয় প্রসন্নতার ভাব, ঠোঁটের কোণে একটু সকৌতুক কোমলতা ক্রীড়া করিতেছ…'\n",
      "\n",
      "=== 100 ===\n",
      "chunk.text:\n",
      "'পৃথ্বী বলিল, ‘থিওরি যাক। এখন ঘটনাগুলো বল শুনি—তোমার সঙ্গে ঘনিষ্ঠতা কতদূর দাঁড়িয়েছে, কোথায় প্রথম সাক্ষাৎ হল ইত্যাদি। অর্থাৎ তোমাকে আগাগোড়া গল্পটা বলবার সুযোগ দিচ্ছি। আরম্ভ কর।’…'\n",
      "chunker.contextualize(chunk):\n",
      "'পৃথ্বী বলিল, ‘থিওরি যাক। এখন ঘটনাগুলো বল শুনি—তোমার সঙ্গে ঘনিষ্ঠতা কতদূর দাঁড়িয়েছে, কোথায় প্রথম সাক্ষাৎ হল ইত্যাদি। অর্থাৎ তোমাকে আগাগোড়া গল্পটা বলবার সুযোগ দিচ্ছি। আরম্ভ কর।’…'\n",
      "\n",
      "=== 101 ===\n",
      "chunk.text:\n",
      "'বরদা একটু হাসিয়া বলিল, ‘বেশ।’ তারপর আবার যেন কান পাতিয়া কি শুনিল—‘দ্যাখো, একটা কথা তোমাদের বলে রাখি। যদি কোনও সময় বুঝতে পারো যে তিনি এসেছেন—ভয় পেয়ো না। ভয় পেলে সব নষ্ট হয়ে যাবে।’\\nচারিদিকে সচকিতভাবে একবার চাহিয়া আমরা আশ্বাস দিলাম, ভয় পাইব না। বরদা তখন বলিতে আরম্ভ করিল—…'\n",
      "chunker.contextualize(chunk):\n",
      "'বরদা একটু হাসিয়া বলিল, ‘বেশ।’ তারপর আবার যেন কান পাতিয়া কি শুনিল—‘দ্যাখো, একটা কথা তোমাদের বলে রাখি। যদি কোনও সময় বুঝতে পারো যে তিনি এসেছেন—ভয় পেয়ো না। ভয় পেলে সব নষ্ট হয়ে যাবে।’\\nচারিদিকে সচকিতভাবে একবার চাহিয়া আমরা আশ্বাস দিলাম, ভয় পাইব না। বরদা তখন বলিতে আরম্ভ করিল—…'\n",
      "\n",
      "=== 102 ===\n",
      "chunk.text:\n",
      "'‘প্রথম যে-রাত্রে এ ঘরে শুই, সে-রাত্রে কিছু বুঝতে পারিনি। দ্বিতীয় রাত্রে হঠাৎ এক সময় ঘুম ভেঙে গেল; শুনতে পেলুম, ঘরের মধ্যে কে খসখস করে চলে বেড়াচ্ছে। দরজা বন্ধ করে শুয়েছিলুম, ভাবলুম, সিঁদ কেটে চোর ঢুকেছে। বালিশের তলায় টর্চ ছিল, হঠাৎ জ্বেলে ঘরের চারিদিকে ফেললুম। কেউ কোথাও নেই।…'\n",
      "chunker.contextualize(chunk):\n",
      "'‘প্রথম যে-রাত্রে এ ঘরে শুই, সে-রাত্রে কিছু বুঝতে পারিনি। দ্বিতীয় রাত্রে হঠাৎ এক সময় ঘুম ভেঙে গেল; শুনতে পেলুম, ঘরের মধ্যে কে খসখস করে চলে বেড়াচ্ছে। দরজা বন্ধ করে শুয়েছিলুম, ভাবলুম, সিঁদ কেটে চোর ঢুকেছে। বালিশের তলায় টর্চ ছিল, হঠাৎ জ্বেলে ঘরের চারিদিকে ফেললুম। কেউ কোথাও নেই।…'\n",
      "\n",
      "=== 103 ===\n",
      "chunk.text:\n",
      "'‘আবার আলো নিভিয়ে যেই শুয়েছি অমনি খসখস শব্দ আরম্ভ হল। আবার আলো জ্বাললুম। এই রকম তিন-চার বার হল। তারপর হঠাৎ বুঝতে পারলুম। চিরজীবন এই বিষয় নিয়ে নাড়াচাড়া করেছি, তবু বুকের ভিতরটা ধড়ফড় করে উঠল। আলো নিভিয়ে গলার স্বর যথাসাধ্য সংযত করে বললুম, ‘আপনি কে আমি জানি না; কিন্তু আপনার যদি কিছু বলবার থাকে আম…'\n",
      "chunker.contextualize(chunk):\n",
      "'‘আবার আলো নিভিয়ে যেই শুয়েছি অমনি খসখস শব্দ আরম্ভ হল। আবার আলো জ্বাললুম। এই রকম তিন-চার বার হল। তারপর হঠাৎ বুঝতে পারলুম। চিরজীবন এই বিষয় নিয়ে নাড়াচাড়া করেছি, তবু বুকের ভিতরটা ধড়ফড় করে উঠল। আলো নিভিয়ে গলার স্বর যথাসাধ্য সংযত করে বললুম, ‘আপনি কে আমি জানি না; কিন্তু আপনার যদি কিছু বলবার থাকে আম…'\n",
      "\n",
      "=== 104 ===\n",
      "chunk.text:\n",
      "'‘মনে হল, কে যেন আমার বিছানার পাশে এসে দাঁড়াল। তারপর ভাঙা ভাঙা অস্পষ্ট আওয়াজ শুনতে পেলুম, ‘আপনি ভয় পাবেন না?’\\n‘লেপের মধ্যে থেকেও হাত পা ঠাণ্ডা হয়ে গিয়েছিল, বললুম, ‘না।’\\n‘তিনি মৃদু কণ্ঠে একটু হাসলেন! যেন আমার অবস্থা বুঝতে পেরেছেন। হাসি শুনে আমার মনে সাহস হল; ভারি সহানুভূতিপূর্ণ নরম হাসি—একটু করুণ…'\n",
      "chunker.contextualize(chunk):\n",
      "'‘মনে হল, কে যেন আমার বিছানার পাশে এসে দাঁড়াল। তারপর ভাঙা ভাঙা অস্পষ্ট আওয়াজ শুনতে পেলুম, ‘আপনি ভয় পাবেন না?’\\n‘লেপের মধ্যে থেকেও হাত পা ঠাণ্ডা হয়ে গিয়েছিল, বললুম, ‘না।’\\n‘তিনি মৃদু কণ্ঠে একটু হাসলেন! যেন আমার অবস্থা বুঝতে পেরেছেন। হাসি শুনে আমার মনে সাহস হল; ভারি সহানুভূতিপূর্ণ নরম হাসি—একটু করুণ…'\n",
      "\n",
      "=== 105 ===\n",
      "chunk.text:\n",
      "'‘চোখে কিছুই দেখতে পেলুম না, অনুভবে বুঝলুম, তিনি আমার বিছানার পাশে বসলেন। তারপর নিঃশ্বাসের মতো মৃদুস্বরে বললেন, ‘আমি এই ঘরটাতে থাকি। আপনি এসে পর্যন্ত আলাপ করবার জন্য ছটফট করছি, কিন্তু পাছে আপনি ভয় পান—তাই সাহস হচ্ছিল না।’…'\n",
      "chunker.contextualize(chunk):\n",
      "'‘চোখে কিছুই দেখতে পেলুম না, অনুভবে বুঝলুম, তিনি আমার বিছানার পাশে বসলেন। তারপর নিঃশ্বাসের মতো মৃদুস্বরে বললেন, ‘আমি এই ঘরটাতে থাকি। আপনি এসে পর্যন্ত আলাপ করবার জন্য ছটফট করছি, কিন্তু পাছে আপনি ভয় পান—তাই সাহস হচ্ছিল না।’…'\n",
      "\n",
      "=== 106 ===\n",
      "chunk.text:\n",
      "'‘আমি কি বলব ভেবে পেলুম না। তিনি বলতে লাগলেন, ‘এইখানে প্রায় পঁচিশ বছর আছি। ঘরটা আমিই তৈরি করিয়েছিলুম, তারপর মৃত্যুও হল এইখানেই। প্লেগ হয়েছিল…সৎকার করবার লোক ছিল না, মৃতদেহটাকে শেয়াল কুকুরে ছেঁড়াছেঁড়ি করলে…সেই থেকে এ জায়গা ছেড়ে যাবার আমার উপায় নেই…একলাই থাকি। আপনি এসেছেন দেখে ভারি আনন্দ হল; ক…'\n",
      "chunker.contextualize(chunk):\n",
      "'‘আমি কি বলব ভেবে পেলুম না। তিনি বলতে লাগলেন, ‘এইখানে প্রায় পঁচিশ বছর আছি। ঘরটা আমিই তৈরি করিয়েছিলুম, তারপর মৃত্যুও হল এইখানেই। প্লেগ হয়েছিল…সৎকার করবার লোক ছিল না, মৃতদেহটাকে শেয়াল কুকুরে ছেঁড়াছেঁড়ি করলে…সেই থেকে এ জায়গা ছেড়ে যাবার আমার উপায় নেই…একলাই থাকি। আপনি এসেছেন দেখে ভারি আনন্দ হল; ক…'\n",
      "\n",
      "=== 107 ===\n",
      "chunk.text:\n",
      "'সুযোগ হয় না। সবাই ভয় পায়; অথচ আমি—আমরা কারো অনিষ্ট করতে চাই না—ক্ষমতাও নেই।—কেন বলুন দেখি সবাই ভয় পায়?’\\n‘এ প্রশ্নের উত্তর জানি না, তাই জবাব দেওয়া হল না। তিনি বললেন, ‘আমি যদি মাঝে মাঝে এসে আপনার সঙ্গে গল্পসল্প করি, আপনার কষ্ট হবে না তো?’\\n‘আমি বললুম, ‘না, বরং খুশি হব।’…'\n",
      "chunker.contextualize(chunk):\n",
      "'সুযোগ হয় না। সবাই ভয় পায়; অথচ আমি—আমরা কারো অনিষ্ট করতে চাই না—ক্ষমতাও নেই।—কেন বলুন দেখি সবাই ভয় পায়?’\\n‘এ প্রশ্নের উত্তর জানি না, তাই জবাব দেওয়া হল না। তিনি বললেন, ‘আমি যদি মাঝে মাঝে এসে আপনার সঙ্গে গল্পসল্প করি, আপনার কষ্ট হবে না তো?’\\n‘আমি বললুম, ‘না, বরং খুশি হব।’…'\n",
      "\n",
      "=== 108 ===\n",
      "chunk.text:\n",
      "'‘তিনি গাঢ় স্বরে বললেন, ‘ধন্যবাদ। আচ্ছা, আমাকে চোখে দেখলে কি আপনি খুব ভয় পাবেন? সত্যি বলছি আমার চেহারা বীভৎস নয়—সাধারণ মানুষের মতো।’\\n‘বুকের ভেতর দুরু দুরু করে উঠল, কিন্তু বললুম, ‘না, ভয় পাব না।’\\n‘তিনি বললেন, ‘তবে আলোটা জ্বালুন।’…'\n",
      "chunker.contextualize(chunk):\n",
      "'‘তিনি গাঢ় স্বরে বললেন, ‘ধন্যবাদ। আচ্ছা, আমাকে চোখে দেখলে কি আপনি খুব ভয় পাবেন? সত্যি বলছি আমার চেহারা বীভৎস নয়—সাধারণ মানুষের মতো।’\\n‘বুকের ভেতর দুরু দুরু করে উঠল, কিন্তু বললুম, ‘না, ভয় পাব না।’\\n‘তিনি বললেন, ‘তবে আলোটা জ্বালুন।’…'\n",
      "\n",
      "=== 109 ===\n",
      "chunk.text:\n",
      "'‘মনকে দৃঢ় করে টর্চ জ্বাললুম। মুহুর্তের জন্য তাকে দেখতে পাওয়া গেল। আমাদেরই সমবয়স্ক একটি যুবক, ময়লা রং, বড় বড় চুল—আগ্রহভরা চোখে আমার পানে চেয়ে রয়েছেন। নিতান্তই সহজ মানুষের চেহারা, ভয় পাবার কিছু নেই, কিন্তু তবু বুদ্ধি-বিবেচনা কোনও কাজেই লাগল না, সমস্ত অন্তরাত্মা যেন ভয়ে আঁতকে উঠল। মূর্তিও সঙ্…'\n",
      "chunker.contextualize(chunk):\n",
      "'‘মনকে দৃঢ় করে টর্চ জ্বাললুম। মুহুর্তের জন্য তাকে দেখতে পাওয়া গেল। আমাদেরই সমবয়স্ক একটি যুবক, ময়লা রং, বড় বড় চুল—আগ্রহভরা চোখে আমার পানে চেয়ে রয়েছেন। নিতান্তই সহজ মানুষের চেহারা, ভয় পাবার কিছু নেই, কিন্তু তবু বুদ্ধি-বিবেচনা কোনও কাজেই লাগল না, সমস্ত অন্তরাত্মা যেন ভয়ে আঁতকে উঠল। মূর্তিও সঙ্…'\n",
      "\n",
      "=== 110 ===\n",
      "chunk.text:\n",
      "'মতো একটা আওয়াজ করে ডেকে উঠল।’\\nবরদা চুপ করিল।\\nফুসফুস হইতে অবরুদ্ধ বাষ্প মুক্ত করিয়া বলিলাম, ‘তারপর?’…'\n",
      "chunker.contextualize(chunk):\n",
      "'মতো একটা আওয়াজ করে ডেকে উঠল।’\\nবরদা চুপ করিল।\\nফুসফুস হইতে অবরুদ্ধ বাষ্প মুক্ত করিয়া বলিলাম, ‘তারপর?’…'\n",
      "\n",
      "=== 111 ===\n",
      "chunk.text:\n",
      "'বরদা বলিল, ‘তারপর—’ সহসা উঠিয়া দাঁড়াইল, পূর্বের ন্যায় উৎকর্ণ হইয়া শুনিল। তারপর আমাদের দিকে ফিরিয়া তাড়াতাড়ি বলিল, ‘সময় সংক্ষিপ্ত হয়ে আসছে—হ্যাঁ, তারপর ক্রমে ভয় কেটে গেল। এখন রোজই তিনি আসেন, অনেক কথাবার্তা হয়। তোমাদের সঙ্গেও দেখা করবার জন্যে তিনি খুব উৎসুক ছিলেন—কিন্তু—। আর সময় নেই—এস।’ বর…'\n",
      "chunker.contextualize(chunk):\n",
      "'বরদা বলিল, ‘তারপর—’ সহসা উঠিয়া দাঁড়াইল, পূর্বের ন্যায় উৎকর্ণ হইয়া শুনিল। তারপর আমাদের দিকে ফিরিয়া তাড়াতাড়ি বলিল, ‘সময় সংক্ষিপ্ত হয়ে আসছে—হ্যাঁ, তারপর ক্রমে ভয় কেটে গেল। এখন রোজই তিনি আসেন, অনেক কথাবার্তা হয়। তোমাদের সঙ্গেও দেখা করবার জন্যে তিনি খুব উৎসুক ছিলেন—কিন্তু—। আর সময় নেই—এস।’ বর…'\n",
      "\n",
      "=== 112 ===\n",
      "chunk.text:\n",
      "'শেকহ্যান্ড করিলাম। বরদার হঠাৎ হইল কি? আমাদের বিদায় করিতে চায় নাকি?’\\nঅমূল্য বলিল, ‘কিন্তু কই, তিনি এখনও দেখা দিলেন না?’\\nবরদা আবার বসিয়া পড়িল, মুখের উপর দিয়া একবার হাত চালাইয়া বলিল, ‘হয়তো দেখা দিয়েছেন—তোমরা জানতে পারনি—’…'\n",
      "chunker.contextualize(chunk):\n",
      "'শেকহ্যান্ড করিলাম। বরদার হঠাৎ হইল কি? আমাদের বিদায় করিতে চায় নাকি?’\\nঅমূল্য বলিল, ‘কিন্তু কই, তিনি এখনও দেখা দিলেন না?’\\nবরদা আবার বসিয়া পড়িল, মুখের উপর দিয়া একবার হাত চালাইয়া বলিল, ‘হয়তো দেখা দিয়েছেন—তোমরা জানতে পারনি—’…'\n",
      "\n",
      "=== 113 ===\n",
      "chunk.text:\n",
      "'এই সময় বাহিরে দ্রুত পদধ্বনি শুনা গেল। আমরা চমকিয়া সোজা হইয়া বসিলাম। পদশব্দ বারান্দার উপরে উঠিল, তারপর বদ্ধ দরজায় সজোরে ধাক্কা পড়িল। হৃদ্\\u200cযন্ত্রটাও ওই ধাক্কার সঙ্গে সঙ্গে চমকিয়া উঠিল; আমরা প্রশ্ন-বিস্ফারিত চক্ষে পরস্পরের পানে চাহিলাম—এ সময় হঠাৎ কে আসিল? তবে কি—\\nবরদার মুখে একটা ম্লান হাসি ক্রীড…'\n",
      "chunker.contextualize(chunk):\n",
      "'এই সময় বাহিরে দ্রুত পদধ্বনি শুনা গেল। আমরা চমকিয়া সোজা হইয়া বসিলাম। পদশব্দ বারান্দার উপরে উঠিল, তারপর বদ্ধ দরজায় সজোরে ধাক্কা পড়িল। হৃদ্\\u200cযন্ত্রটাও ওই ধাক্কার সঙ্গে সঙ্গে চমকিয়া উঠিল; আমরা প্রশ্ন-বিস্ফারিত চক্ষে পরস্পরের পানে চাহিলাম—এ সময় হঠাৎ কে আসিল? তবে কি—\\nবরদার মুখে একটা ম্লান হাসি ক্রীড…'\n",
      "\n",
      "=== 114 ===\n",
      "chunk.text:\n",
      "'আমি নীরবে মাথা নাড়িলাম।\\nবরদা ব্যথিত অবসন্ন কণ্ঠে বলিল, ‘এখনি বুঝতে পারবে; দোর খুলে দাও—’\\nদ্বার খুলিয়া দিব? কিন্তু দ্বারের ওপারে কী আছে?\\nআবার সজোরে ধাক্কা পড়িল; বরদা আবার চোখের নীরব ইঙ্গিতে আমাকে দ্বার খুলিয়া দিতে বলিল। আমি মোহাচ্ছন্নের মতো উঠিয়া গিয়া দ্বারের হুড়কা খুলিয়া দিলাম।\\nঅধীর হস্তে কব…'\n",
      "chunker.contextualize(chunk):\n",
      "'আমি নীরবে মাথা নাড়িলাম।\\nবরদা ব্যথিত অবসন্ন কণ্ঠে বলিল, ‘এখনি বুঝতে পারবে; দোর খুলে দাও—’\\nদ্বার খুলিয়া দিব? কিন্তু দ্বারের ওপারে কী আছে?\\nআবার সজোরে ধাক্কা পড়িল; বরদা আবার চোখের নীরব ইঙ্গিতে আমাকে দ্বার খুলিয়া দিতে বলিল। আমি মোহাচ্ছন্নের মতো উঠিয়া গিয়া দ্বারের হুড়কা খুলিয়া দিলাম।\\nঅধীর হস্তে কব…'\n",
      "\n",
      "=== 115 ===\n",
      "chunk.text:\n",
      "'বরদা বলিয়া উঠিল, ‘আরে, তোমরা এসেছ? আমি একটা কাজে বেরিয়েছিলুম—’ আমাদের মুখ দেখিয়া বরদা অর্ধপথে থামিয়া গেল।\\nআমরা সকলে, যে মোড়ায় বরদা বসিয়াছিল সেই দিকে ফিরিলাম। দেখিলাম, মোড়ায় যে বসিয়াছিল সে নাই—মোড়া খালি।\\nএই সময় বাহিরে বরদার কুকুরটা কান্নার মতো একটা দীর্ঘ একটানা সুরে ডাকিয়া উঠিল।…'\n",
      "chunker.contextualize(chunk):\n",
      "'বরদা বলিয়া উঠিল, ‘আরে, তোমরা এসেছ? আমি একটা কাজে বেরিয়েছিলুম—’ আমাদের মুখ দেখিয়া বরদা অর্ধপথে থামিয়া গেল।\\nআমরা সকলে, যে মোড়ায় বরদা বসিয়াছিল সেই দিকে ফিরিলাম। দেখিলাম, মোড়ায় যে বসিয়াছিল সে নাই—মোড়া খালি।\\nএই সময় বাহিরে বরদার কুকুরটা কান্নার মতো একটা দীর্ঘ একটানা সুরে ডাকিয়া উঠিল।…'\n",
      "\n",
      "=== 116 ===\n",
      "chunk.text:\n",
      "'বরদা সেই ডাক শুনিয়া তীক্ষ্ণ চক্ষে আমাদের পানে চাহিল, তারপর ব্যগ্র কণ্ঠে বলিল, ‘অ্যাঁ! তবে কি—?’\\nআমি অতি কষ্টে গলা হইতে আওয়াজ বাহির করিলাম, ‘হ্যাঁ। অতিথি-সৎকারের কোনও ত্রুটি হয়নি। কিন্তু ভাই, আজ রাত্রেই আমরা বাড়ি ফিরব।\\nবরদা বলিল, ‘ওস্তাদ কাফি খাঁর সেতার শুনেছ?’…'\n",
      "chunker.contextualize(chunk):\n",
      "'বরদা সেই ডাক শুনিয়া তীক্ষ্ণ চক্ষে আমাদের পানে চাহিল, তারপর ব্যগ্র কণ্ঠে বলিল, ‘অ্যাঁ! তবে কি—?’\\nআমি অতি কষ্টে গলা হইতে আওয়াজ বাহির করিলাম, ‘হ্যাঁ। অতিথি-সৎকারের কোনও ত্রুটি হয়নি। কিন্তু ভাই, আজ রাত্রেই আমরা বাড়ি ফিরব।\\nবরদা বলিল, ‘ওস্তাদ কাফি খাঁর সেতার শুনেছ?’…'\n",
      "\n",
      "=== 117 ===\n",
      "chunk.text:\n",
      "'ক্লাবের পাঠাগারে আমরা কয়েকজন নীরবে বসিয়া সাময়িক পত্রিকার পাতা উল্টাইতেছিলাম। অমুল্য পত্রিকা হইতে চোখ তুলিয়া কিছুক্ষণ ভ্রূকুটি করিয়া রহিল, তারপর বলিল, ‘মতলবটা কি? নতুন আষাঢ়ে গল্প তৈরি করেছ, তাই শোনাতে চাও?’…'\n",
      "chunker.contextualize(chunk):\n",
      "'ক্লাবের পাঠাগারে আমরা কয়েকজন নীরবে বসিয়া সাময়িক পত্রিকার পাতা উল্টাইতেছিলাম। অমুল্য পত্রিকা হইতে চোখ তুলিয়া কিছুক্ষণ ভ্রূকুটি করিয়া রহিল, তারপর বলিল, ‘মতলবটা কি? নতুন আষাঢ়ে গল্প তৈরি করেছ, তাই শোনাতে চাও?’…'\n",
      "\n",
      "=== 118 ===\n",
      "chunk.text:\n",
      "'বরদা কর্ণপাত করিল না, গল্প আরম্ভ করিয়া দিল— পূজোর ছুটিতে শ্বশুরবাড়ি গিয়েছিলাম। আমার ছোট শালা শুভেন্দুর ভারি গান বাজনার শখ, একদিন আমাকে বলল—‘জামাইবাবু, ওস্তাদ কাফি খাঁর সেতার শুনতে যাবেন? ওস্তাদজি আমাকে খুব ভালবাসেন; কয়েকদিনের জন্য শহরে এসেছেন, ডাকবাংলোতে আছেন। আমি খবর পেয়েই ছুটে গিয়েছিলাম; তিন…'\n",
      "chunker.contextualize(chunk):\n",
      "'বরদা কর্ণপাত করিল না, গল্প আরম্ভ করিয়া দিল— পূজোর ছুটিতে শ্বশুরবাড়ি গিয়েছিলাম। আমার ছোট শালা শুভেন্দুর ভারি গান বাজনার শখ, একদিন আমাকে বলল—‘জামাইবাবু, ওস্তাদ কাফি খাঁর সেতার শুনতে যাবেন? ওস্তাদজি আমাকে খুব ভালবাসেন; কয়েকদিনের জন্য শহরে এসেছেন, ডাকবাংলোতে আছেন। আমি খবর পেয়েই ছুটে গিয়েছিলাম; তিন…'\n",
      "\n",
      "=== 119 ===\n",
      "chunk.text:\n",
      "'থাকবে না তখন বাজনা শোনাবেন। যাবেন আপনি আমার সঙ্গে?’\\nনেই কাজ তো খই ভাজ। উচ্চাঙ্গ গান-বাজনার প্রতি আমার বিশেষ আসক্তি নেই; ধ্রুপদ চৌতাল ধামার দশকুশী বুঝি না; রবীন্দ্র-সঙ্গীতেই আমার আত্মা পরিতুষ্ট। কিন্তু বিনা মাশুলে যখন এতবড় একজন ওস্তাদের বাজনা শোনার সুযোগ হয়েছে তখন ছাড়ি কেন। বললাম— ‘আচ্ছা যাব।’…'\n",
      "chunker.contextualize(chunk):\n",
      "'থাকবে না তখন বাজনা শোনাবেন। যাবেন আপনি আমার সঙ্গে?’\\nনেই কাজ তো খই ভাজ। উচ্চাঙ্গ গান-বাজনার প্রতি আমার বিশেষ আসক্তি নেই; ধ্রুপদ চৌতাল ধামার দশকুশী বুঝি না; রবীন্দ্র-সঙ্গীতেই আমার আত্মা পরিতুষ্ট। কিন্তু বিনা মাশুলে যখন এতবড় একজন ওস্তাদের বাজনা শোনার সুযোগ হয়েছে তখন ছাড়ি কেন। বললাম— ‘আচ্ছা যাব।’…'\n",
      "\n",
      "=== 120 ===\n",
      "chunk.text:\n",
      "'রাত্রি আন্দাজ নটার সময় খাওয়া-দাওয়া সেরে ডাকবাংলোতে উপস্থিত হলাম। জায়গাটা বেশ নিরিবিলি, পাঁচিল-ঘেরা উঁচু ভিতের বাড়ি, বাড়ির সামনে চার ফুট উঁচু চাতাল। এই চাতালের ওপর আলোয়ান গায়ে দিয়ে একটি বৃদ্ধ বসে আছেন, তাঁর পাশে একটি সেতার শোয়ানো রয়েছে।…'\n",
      "chunker.contextualize(chunk):\n",
      "'রাত্রি আন্দাজ নটার সময় খাওয়া-দাওয়া সেরে ডাকবাংলোতে উপস্থিত হলাম। জায়গাটা বেশ নিরিবিলি, পাঁচিল-ঘেরা উঁচু ভিতের বাড়ি, বাড়ির সামনে চার ফুট উঁচু চাতাল। এই চাতালের ওপর আলোয়ান গায়ে দিয়ে একটি বৃদ্ধ বসে আছেন, তাঁর পাশে একটি সেতার শোয়ানো রয়েছে।…'\n",
      "\n",
      "=== 121 ===\n",
      "chunk.text:\n",
      "'পরিষ্কার চাঁদের আলোয় ওস্তাদজিকে দেখলাম। লম্বা একহারা চেহারা, মাথায় পাকা বাব্\\u200cরি চুল, চিবুকে ত্রিকোণ দাড়ি। বয়স অনুমান করা শক্ত, তবে সত্তরের কাছাকাছি। শ্যালক ভূমিষ্ঠ হয়ে প্রণাম করল। ওস্তাদজি স্নিগ্ধ স্বরে বললেন— ‘এস বাবা। সঙ্গে ওটি কে?’…'\n",
      "chunker.contextualize(chunk):\n",
      "'পরিষ্কার চাঁদের আলোয় ওস্তাদজিকে দেখলাম। লম্বা একহারা চেহারা, মাথায় পাকা বাব্\\u200cরি চুল, চিবুকে ত্রিকোণ দাড়ি। বয়স অনুমান করা শক্ত, তবে সত্তরের কাছাকাছি। শ্যালক ভূমিষ্ঠ হয়ে প্রণাম করল। ওস্তাদজি স্নিগ্ধ স্বরে বললেন— ‘এস বাবা। সঙ্গে ওটি কে?’…'\n",
      "\n",
      "=== 122 ===\n",
      "chunk.text:\n",
      "'শালা পরিচয় করিয়ে দিল, আমিও হেঁট হয়ে প্রণাম করলাম। ওস্তাদজিকে দেখে তিনি হিন্দু কি মুসলমান এ কথা মনে আসে না। মনে হয় তিনি একটি প্রশান্তচিত্ত সাধক। সাধকের জাত নেই।\\nশালা জিজ্ঞেস করল— ‘আজ কেউ আসেনি?’\\nওস্তাদজি একটু ম্লান হেসে বললেন— ‘এসেছিল কয়েকজন রঈস্ লোক, আধঘণ্টা বাজনা শুনে বাহবা দিতে দিতে চলে গেল।—…'\n",
      "chunker.contextualize(chunk):\n",
      "'শালা পরিচয় করিয়ে দিল, আমিও হেঁট হয়ে প্রণাম করলাম। ওস্তাদজিকে দেখে তিনি হিন্দু কি মুসলমান এ কথা মনে আসে না। মনে হয় তিনি একটি প্রশান্তচিত্ত সাধক। সাধকের জাত নেই।\\nশালা জিজ্ঞেস করল— ‘আজ কেউ আসেনি?’\\nওস্তাদজি একটু ম্লান হেসে বললেন— ‘এসেছিল কয়েকজন রঈস্ লোক, আধঘণ্টা বাজনা শুনে বাহবা দিতে দিতে চলে গেল।—…'\n",
      "\n",
      "=== 123 ===\n",
      "chunk.text:\n",
      "'গুণিজনের পক্ষে অরসিকেষু রসস্য নিবেদনম্ কতখানি পীড়াদায়ক তা জানি বলেই নিজের কথা ভেবে মনে মনে সন্ত্রস্ত হয়ে উঠলাম। ওস্তাদজি যাতে আমার অজ্ঞতা ধরতে না পারেন সে বিষয়ে সতর্ক থাকা দরকার।\\nওস্তাদজি সেতারের ওপর হাত রেখে শালাকে বললেন— ‘কী শুনতে চাও বল।’\\nশালা হাত জোড় করে বলল— ‘অনেকদিন আপনার মালকোষ শুনিনি।’…'\n",
      "chunker.contextualize(chunk):\n",
      "'গুণিজনের পক্ষে অরসিকেষু রসস্য নিবেদনম্ কতখানি পীড়াদায়ক তা জানি বলেই নিজের কথা ভেবে মনে মনে সন্ত্রস্ত হয়ে উঠলাম। ওস্তাদজি যাতে আমার অজ্ঞতা ধরতে না পারেন সে বিষয়ে সতর্ক থাকা দরকার।\\nওস্তাদজি সেতারের ওপর হাত রেখে শালাকে বললেন— ‘কী শুনতে চাও বল।’\\nশালা হাত জোড় করে বলল— ‘অনেকদিন আপনার মালকোষ শুনিনি।’…'\n",
      "\n",
      "=== 124 ===\n",
      "chunk.text:\n",
      "'ওস্তাদজি আস্তে আস্তে সেতারটি কোলে তুলে নিলেন, আঙুলের মেরজাপ্\\u200c পরে তারের ওপর মৃদু স্পর্শ করলেন; তারগুলি রণ্\\u200cরণ্\\u200c করে উঠল। তারপর তিনি সেতারের কানে মোচড় দিয়ে তারগুলি বেঁধে নিতে নিতে বললেন— ‘এখন হেমন্ত কাল, রাত্রি দ্বিতীয় প্রহরও আরম্ভ হয়ে গেছে। মালকোষ বাজাবার উপযুক্ত সময় বটে।’…'\n",
      "chunker.contextualize(chunk):\n",
      "'ওস্তাদজি আস্তে আস্তে সেতারটি কোলে তুলে নিলেন, আঙুলের মেরজাপ্\\u200c পরে তারের ওপর মৃদু স্পর্শ করলেন; তারগুলি রণ্\\u200cরণ্\\u200c করে উঠল। তারপর তিনি সেতারের কানে মোচড় দিয়ে তারগুলি বেঁধে নিতে নিতে বললেন— ‘এখন হেমন্ত কাল, রাত্রি দ্বিতীয় প্রহরও আরম্ভ হয়ে গেছে। মালকোষ বাজাবার উপযুক্ত সময় বটে।’…'\n",
      "\n",
      "=== 125 ===\n",
      "chunk.text:\n",
      "'চারিদিকে জ্যোৎস্না ঝিমঝিম করছে; দূর থেকে শহরের যেটুকু শব্দ আসছে তাও যেন দূরত্বের দ্বারা মোলায়েম হয়ে আসছে। ওস্তাদজি যন্ত্র বেঁধে নিয়ে বললেন—‘মালকোষ বাজাচ্ছি। একটা কথা বলে রাখি, যদি কিছু দেখতে পাও ভয় পেয়ো না।’…'\n",
      "chunker.contextualize(chunk):\n",
      "'চারিদিকে জ্যোৎস্না ঝিমঝিম করছে; দূর থেকে শহরের যেটুকু শব্দ আসছে তাও যেন দূরত্বের দ্বারা মোলায়েম হয়ে আসছে। ওস্তাদজি যন্ত্র বেঁধে নিয়ে বললেন—‘মালকোষ বাজাচ্ছি। একটা কথা বলে রাখি, যদি কিছু দেখতে পাও ভয় পেয়ো না।’…'\n",
      "\n",
      "=== 126 ===\n",
      "chunk.text:\n",
      "'ওস্তাদজি নিতান্ত সহজভাবেই কথাটা বললেন, কিন্তু আমি সচকিত হয়ে উঠলাম। ওস্তাদজি আমার দিকে চেয়ে বললেন— ‘মালকোষ যদি শুদ্ধভাবে বাজানো যায় তাহলে জিনও আসে। ওরা মালকোষ রাগ শুনতে বড় ভালবাসে।’…'\n",
      "chunker.contextualize(chunk):\n",
      "'ওস্তাদজি নিতান্ত সহজভাবেই কথাটা বললেন, কিন্তু আমি সচকিত হয়ে উঠলাম। ওস্তাদজি আমার দিকে চেয়ে বললেন— ‘মালকোষ যদি শুদ্ধভাবে বাজানো যায় তাহলে জিনও আসে। ওরা মালকোষ রাগ শুনতে বড় ভালবাসে।’…'\n",
      "\n",
      "=== 127 ===\n",
      "chunk.text:\n",
      "'জিন্! আরব দেশের দৈত্য বিশেষ। আমি ভূত-প্রেত নিয়ে অনেক নাড়াচাড়া করেছি, কিন্তু জিন্\\u200c জাতীয় জীবের সঙ্গে কখনো মূলাকাৎ হয়নি। ওরা আরব্য রজনীর কাল্পনিক প্রাণী, এই ধারণাই ছিল। এখন মালকোষ শোনবার জন্যে তারা আসতে পারে এই কথা ভেবে মনটা বেশ উৎসুক হয়ে উঠল।…'\n",
      "chunker.contextualize(chunk):\n",
      "'জিন্! আরব দেশের দৈত্য বিশেষ। আমি ভূত-প্রেত নিয়ে অনেক নাড়াচাড়া করেছি, কিন্তু জিন্\\u200c জাতীয় জীবের সঙ্গে কখনো মূলাকাৎ হয়নি। ওরা আরব্য রজনীর কাল্পনিক প্রাণী, এই ধারণাই ছিল। এখন মালকোষ শোনবার জন্যে তারা আসতে পারে এই কথা ভেবে মনটা বেশ উৎসুক হয়ে উঠল।…'\n",
      "\n",
      "=== 128 ===\n",
      "chunk.text:\n",
      "'ওস্তাদজি বাজাতে শুরু করলেন। লক্ষ্য করলাম, তাঁর হাতের আঙুলগুলো লোহার তারের মতো বাঁকা-বাঁকা, কঠিন; কিন্তু সেতারের তারের ওপর তাদের স্পর্শ কি নরম! যেন ফুলের বাগানে মৌমাছি গুঞ্জন করে বেড়াচ্ছে। তিনি প্রথমে খুব ঠায়ে বাজতে শুরু করলেন, তারপর আস্তে আস্তে তালের গতি দ্রুত হতে লাগল। আমি উচ্চসঙ্গীতের সমঝদার নই …'\n",
      "chunker.contextualize(chunk):\n",
      "'ওস্তাদজি বাজাতে শুরু করলেন। লক্ষ্য করলাম, তাঁর হাতের আঙুলগুলো লোহার তারের মতো বাঁকা-বাঁকা, কঠিন; কিন্তু সেতারের তারের ওপর তাদের স্পর্শ কি নরম! যেন ফুলের বাগানে মৌমাছি গুঞ্জন করে বেড়াচ্ছে। তিনি প্রথমে খুব ঠায়ে বাজতে শুরু করলেন, তারপর আস্তে আস্তে তালের গতি দ্রুত হতে লাগল। আমি উচ্চসঙ্গীতের সমঝদার নই …'\n",
      "\n",
      "=== 129 ===\n",
      "chunk.text:\n",
      "'বলছে—হামারি দুখের নাহি ওর—\\nআমার শালা সত্যিকারের রসজ্ঞ লোক। সে মাথা নাড়ছে না, ঊরুতে তাল ঠুকছে না, ঘাড় নীচু করে স্থির হয়ে বসে আছে। আমিও একটা নিবিড় অনুভূতির মধ্যে ডুবে গেছি। এই ভাবে কতক্ষণ কেটে গিয়েছে জানি না, বোধহয় কুড়ি-পঁচিশ মিনিট হবে। এক সময় অনুভব করলাম, নাকে একটা গন্ধ আসছে। স্থান কাল বিবেচন…'\n",
      "chunker.contextualize(chunk):\n",
      "'বলছে—হামারি দুখের নাহি ওর—\\nআমার শালা সত্যিকারের রসজ্ঞ লোক। সে মাথা নাড়ছে না, ঊরুতে তাল ঠুকছে না, ঘাড় নীচু করে স্থির হয়ে বসে আছে। আমিও একটা নিবিড় অনুভূতির মধ্যে ডুবে গেছি। এই ভাবে কতক্ষণ কেটে গিয়েছে জানি না, বোধহয় কুড়ি-পঁচিশ মিনিট হবে। এক সময় অনুভব করলাম, নাকে একটা গন্ধ আসছে। স্থান কাল বিবেচন…'\n",
      "\n",
      "=== 130 ===\n",
      "chunk.text:\n",
      "'শুকনো তামাক পাতার কড়া গন্ধ! এতক্ষণ অর্ধনিমীলিত নেত্রে বাজনা শুনছিলাম, এখন চোখ আর একটু খুলে এদিক ওদিক তাকালাম। কই, তামাক পাতা তো কোথাও নেই। ওস্তাদজি ঘাড় গুঁজে বাজিয়ে চলেছেন, শালা নিবাত নিষ্কম্প বসে আছে। অন্য মানুষও কেউ আসেনি। তবে?\\nহঠাৎ নজর পড়ল চাতালের নীচে মাটির ওপর। বুকটা একবার গুরগুর করে উঠল—…'\n",
      "chunker.contextualize(chunk):\n",
      "'শুকনো তামাক পাতার কড়া গন্ধ! এতক্ষণ অর্ধনিমীলিত নেত্রে বাজনা শুনছিলাম, এখন চোখ আর একটু খুলে এদিক ওদিক তাকালাম। কই, তামাক পাতা তো কোথাও নেই। ওস্তাদজি ঘাড় গুঁজে বাজিয়ে চলেছেন, শালা নিবাত নিষ্কম্প বসে আছে। অন্য মানুষও কেউ আসেনি। তবে?\\nহঠাৎ নজর পড়ল চাতালের নীচে মাটির ওপর। বুকটা একবার গুরগুর করে উঠল—…'\n",
      "\n",
      "=== 131 ===\n",
      "chunk.text:\n",
      "'আমি বসেছিলাম চার ফুট উঁচু চাতালের কিনারা ঘেঁষে, নীচে নজর পড়তেই বুঝলাম গন্ধটা কোথা থেকে আসছে। ঠিক চাতালের নীচেই একটা প্রকাণ্ড মানুষ উপুড় হয়ে শুয়ে আছে। চাঁদের আলোয় তার চেহারা পরিষ্কার দেখতে পাচ্ছি, নিকষের মতো কালো গায়ের রঙ, আট হাত লম্বা তাগড়া শরীর, সর্বাঙ্গে লোহার শলার মতো রোঁয়া খাড়া হয়ে রয়…'\n",
      "chunker.contextualize(chunk):\n",
      "'আমি বসেছিলাম চার ফুট উঁচু চাতালের কিনারা ঘেঁষে, নীচে নজর পড়তেই বুঝলাম গন্ধটা কোথা থেকে আসছে। ঠিক চাতালের নীচেই একটা প্রকাণ্ড মানুষ উপুড় হয়ে শুয়ে আছে। চাঁদের আলোয় তার চেহারা পরিষ্কার দেখতে পাচ্ছি, নিকষের মতো কালো গায়ের রঙ, আট হাত লম্বা তাগড়া শরীর, সর্বাঙ্গে লোহার শলার মতো রোঁয়া খাড়া হয়ে রয়…'\n",
      "\n",
      "=== 132 ===\n",
      "chunk.text:\n",
      "'ভূত-প্রেত দেখে ডরিয়ে ওঠার দিন আমার নেই, কিন্তু সাষ্টাঙ্গ প্রণামরত বিরাট দৈত্যটাকে দেখে বুকের রক্ত হিম হয়ে আসতে লাগল। তারপর ঘাড় বেঁকিয়ে দেখি, আমার ঠিক পিছনে আর একটা দৈত্য লম্বা হয়ে শুয়ে মালকোষ শুনছে।…'\n",
      "chunker.contextualize(chunk):\n",
      "'ভূত-প্রেত দেখে ডরিয়ে ওঠার দিন আমার নেই, কিন্তু সাষ্টাঙ্গ প্রণামরত বিরাট দৈত্যটাকে দেখে বুকের রক্ত হিম হয়ে আসতে লাগল। তারপর ঘাড় বেঁকিয়ে দেখি, আমার ঠিক পিছনে আর একটা দৈত্য লম্বা হয়ে শুয়ে মালকোষ শুনছে।…'\n",
      "\n",
      "=== 133 ===\n",
      "chunk.text:\n",
      "'আর একটু হলেই হাউমাউ করে উঠেছিলাম আর কি! অতি কষ্টে সামলে নিলাম। তারপর চোখ বুজে বসে রইলাম। চোখ খুলে তাকাবার সাহস নেই, হয়তো দেখব আরও অনেকগুলি আট হাত লম্বা জিন্ ভূমিষ্ঠ হয়ে মালকোষ শুনছে।…'\n",
      "chunker.contextualize(chunk):\n",
      "'আর একটু হলেই হাউমাউ করে উঠেছিলাম আর কি! অতি কষ্টে সামলে নিলাম। তারপর চোখ বুজে বসে রইলাম। চোখ খুলে তাকাবার সাহস নেই, হয়তো দেখব আরও অনেকগুলি আট হাত লম্বা জিন্ ভূমিষ্ঠ হয়ে মালকোষ শুনছে।…'\n",
      "\n",
      "=== 134 ===\n",
      "chunk.text:\n",
      "'ভাই, আমি নানা জাতের ভূত দেখেছি, কিন্তু ভূতের গা দিয়ে তামাক পাতার গন্ধ বেরোয় এবং তারা উপুড় হয়ে শুয়ে মালকোষ শুনতে ভালবাসে এ কথা জানা ছিল না। আরব্য উপন্যাসেও কিছু লেখেনি। হয়তো আরব দেশের ভূত এমনিই হয়। মালকোষ সুরটা কিন্তু খাঁটি ভারতীয় সুর, তার আদি নাম মল্লকৌষিক।…'\n",
      "chunker.contextualize(chunk):\n",
      "'ভাই, আমি নানা জাতের ভূত দেখেছি, কিন্তু ভূতের গা দিয়ে তামাক পাতার গন্ধ বেরোয় এবং তারা উপুড় হয়ে শুয়ে মালকোষ শুনতে ভালবাসে এ কথা জানা ছিল না। আরব্য উপন্যাসেও কিছু লেখেনি। হয়তো আরব দেশের ভূত এমনিই হয়। মালকোষ সুরটা কিন্তু খাঁটি ভারতীয় সুর, তার আদি নাম মল্লকৌষিক।…'\n",
      "\n",
      "=== 135 ===\n",
      "chunk.text:\n",
      "'ওস্তাদজির বাজনা ধীরে ধীরে শেষ হয়ে আসছে। যেন একটা মর্মন্তুদ বিলাপ ফুঁপিয়ে ফুপিয়ে কেঁদে কেঁদে ঘুমিয়ে পড়ল। ওস্তাদজি কিছুক্ষণ সেই ভাবে বসে রইলেন, তারপর আস্তে আস্তে সেতার নামিয়ে রাখলেন।\\nআমি চোখ বুজে বসে বসে অনুভব করলাম তামাক পাতার গন্ধটা মিলিয়ে যাচ্ছে। ভয়ে ভয়ে এদিক ওদিক তাকালাম, কাউকে দেখতে পেলা…'\n",
      "chunker.contextualize(chunk):\n",
      "'ওস্তাদজির বাজনা ধীরে ধীরে শেষ হয়ে আসছে। যেন একটা মর্মন্তুদ বিলাপ ফুঁপিয়ে ফুপিয়ে কেঁদে কেঁদে ঘুমিয়ে পড়ল। ওস্তাদজি কিছুক্ষণ সেই ভাবে বসে রইলেন, তারপর আস্তে আস্তে সেতার নামিয়ে রাখলেন।\\nআমি চোখ বুজে বসে বসে অনুভব করলাম তামাক পাতার গন্ধটা মিলিয়ে যাচ্ছে। ভয়ে ভয়ে এদিক ওদিক তাকালাম, কাউকে দেখতে পেলা…'\n",
      "\n",
      "=== 136 ===\n",
      "chunk.text:\n",
      "'ওস্তাদজি আমার দিকে সপ্রশ্ন চোখে চাইলেন— ‘ওরা এসেছিল নাকি?’\\nবললাম— ‘এসেছিল।’\\nতিনি তৃপ্তস্বরে বললেন— ‘আজ বাজানো ভাল হয়েছে; মন বসে গিয়েছিল। তোমরা ভয় পাওনি তো?’\\nএতক্ষণে শালার ধ্যানভঙ্গ হল। সে পকেট থেকে একটি রুমাল এবং একটি গিনি বার করল; গিনি রুমালের ওপর রেখে রুমাল ওস্তাদজির পায়ের কাছে রাখল। তারপর লম্…'\n",
      "chunker.contextualize(chunk):\n",
      "'ওস্তাদজি আমার দিকে সপ্রশ্ন চোখে চাইলেন— ‘ওরা এসেছিল নাকি?’\\nবললাম— ‘এসেছিল।’\\nতিনি তৃপ্তস্বরে বললেন— ‘আজ বাজানো ভাল হয়েছে; মন বসে গিয়েছিল। তোমরা ভয় পাওনি তো?’\\nএতক্ষণে শালার ধ্যানভঙ্গ হল। সে পকেট থেকে একটি রুমাল এবং একটি গিনি বার করল; গিনি রুমালের ওপর রেখে রুমাল ওস্তাদজির পায়ের কাছে রাখল। তারপর লম্…'\n",
      "\n",
      "=== 137 ===\n",
      "chunk.text:\n",
      "'তার ভূমিষ্ঠ প্রণামের ভঙ্গি দেখে মনে হল সেও একটি ছোটখাটো জিন্…'\n",
      "chunker.contextualize(chunk):\n",
      "'তার ভূমিষ্ঠ প্রণামের ভঙ্গি দেখে মনে হল সেও একটি ছোটখাটো জিন্…'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for i, chunk in enumerate(chunk_iter):\n",
    "    print(f\"=== {i} ===\")\n",
    "    print(f\"chunk.text:\\n{f'{chunk.text[:300]}…'!r}\")\n",
    "\n",
    "    enriched_text = chunker.contextualize(chunk=chunk)\n",
    "    print(f\"chunker.contextualize(chunk):\\n{f'{enriched_text[:300]}…'!r}\")\n",
    "    texts.append(enriched_text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e957f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BASIC PURCHASE AGREEMENT\\nThis Agreement is made by and between Sevensix Inc., a corporation organized and existing under the laws of Japan, having its principal place of business at 17F Roppongi Hills Mori tower, 6-10-1, Roppongi, Minato-ku, Tokyo , Japan ( \" Buyer \" ) and 3Coptics Co., Ltd., a corporation organized and existing under the laws of China, having its principal place of business at No.10, Kexing Road, NanShan District, Shenzhen, China( \" Seller \" ).',\n",
       " \"Recitals:\\nWHEREAS, Seller has developed and manufactures the Products (hereinafter defined); and WHEREAS, Buyer desires to purchase such Products from Seller for reselling to Buyer's customer, and Seller desires to sell the same to Buyer.\\nNOW THEREFORE, in consideration of the terms and conditions set forth herein, the parties hereby agree as follows:\",\n",
       " 'Article 1 Sales and Purchase\\nSeller agrees to sell and deliver to Buyer, and Buyer agrees to purchase and take delivery from Seller of, the Products (hereinafter defined) in accordance with and subject to the terms and conditions set forth herein.',\n",
       " 'Article 2 Products\\n- (1) The Products are listed and defined in Appendix 1. New products can be added to this Agreement by mutual written agreement.\\n- (2) Each Product sold and purchased hereunder shall meet the specifications to be agreed beforehand in writing between Buyer and Seller.\\nSeller is not entitled to change the specifications of the Products during the term of this Agreement without Buyer b s written consent.\\n- (3) Seller shall promptly inform Buyer of any modifications or improvements to the Products.\\n2. Buyer shall have the right to purchase such modifications or improvements, at its sole discretion, in accordance with the terms and conditions herein set forth.',\n",
       " 'Article 3 Individual Contract\\nThe specific items, quantity, price, delivery date, delivery location, and other specific contents of the sales contract of the product that Seller sells to Buyer are specified in the individual contract. However, an alternative method may be determined after consultation between the parties.',\n",
       " 'Article 4 Payment\\nBuyer shall pay to Seller the prices of the Products sold and purchased hereunder in US dollar by means of telegraphic transfer to the bank account designated by Seller thirty(30) days after the date of the multimodal transport bill of lading concerning the Products.',\n",
       " 'Article 5 Consignment\\n- (1) Seller shall deliver the Products to the carrier nominated by Buyer at the place designated by Buyer on a FCA Shenzhen basis. The date of the multimodal transport bill of lading shall be deemed as conclusive evidence of the date of delivery.\\n- (2) Partial shipments shall be allowed.\\n- (3) Seller shall assist Buyer in arranging vessel and cargo insurance.',\n",
       " 'Article 6 Title and Risk\\nTitle and risk of loss for each delivery of the Products shall pass from Seller to Buyer at the time such Products are placed at the disposal of the carrier nominated by Buyer on Seller b s means of transport ready for unloading.',\n",
       " \"Article 7 Inspection, defect warranty liability\\n- (1) After receiving the delivery of the product from Seller, Buyer immediately inspects the item, quantity, appearance, quality, etc. of the product, and if there is a difference from the order contents and defects in appearance, quality, etc. , Must notify Seller within 14 days after delivery.\\n- (2) If Seller receives the notification set forth in the preceding paragraph within 14 days after delivery, Seller will investigate the notified product, and if it is confirmed that the quantity is insufficient or the existence of a defect is confirmed, Buyer is entitled to defer payment of the product, and Seller reset the delivery date of replacement or additional products. For overquantity, item differences, or defective products, Buyer shall take measures to return or dispose of the products according to Seller's choice. Seller shall bear the cost of returning or disposing of the product.\\n- (3) The provisions of this Article stipulate all of Seller's liability for defects in the product, and shall replace the legal liability for defects.\\n- (4) The provisions of each paragraph of this Article shall apply mutatis mutandis to redelivered products.\",\n",
       " 'Article 7 Inspection, defect warranty liability\\n- (5) When a product can identify the existence of the defect, the buyer can reprieve payment to affect the product. The buyer shall pay the product price to the bank account that the seller\\nappoints within 30 days after the delivery of the product without the defect.',\n",
       " 'Article 8 Warranty\\n- (1) Seller shall convey to Buyer good and merchantable title to the Products free and clear of any encumbrance, lien or security interest. Seller warrants that all Products shall be of the quality specified in the product specification sheet and otherwise conform exactly to the drawings, samples, or other specifications, if any, in all respects.\\n- (2) Seller also warrants that all Products shall be free from any defects in design, materials or workmanship and shall be fit for the intended purpose of Buyer expressed in writing from time to time.\\n- (3) Seller further warrants that the quality of the Products shall not change in transportation and for a period of five (5) years from the date of delivery to Buyer.',\n",
       " 'Article 8 Warranty\\n- (4) This warranty shall survive any inspection, acceptance or payment by Buyer. In the event of any breach by Seller of any of its warranties set forth herein, Buyer shall have the right, at its sole discretion, either to request Seller to repair or replace defective Products or any parts thereof, or to refund a portion of the sales price applicable thereto at Seller b s expense without prejudice to any other remedy, and Seller shall be responsible for report of investigation on cause of the defect which Buyer requests, and Seller shall be liable for all loss and/or damage, direct or consequential, caused by Seller b s breach of any of the warranties hereunder.\\n- (5) By the request of the buyer, the buyer returns the product concerned for a seller, and the buyer shall take responsibility to report a cause investigation and the findings that the buyer demands to the seller for trouble, an obstacle, the defective merchandise which occurred during this term of a guarantee. It is decided that a seller bears the expense that it costs for the return of this product, and the buyer can return the product concerned to a seller on FCA Tokyo condition.',\n",
       " 'Article 9 Failure of Product\\n- (1) Definition of failure product\\nA product whose specifications do not match to the contents of the product specification sheet exchanged between the two parties in advance.\\n- (2) Necessary measures\\n2. (2-1) Seller should report any problems to Buyer as soon as possible. If the occurrence is confirmed on a lot-by-lot basis, give the highest priority.\\n3. (2-2) Seller shall present the information requested by Buyer when a failure occurs. The main information requested is as follows.\\n- a) Information that identifies the target item (product name, item code, model number, serial\\nnumber, etc.)\\n- b) Number of deliveries of target goods, delivery destination, delivery date\\n- c) Occurrence status\\n- d) Scope of influence (spreading to other products, etc.)\\n4. (2-3) To solve the problem. Present a specific solution to the problem, and decide the solution after consultation between the parties. The cooperation required for the work should be dealt with free of charge.',\n",
       " 'Article 10 Delivery\\nIf there is a delay in the delivery date agreed in advance between the parties for the product, Seller shall promptly notify Buyer and provide the following information.\\n- (1) Occurrence of delay of delivery date\\n- (2) Causes of delay of delivery date\\n- (3) Countermeasure\\n- (4) Forecast and time schedule until the standard delivery date is restored\\n- (5) Inventory status of products',\n",
       " 'Article 11 Product Liability\\n- (1) Seller shall indemnify and hold harmless Buyer, its employees, officers, agents and subcontractors from and against any and all actions, suits, administrative proceedings, claims, demands, losses, damages and costs and expenses of whatever nature including, without limitation, all attorney b s fees, for injury to or death of any individual, or any loss of or damage to property, which may arise from or in connection with any defect or alleged defect in design, manufacturing and/or warning of the Products.\\n- (2) Buyer may, but shall not be obliged to, obtain and maintain product liability insurance with insurers at the Seller b s expense under such terms and conditions deemed proper by Buyer, and subject to Seller b s reasonable approval, to cover any and all losses, damages, costs and expenses of whatever nature, which may arise from or in connection with any defect of alleged defect in design, manufacturing and/or warning of the Products. Seller shall pay or reimburse Buyer for all premiums incurred by Buyer for this product liability insurance.',\n",
       " 'Article 12 End of Sales, End of Production\\n- (1) Advance notification\\n- a) Seller shall notify Buyer at least six(6) months in advance when the seller discontinue to sell the product.\\n- b) Seller shall notify Buyer at least one(1) year in advance when the seller discontinue\\nproduction and support of the product.',\n",
       " '(2) Notification method\\nAdvance notification for the discontinue of sales, production, and support shall be notified in writing or by e-mail from the seller to the buyer.\\n- (3) Proposal of alternative products\\nWhen Seller propose a alternative for a discontinued product to Buyer, it shall be possible to purchase it at the same price or less without any degradation in performance or function.',\n",
       " 'Article 13 Business Continuity Plan\\nThe product that the Seller sell to the Buyer shall satisfy the following requirements regarding the supply chain.\\nIf the manufacturer of the product is different from Seller, Seller shall guarantees that the manufacturer meets the following requirements. If there are parties other than the seller and manufacturer in the supply chain and they play a role that corresponds the following requirements, Seller shall guarantees that those parties meet the requirements.\\nThe warranty shall be continued without interruption during the term of this agreement.',\n",
       " 'Article 13 Business Continuity Plan\\n- (1) Have established Business Continuity Plan requirements for the supplier or outsourcer of products and parts, or have grasped the distribution status of production / inventory storage bases and the target recovery time. Present the response status in response to the request from Buyer.\\n- (2) Countermeasures for risk of business continuity must be taken at the production, storage, and inspection bases of products and parts. In addition, grasp the products and parts that are produced, stored, and inspected at bases where risk countermeasures are not taken, and formulate risk hedging measures that will not extend the standard delivery date. Present the response status in response to the request from Buyer.\\n- (3) If you become aware of the possibility of affecting the supply chain, promptly report the situation to the Buyer even if it has not yet affected the supply chain. If you become aware of the fact that the supply chain will be affected and the delivery date will be extended more than 14 days from the standard lead time, even if no order has been placed, immediately report the situation to the Buyer.',\n",
       " 'Article 14 Intellectual Property Rights\\nSeller shall indemnify and hold harmless Buyer, its employees, officers, agents and sub- contractors from and against any and all actions, suites, administrative proceedings, claims, demands, losses, damages and costs and expenses of whatsoever nature including, without limitation, all attorney b s fees, which may arise from or in connection with infringement or alleged infringement of any patent, utility model, design, trademark, copyright or any other intellectual property rights including, without limitation, rights created under the Unfair Competition Prevention Act of Japan, in connection with the Products.',\n",
       " 'Article 15 Trademarks\\n- (1) Buyer shall have the right to use the trademarks of Seller (the \" Trademarks \" ) on the Products during the term of this Agreement.\\n- (2) Upon termination of this Agreement, any and all rights granted in this Article by Seller to Buyer shall automatically terminate and Buyer shall forthwith cease to use any Trademarks; provided, however, that even after the termination of this Agreement, Buyer may use the Trademarks in connection with the Products held in stock by it at the time of termination.',\n",
       " 'Article 16 Tax and Duty\\nAll customs duties, taxes, imposts, fees and other charges including, without limitation, the cost of any certificate of origin imposed on or required for the Products and sale thereof in the country of shipment, shall be borne by Seller. All corresponding charges including, without limitation, any import charges imposed in the country of destination shall be borne by Buyer.',\n",
       " 'Article 17 Term\\n- (1) The term of this Agreement shall commence on the date first above written and continue in full force and effect for one (1) years from the date of such commencement unless terminated earlier.\\n- (2) Unless either party gives to the other a written notice of its intention not to extend this Agreement at least six (6) months prior to the end of the initial term of this Agreement or any extension thereof, this Agreement shall be automatically extended for one (1) consecutive years.',\n",
       " 'Article 18 Termination\\n- (1) Either party may terminate this Agreement and/or any Individual Sales Contract if the other party fails to perform its obligations and undertakings of this Agreement, or otherwise commits a breach of this Agreement, and such default or breach is not cured within fourteen (14) days after written notice thereof.\\n- (2) This Agreement shall be automatically terminated without notice to the party if any of the\\nfollowing events occurs to such party:\\n- (a) General assignment by the party for the benefit of creditors;\\n- (b) Insolvency of the party; or,\\n- (c) Institution of voluntary or involuntary proceedings by or against the party in bankruptcy or under insolvency laws, or for corporate reorganization, or for a receivership, or for the dissolution of the party.\\n- (3) Unless otherwise set forth herein or unless otherwise expressly agreed upon between the parties, the termination of this Agreement shall not affect any outstanding Individual Sales Contracts that have been confirmed prior to such termination and such Individual Sales Contracts shall be executed in accordance with the terms of this Agreement.',\n",
       " 'Article 19 Assignment\\nNeither party shall assign, transfer or otherwise dispose of whole or any part of this Agreement, or any rights or obligations hereunder without the prior written consent of the other party. Any assignment, transfer or disposition made without such consent shall be null and void.',\n",
       " 'Article 20 Secrecy\\n(1) If either party expressly designates certain matters as the confidential information (\"Confidential Information\") at the time when such matters are disclosed by such party in connection with this Agreement, the other party ( \" Receiving Party \" ) shall keep such matters in strict confidence from any third party.\\nThe Confidential Information means any technical, commercial or business information which has proprietary value and which is not open to the public.\\nInformation stated clearly with the secret information as \"confidential information /Confidential\" to disclose for the other party by the person concerned of either and a document (including materiality, the E-mails such as the electronic mediums which stored away documents, electronic data).\\nIt was information except the technical information to affect business, administration to disclose for the other party, and, with the secret information, it was shown orally by the person concerned of either and it was shown a secret thing clearly on disclosure and was notified by letter for the other party within 30 days after disclosure.',\n",
       " 'Article 20 Secrecy\\n- (2) The obligation of secrecy shall not apply if the information sought to be disclosed is:\\n2. (a) in the possession of the Receiving Party at the time of its communication;\\n3. (b) in the public domain at the time it was communicated to the Receiving Party; or\\n4. (c) made public subsequent to the time of communication through no fault of the Receiving Party.\\n- (3) The obligation of secrecy shall be relieved if disclosure is required by law, regulations or orders (whether or not having the force of law) of a government authority or other organization having appropriate authority.',\n",
       " 'Article 21 Force Majeure\\nNeither party shall be liable to the other party for a failure or delay in the performance of any of its obligations under this Agreement for the period and to the extent such failure or delay is caused by riots, civil commotions, wars (declared or undeclared), hostilities between nations, governmental laws, orders or regulations, embargoes, actions by the government or any agency thereof, acts of God, storms, fires, accidents, strikes, sabotage, explosions, or other similar or different contingencies beyond the reasonable control of the respective parties.',\n",
       " 'Article 22 Notice\\n- (1) All notices, demands and other communications by one party to the other with respect to this Agreement shall be made in writing by registered airmail, postage prepaid, or facsimile, or electronic mail, or personal delivery at the addresses first above written, or at such other address as may be notified by such other party pursuant to the provisions of this Article from time to time.\\n- (2) All notices, demands and other communications mentioned above shall be deemed to have been given at the time of receipt when made by personal delivery, at the time of confirmation when made by facsimile or electronic mail, and seven (7) days after posting when made by registered airmail.',\n",
       " 'Article 23 Trade Terms\\nThe trade terms used under this Agreement and/or each Individual Sales Contract shall be governed by and interpreted in accordance with the provisions of Incoterms 2020 of the International Chamber of Commerce, or any subsequent revision or amendment thereto.',\n",
       " 'Article 24 Governing Law\\nThe validity, construction, performance and enforceability of this Agreement and/or each Individual Sales Contract shall be governed by and construed under the laws of Japan[, excluding the United Nations Convention on Contracts for the International Sale of Goods].',\n",
       " 'Article 25 Arbitration\\nAll disputes, controversies or differences arising out of or in connection with this contract shall be finally settled by arbitration in accordance with the Commercial Arbitration Rules of The\\nJapan Commercial Arbitration Association. The place of the arbitration shall be Tokyo, Japan.',\n",
       " 'Article 26 Entire Agreement and Modification\\n- (1) This Agreement constitutes the entire and only agreement between the parties and supersedes all previous or contemporaneous negotiations, agreements and commitments relating to the sale of the Products.\\n- (2) This Agreement shall not be modified or changed in any manner except by mutual written consent of subsequent date signed by a duly authorized representative of each of the parties.',\n",
       " 'Article 27 Headings\\nThe headings of articles used in this Agreement are inserted for reference only and shall not affect the interpretation of the respective articles of this Agreement.',\n",
       " 'Article 28 Language\\nThis Agreement shall be executed in English.',\n",
       " 'Article 29 Severability\\nIf any provision of this Agreement is subsequently held illegal, unenforceable or invalid by a court or other competent authority, such illegality, unenforceability or invalidity shall not affect the legality, enforceability and validity of any other provisions of this Agreement. The parties shall replace any such provision with a valid, legal and enforceable provision which most nearly conforms to their original intent.\\nIN WITNESS WHEREOF, the parties have caused this Agreement to be executed in duplicate by their duly authorized representatives as of the date first above written, each party retaining one copy thereof respectively.',\n",
       " 'Buyer :\\nSevensix Inc.\\nSign : ______________________\\nName : Yosuke Hane\\nTitle : Chief Executive Officer\\nSeller :\\n3Coptics co.,ltd.\\nSign : ___________________________\\nName : __________________________\\nTitle : ___________________________']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1aca95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data object\n",
    "data = []\n",
    "\n",
    "# Create a dictionary for each row by iterating through the corresponding lists\n",
    "for text in texts:\n",
    "    data_point = {\n",
    "        \"text\": text,\n",
    "    }\n",
    "    data.append(data_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c957d660",
   "metadata": {},
   "source": [
    "# WEAVIATE CONNECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86206ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbc/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.29.0 is exactly one major version older than the runtime version 6.31.1 at v1/aggregate.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/jbc/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.29.0 is exactly one major version older than the runtime version 6.31.1 at v1/base.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/jbc/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.29.0 is exactly one major version older than the runtime version 6.31.1 at v1/base_search.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/jbc/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.29.0 is exactly one major version older than the runtime version 6.31.1 at v1/batch_delete.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/jbc/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.29.0 is exactly one major version older than the runtime version 6.31.1 at v1/batch.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/jbc/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.29.0 is exactly one major version older than the runtime version 6.31.1 at v1/search_get.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/jbc/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.29.0 is exactly one major version older than the runtime version 6.31.1 at v1/generative.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/jbc/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.29.0 is exactly one major version older than the runtime version 6.31.1 at v1/properties.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/jbc/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.29.0 is exactly one major version older than the runtime version 6.31.1 at v1/tenants.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True  )\n",
    "headers = {\n",
    "    \"X-JinaAI-Api-Key\": os.getenv(\"JINAAI_API_KEY\")\n",
    "}\n",
    "client = weaviate.connect_to_local(headers=headers)\n",
    "# client.collections.delete_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf585527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Configure,Property,DataType\n",
    "\n",
    "collection= client.collections.create(\n",
    "    \"DemoCollection\",\n",
    "    vector_config=Configure.Vectors.text2vec_jinaai(\n",
    "        name=\"text_vector\",\n",
    "        model=\"jina-embeddings-v3\",\n",
    "        source_properties=[\"text\"]),\n",
    "    reranker_config=Configure.Reranker.jinaai(\"jina-reranker-v2-base-multilingual\"),\n",
    "    properties= [\n",
    "        Property(name=\"text\", data_type=DataType.TEXT, vectorize_property=True)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4364bdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert complete.\n"
     ]
    }
   ],
   "source": [
    "# Insert text chunks and metadata into vector DB collection\n",
    "response = collection.data.insert_many(data)\n",
    "\n",
    "if response.has_errors:\n",
    "    print(response.errors)\n",
    "else:\n",
    "    print(\"Insert complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "727a1665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Business_data_collection': _CollectionConfigSimple(name='Business_data_collection', description=None, generative_config=None, properties=[_Property(name='text', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer=None, vectorizer_configs={'text2vec-jinaai': _PropertyVectorizerConfig(skip=False, vectorize_property_name=False)}), _Property(name='path', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer=None, vectorizer_configs={'text2vec-jinaai': _PropertyVectorizerConfig(skip=False, vectorize_property_name=False)})], references=[], reranker_config=_RerankerConfig(model={'model': 'jina-reranker-v2-base-multilingual'}, reranker=<Rerankers.JINAAI: 'reranker-jinaai'>), vectorizer_config=None, vectorizer=None, vector_config={'text_vector': _NamedVectorConfig(vectorizer=_NamedVectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_JINAAI: 'text2vec-jinaai'>, model={'baseURL': 'https://api.jina.ai', 'model': 'jina-embeddings-v3', 'vectorizeClassName': True}, source_properties=['text']), vector_index_config=_VectorIndexConfigHNSW(multi_vector=None, quantizer=None, cleanup_interval_seconds=300, distance_metric=<VectorDistances.COSINE: 'cosine'>, dynamic_ef_min=100, dynamic_ef_max=500, dynamic_ef_factor=8, ef=-1, ef_construction=128, filter_strategy=<VectorFilterStrategy.SWEEPING: 'sweeping'>, flat_search_cutoff=40000, max_connections=32, skip=False, vector_cache_max_objects=1000000000000))})}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.collections.list_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd7e3a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.collections.get(\"Business_data_collection\")\n",
    "# client.collections.delete_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2714026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.query import MetadataQuery\n",
    "from weaviate.classes.query import Rerank\n",
    "response = collection.query.near_text(\n",
    "    query=\"MechanicsPOM cove\",\n",
    "    limit=5,\n",
    "    rerank=Rerank(\n",
    "        prop=\"text\",\n",
    "    ),\n",
    "    return_metadata=MetadataQuery(distance=True),\n",
    "    return_properties=[\"text\",\"source\"],\n",
    ")\n",
    "for o in response.objects:\n",
    "\n",
    "    print(o.properties[\"text\"])\n",
    "    print(o.metadata.distance)\n",
    "    print(o.metadata.rerank_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548d6386",
   "metadata": {},
   "source": [
    "#### with transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd92a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "client = weaviate.connect_to_local()\n",
    "import weaviate.classes.config as wc\n",
    "\n",
    "# Define the collection name\n",
    "collection_name = \"docling\"\n",
    "\n",
    "# Delete the collection if it already exists\n",
    "if client.collections.exists(collection_name):\n",
    "    client.collections.delete(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1f41ae78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DemoCollection': _CollectionConfigSimple(name='DemoCollection', description=None, generative_config=None, properties=[_Property(name='text', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer=None, vectorizer_configs={'text2vec-jinaai': _PropertyVectorizerConfig(skip=False, vectorize_property_name=False)})], references=[], reranker_config=_RerankerConfig(model={'model': 'jina-reranker-v2-base-multilingual'}, reranker=<Rerankers.JINAAI: 'reranker-jinaai'>), vectorizer_config=None, vectorizer=None, vector_config={'text_vector': _NamedVectorConfig(vectorizer=_NamedVectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_JINAAI: 'text2vec-jinaai'>, model={'baseURL': 'https://api.jina.ai', 'model': 'jina-embeddings-v3', 'vectorizeClassName': True}, source_properties=['text']), vector_index_config=_VectorIndexConfigHNSW(multi_vector=None, quantizer=None, cleanup_interval_seconds=300, distance_metric=<VectorDistances.COSINE: 'cosine'>, dynamic_ef_min=100, dynamic_ef_max=500, dynamic_ef_factor=8, ef=-1, ef_construction=128, filter_strategy=<VectorFilterStrategy.SWEEPING: 'sweeping'>, flat_search_cutoff=40000, max_connections=32, skip=False, vector_cache_max_objects=1000000000000))})}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.collections.list_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a40c6b03",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnexpectedStatusCodeError",
     "evalue": "Collection may not have been created properly.! Unexpected status code: 422, with response body: {'error': [{'message': 'target vector \"text_vector\": vectorizer: no module with name \"text2vec-transformers\" present'}]}.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnexpectedStatusCodeError\u001b[39m                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mweaviate\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Configure\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m collection = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollections\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvector_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVectors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext2vec_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext_vector\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m            \u001b[49m\u001b[43msource_properties\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproperties\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProperty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataType\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTEXT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Additional parameters not shown\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/weaviate/collections/collections/executor.py:240\u001b[39m, in \u001b[36m_CollectionsExecutor.create\u001b[39m\u001b[34m(self, name, description, generative_config, inverted_index_config, multi_tenancy_config, properties, references, replication_config, reranker_config, sharding_config, vector_index_config, vectorizer_config, vector_config, data_model_properties, data_model_references, skip_argument_validation)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    236\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WeaviateInvalidInputError(\n\u001b[32m    237\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid collection config create parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    238\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_to_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_model_properties\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_model_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_model_references\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_model_references\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_argument_validation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_argument_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/weaviate/collections/collections/executor.py:104\u001b[39m, in \u001b[36m_CollectionsExecutor.__create\u001b[39m\u001b[34m(self, config, data_model_properties, data_model_references, skip_argument_validation)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__create\u001b[39m(\n\u001b[32m     94\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     95\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    102\u001b[39m     Awaitable[CollectionAsync[Properties, References]],\n\u001b[32m    103\u001b[39m ]:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/schema\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweaviate_object\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_msg\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCollection may not have been created properly.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatus_codes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_ExpectedStatusCodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mok_in\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCreate collection\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Awaitable):\n\u001b[32m    113\u001b[39m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_\u001b[39m():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/weaviate/connect/v4.py:822\u001b[39m, in \u001b[36m_ConnectionBase.post\u001b[39m\u001b[34m(self, path, weaviate_object, params, error_msg, status_codes, is_gql_query)\u001b[39m\n\u001b[32m    813\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m    814\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    815\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    820\u001b[39m     is_gql_query: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    821\u001b[39m ) -> executor.Result[Response]:\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_version_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweaviate_object\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweaviate_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_msg\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_msg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatus_codes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstatus_codes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_gql_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_gql_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/weaviate/connect/v4.py:716\u001b[39m, in \u001b[36m_ConnectionBase._send\u001b[39m\u001b[34m(self, method, url, error_msg, status_codes, is_gql_query, weaviate_object, params, check_is_connected)\u001b[39m\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexc\u001b[39m(e: \u001b[38;5;167;01mException\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    714\u001b[39m     \u001b[38;5;28mself\u001b[39m.__handle_exceptions(e, error_msg)\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexception_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/weaviate/connect/executor.py:99\u001b[39m, in \u001b[36mexecute\u001b[39m\u001b[34m(method, response_callback, exception_callback, *args, **kwargs)\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resp_call\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(T, \u001b[43mexception_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/weaviate/connect/v4.py:714\u001b[39m, in \u001b[36m_ConnectionBase._send.<locals>.exc\u001b[39m\u001b[34m(e)\u001b[39m\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexc\u001b[39m(e: \u001b[38;5;167;01mException\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m714\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__handle_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_msg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/weaviate/connect/v4.py:670\u001b[39m, in \u001b[36m_ConnectionBase.__handle_exceptions\u001b[39m\u001b[34m(self, e, error_msg)\u001b[39m\n\u001b[32m    668\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeout):\n\u001b[32m    669\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WeaviateTimeoutError(error_msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m670\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/weaviate/connect/executor.py:95\u001b[39m, in \u001b[36mexecute\u001b[39m\u001b[34m(method, response_callback, exception_callback, *args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m cast(T, exception_callback(e))\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _execute()\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m resp_call = \u001b[43mresponse_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp_call, Awaitable)\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp_call\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/weaviate/connect/v4.py:711\u001b[39m, in \u001b[36m_ConnectionBase._send.<locals>.resp\u001b[39m\u001b[34m(res)\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresp\u001b[39m(res: Response) -> Response:\n\u001b[32m--> \u001b[39m\u001b[32m711\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__handle_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_msg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus_codes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SevenSix/etl_data_processing/.venv/lib/python3.11/site-packages/weaviate/connect/v4.py:681\u001b[39m, in \u001b[36m_ConnectionBase.__handle_response\u001b[39m\u001b[34m(self, response, error_msg, status_codes)\u001b[39m\n\u001b[32m    679\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InsufficientPermissionsError(response)\n\u001b[32m    680\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m status_codes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m status_codes.ok:\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedStatusCodeError(error_msg, response)\n\u001b[32m    682\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[31mUnexpectedStatusCodeError\u001b[39m: Collection may not have been created properly.! Unexpected status code: 422, with response body: {'error': [{'message': 'target vector \"text_vector\": vectorizer: no module with name \"text2vec-transformers\" present'}]}."
     ]
    }
   ],
   "source": [
    "from weaviate.classes.config import Configure\n",
    "\n",
    "collection = client.collections.create(\n",
    "    collection_name,\n",
    "    vector_config=[\n",
    "        Configure.Vectors.text2vec_transformers(\n",
    "            name=\"text_vector\",\n",
    "            source_properties=[\"text\"]\n",
    "        )\n",
    "    ],\n",
    "    properties=[\n",
    "        wc.Property(name=\"text\", data_type=wc.DataType.TEXT),\n",
    "    ],\n",
    "    # Additional parameters not shown\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c9e2031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CollectionConfig(name='DemoCollection', description=None, generative_config=None, inverted_index_config=_InvertedIndexConfig(bm25=_BM25Config(b=0.75, k1=1.2), cleanup_interval_seconds=60, index_null_state=False, index_property_length=False, index_timestamps=False, stopwords=_StopwordsConfig(preset=<StopwordsPreset.EN: 'en'>, additions=None, removals=None)), multi_tenancy_config=_MultiTenancyConfig(enabled=False, auto_tenant_creation=False, auto_tenant_activation=False), properties=[_Property(name='text', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer=None, vectorizer_configs={'text2vec-jinaai': _PropertyVectorizerConfig(skip=False, vectorize_property_name=False)})], references=[], replication_config=_ReplicationConfig(factor=1, async_enabled=False, deletion_strategy=<ReplicationDeletionStrategy.NO_AUTOMATED_RESOLUTION: 'NoAutomatedResolution'>), reranker_config=_RerankerConfig(model={'model': 'jina-reranker-v2-base-multilingual'}, reranker=<Rerankers.JINAAI: 'reranker-jinaai'>), sharding_config=_ShardingConfig(virtual_per_physical=128, desired_count=1, actual_count=1, desired_virtual_count=128, actual_virtual_count=128, key='_id', strategy='hash', function='murmur3'), vector_index_config=None, vector_index_type=None, vectorizer_config=None, vectorizer=None, vector_config={'text_vector': _NamedVectorConfig(vectorizer=_NamedVectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_JINAAI: 'text2vec-jinaai'>, model={'baseURL': 'https://api.jina.ai', 'model': 'jina-embeddings-v3', 'vectorizeClassName': True}, source_properties=['text']), vector_index_config=_VectorIndexConfigHNSW(multi_vector=None, quantizer=None, cleanup_interval_seconds=300, distance_metric=<VectorDistances.COSINE: 'cosine'>, dynamic_ef_min=100, dynamic_ef_max=500, dynamic_ef_factor=8, ef=-1, ef_construction=128, filter_strategy=<VectorFilterStrategy.SWEEPING: 'sweeping'>, flat_search_cutoff=40000, max_connections=32, skip=False, vector_cache_max_objects=1000000000000))})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.config.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5deb005c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert complete.\n"
     ]
    }
   ],
   "source": [
    "# Insert text chunks and metadata into vector DB collection\n",
    "response = collection.data.insert_many(data)\n",
    "\n",
    "if response.has_errors:\n",
    "    print(response.errors)\n",
    "else:\n",
    "    print(\"Insert complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c1dd89fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'ওস্তাদজি আমার দিকে সপ্রশ্ন চোখে চাইলেন— ‘ওরা এসেছিল নাকি?’\\nবললাম— ‘এসেছিল।’\\nতিনি তৃপ্তস্বরে বললেন— ‘আজ বাজানো ভাল হয়েছে; মন বসে গিয়েছিল। তোমরা ভয় পাওনি তো?’\\nএতক্ষণে শালার ধ্যানভঙ্গ হল। সে পকেট থেকে একটি রুমাল এবং একটি গিনি বার করল; গিনি রুমালের ওপর রেখে রুমাল ওস্তাদজির পায়ের কাছে রাখল। তারপর লম্বা হয়ে তাঁকে প্রণাম করল।'}\n",
      "0.6022896766662598\n",
      "{'text': 'ওস্তাদজি নিতান্ত সহজভাবেই কথাটা বললেন, কিন্তু আমি সচকিত হয়ে উঠলাম। ওস্তাদজি আমার দিকে চেয়ে বললেন— ‘মালকোষ যদি শুদ্ধভাবে বাজানো যায় তাহলে জিনও আসে। ওরা মালকোষ রাগ শুনতে বড় ভালবাসে।’'}\n",
      "0.6902013421058655\n",
      "{'text': 'ওস্তাদজি বাজাতে শুরু করলেন। লক্ষ্য করলাম, তাঁর হাতের আঙুলগুলো লোহার তারের মতো বাঁকা-বাঁকা, কঠিন; কিন্তু সেতারের তারের ওপর তাদের স্পর্শ কি নরম! যেন ফুলের বাগানে মৌমাছি গুঞ্জন করে বেড়াচ্ছে। তিনি প্রথমে খুব ঠায়ে বাজতে শুরু করলেন, তারপর আস্তে আস্তে তালের গতি দ্রুত হতে লাগল। আমি উচ্চসঙ্গীতের সমঝদার নই কিন্তু শুনতে শুনতে তন্ময় হয়ে গেলাম। কে যেন ওই সুরের মধ্যে ডুক্\\u200cরে ডুক্\\u200cরে মাথা কুটে কুটে কাঁদছে, যেন অব্যক্তকণ্ঠে'}\n",
      "0.7106322050094604\n",
      "{'text': 'চারিদিকে জ্যোৎস্না ঝিমঝিম করছে; দূর থেকে শহরের যেটুকু শব্দ আসছে তাও যেন দূরত্বের দ্বারা মোলায়েম হয়ে আসছে। ওস্তাদজি যন্ত্র বেঁধে নিয়ে বললেন—‘মালকোষ বাজাচ্ছি। একটা কথা বলে রাখি, যদি কিছু দেখতে পাও ভয় পেয়ো না।’'}\n",
      "0.7244835495948792\n",
      "{'text': 'থাকবে না তখন বাজনা শোনাবেন। যাবেন আপনি আমার সঙ্গে?’\\nনেই কাজ তো খই ভাজ। উচ্চাঙ্গ গান-বাজনার প্রতি আমার বিশেষ আসক্তি নেই; ধ্রুপদ চৌতাল ধামার দশকুশী বুঝি না; রবীন্দ্র-সঙ্গীতেই আমার আত্মা পরিতুষ্ট। কিন্তু বিনা মাশুলে যখন এতবড় একজন ওস্তাদের বাজনা শোনার সুযোগ হয়েছে তখন ছাড়ি কেন। বললাম— ‘আচ্ছা যাব।’'}\n",
      "0.7721114754676819\n"
     ]
    }
   ],
   "source": [
    "from weaviate.classes.query import MetadataQuery\n",
    "\n",
    "response = collection.query.near_text(\n",
    "    query=\"বাজানো ভাল হয়েছে\",\n",
    "    limit=5,\n",
    "    return_metadata=MetadataQuery(distance=True),\n",
    "    return_properties=[\"text\"],\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o.properties)\n",
    "    print(o.metadata.distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de342b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'text': 'BASIC PURCHASE AGREEMENT\\nThis Agreement is made by and between Sevensix Inc., a corporation organized and existing under the laws of Japan, having its principal place of business at 17F Roppongi Hills Mori tower, 6-10-1, Roppongi, Minato-ku, Tokyo , Japan ( \" Buyer \" ) and 3Coptics Co., Ltd., a corporation organized and existing under the laws of China, having its principal place of business at No.10, Kexing Road, NanShan District, Shenzhen, China( \" Seller \" ).'}\n",
    "0.7579280734062195\n",
    "{'text': 'Buyer :\\nSevensix Inc.\\nSign : ______________________\\nName : Yosuke Hane\\nTitle : Chief Executive Officer\\nSeller :\\n3Coptics co.,ltd.\\nSign : ___________________________\\nName : __________________________\\nTitle : ___________________________'}\n",
    "0.7665644884109497\n",
    "{'text': 'Article 24 Governing Law\\nThe validity, construction, performance and enforceability of this Agreement and/or each Individual Sales Contract shall be governed by and construed under the laws of Japan[, excluding the United Nations Convention on Contracts for the International Sale of Goods].'}\n",
    "0.8507193922996521\n",
    "{'text': 'Article 8 Warranty\\n- (4) This warranty shall survive any inspection, acceptance or payment by Buyer. In the event of any breach by Seller of any of its warranties set forth herein, Buyer shall have the right, at its sole discretion, either to request Seller to repair or replace defective Products or any parts thereof, or to refund a portion of the sales price applicable thereto at Seller b s expense without prejudice to any other remedy, and Seller shall be responsible for report of investigation on cause of the defect which Buyer requests, and Seller shall be liable for all loss and/or damage, direct or consequential, caused by Seller b s breach of any of the warranties hereunder.\\n- (5) By the request of the buyer, the buyer returns the product concerned for a seller, and the buyer shall take responsibility to report a cause investigation and the findings that the buyer demands to the seller for trouble, an obstacle, the defective merchandise which occurred during this term of a guarantee. It is decided that a seller bears the expense that it costs for the return of this product, and the buyer can return the product concerned to a seller on FCA Tokyo condition.'}\n",
    "0.8972655534744263\n",
    "{'text': 'Article 25 Arbitration\\nAll disputes, controversies or differences arising out of or in connection with this contract shall be finally settled by arbitration in accordance with the Commercial Arbitration Rules of The\\nJapan Commercial Arbitration Association. The place of the arbitration shall be Tokyo, Japan.'}\n",
    "0.9014863967895508"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f31e5cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DemoCollection': _CollectionConfig(name='DemoCollection', description=None, generative_config=None, inverted_index_config=_InvertedIndexConfig(bm25=_BM25Config(b=0.75, k1=1.2), cleanup_interval_seconds=60, index_null_state=False, index_property_length=False, index_timestamps=False, stopwords=_StopwordsConfig(preset=<StopwordsPreset.EN: 'en'>, additions=None, removals=None)), multi_tenancy_config=_MultiTenancyConfig(enabled=False, auto_tenant_creation=False, auto_tenant_activation=False), properties=[], references=[], replication_config=_ReplicationConfig(factor=1, async_enabled=False, deletion_strategy=<ReplicationDeletionStrategy.NO_AUTOMATED_RESOLUTION: 'NoAutomatedResolution'>), reranker_config=None, sharding_config=_ShardingConfig(virtual_per_physical=128, desired_count=1, actual_count=1, desired_virtual_count=128, actual_virtual_count=128, key='_id', strategy='hash', function='murmur3'), vector_index_config=None, vector_index_type=None, vectorizer_config=None, vectorizer=None, vector_config={'title_vector': _NamedVectorConfig(vectorizer=_NamedVectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_TRANSFORMERS: 'text2vec-transformers'>, model={'poolingStrategy': 'masked_mean', 'vectorizeClassName': True}, source_properties=['title']), vector_index_config=_VectorIndexConfigHNSW(multi_vector=None, quantizer=None, cleanup_interval_seconds=300, distance_metric=<VectorDistances.COSINE: 'cosine'>, dynamic_ef_min=100, dynamic_ef_max=500, dynamic_ef_factor=8, ef=-1, ef_construction=128, filter_strategy=<VectorFilterStrategy.SWEEPING: 'sweeping'>, flat_search_cutoff=40000, max_connections=32, skip=False, vector_cache_max_objects=1000000000000))}),\n",
       " 'Docling': _CollectionConfig(name='Docling', description=None, generative_config=None, inverted_index_config=_InvertedIndexConfig(bm25=_BM25Config(b=0.75, k1=1.2), cleanup_interval_seconds=60, index_null_state=False, index_property_length=False, index_timestamps=False, stopwords=_StopwordsConfig(preset=<StopwordsPreset.EN: 'en'>, additions=None, removals=None)), multi_tenancy_config=_MultiTenancyConfig(enabled=False, auto_tenant_creation=False, auto_tenant_activation=False), properties=[], references=[], replication_config=_ReplicationConfig(factor=1, async_enabled=False, deletion_strategy=<ReplicationDeletionStrategy.NO_AUTOMATED_RESOLUTION: 'NoAutomatedResolution'>), reranker_config=None, sharding_config=_ShardingConfig(virtual_per_physical=128, desired_count=1, actual_count=1, desired_virtual_count=128, actual_virtual_count=128, key='_id', strategy='hash', function='murmur3'), vector_index_config=None, vector_index_type=None, vectorizer_config=None, vectorizer=None, vector_config={'title_vector': _NamedVectorConfig(vectorizer=_NamedVectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_TRANSFORMERS: 'text2vec-transformers'>, model={'poolingStrategy': 'masked_mean', 'vectorizeClassName': True}, source_properties=['title']), vector_index_config=_VectorIndexConfigHNSW(multi_vector=None, quantizer=None, cleanup_interval_seconds=300, distance_metric=<VectorDistances.COSINE: 'cosine'>, dynamic_ef_min=100, dynamic_ef_max=500, dynamic_ef_factor=8, ef=-1, ef_construction=128, filter_strategy=<VectorFilterStrategy.SWEEPING: 'sweeping'>, flat_search_cutoff=40000, max_connections=32, skip=False, vector_cache_max_objects=1000000000000))}),\n",
       " 'Docling1': _CollectionConfig(name='Docling1', description=None, generative_config=None, inverted_index_config=_InvertedIndexConfig(bm25=_BM25Config(b=0.75, k1=1.2), cleanup_interval_seconds=60, index_null_state=False, index_property_length=False, index_timestamps=False, stopwords=_StopwordsConfig(preset=<StopwordsPreset.EN: 'en'>, additions=None, removals=None)), multi_tenancy_config=_MultiTenancyConfig(enabled=False, auto_tenant_creation=False, auto_tenant_activation=False), properties=[_Property(name='text', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer=None, vectorizer_configs={'text2vec-transformers': _PropertyVectorizerConfig(skip=False, vectorize_property_name=False)})], references=[], replication_config=_ReplicationConfig(factor=1, async_enabled=False, deletion_strategy=<ReplicationDeletionStrategy.NO_AUTOMATED_RESOLUTION: 'NoAutomatedResolution'>), reranker_config=None, sharding_config=_ShardingConfig(virtual_per_physical=128, desired_count=1, actual_count=1, desired_virtual_count=128, actual_virtual_count=128, key='_id', strategy='hash', function='murmur3'), vector_index_config=None, vector_index_type=None, vectorizer_config=None, vectorizer=None, vector_config={'title_vector': _NamedVectorConfig(vectorizer=_NamedVectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_TRANSFORMERS: 'text2vec-transformers'>, model={'poolingStrategy': 'masked_mean', 'vectorizeClassName': True}, source_properties=['title']), vector_index_config=_VectorIndexConfigHNSW(multi_vector=None, quantizer=None, cleanup_interval_seconds=300, distance_metric=<VectorDistances.COSINE: 'cosine'>, dynamic_ef_min=100, dynamic_ef_max=500, dynamic_ef_factor=8, ef=-1, ef_construction=128, filter_strategy=<VectorFilterStrategy.SWEEPING: 'sweeping'>, flat_search_cutoff=40000, max_connections=32, skip=False, vector_cache_max_objects=1000000000000))}),\n",
       " 'Docling2': _CollectionConfig(name='Docling2', description=None, generative_config=None, inverted_index_config=_InvertedIndexConfig(bm25=_BM25Config(b=0.75, k1=1.2), cleanup_interval_seconds=60, index_null_state=False, index_property_length=False, index_timestamps=False, stopwords=_StopwordsConfig(preset=<StopwordsPreset.EN: 'en'>, additions=None, removals=None)), multi_tenancy_config=_MultiTenancyConfig(enabled=False, auto_tenant_creation=False, auto_tenant_activation=False), properties=[_Property(name='text', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer=None, vectorizer_configs={'text2vec-transformers': _PropertyVectorizerConfig(skip=False, vectorize_property_name=False)})], references=[], replication_config=_ReplicationConfig(factor=1, async_enabled=False, deletion_strategy=<ReplicationDeletionStrategy.NO_AUTOMATED_RESOLUTION: 'NoAutomatedResolution'>), reranker_config=None, sharding_config=_ShardingConfig(virtual_per_physical=128, desired_count=1, actual_count=1, desired_virtual_count=128, actual_virtual_count=128, key='_id', strategy='hash', function='murmur3'), vector_index_config=None, vector_index_type=None, vectorizer_config=None, vectorizer=None, vector_config={'text_vector': _NamedVectorConfig(vectorizer=_NamedVectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_TRANSFORMERS: 'text2vec-transformers'>, model={'poolingStrategy': 'masked_mean', 'vectorizeClassName': True}, source_properties=['text']), vector_index_config=_VectorIndexConfigHNSW(multi_vector=None, quantizer=None, cleanup_interval_seconds=300, distance_metric=<VectorDistances.COSINE: 'cosine'>, dynamic_ef_min=100, dynamic_ef_max=500, dynamic_ef_factor=8, ef=-1, ef_construction=128, filter_strategy=<VectorFilterStrategy.SWEEPING: 'sweeping'>, flat_search_cutoff=40000, max_connections=32, skip=False, vector_cache_max_objects=1000000000000))}),\n",
       " 'Docling3': _CollectionConfig(name='Docling3', description=None, generative_config=None, inverted_index_config=_InvertedIndexConfig(bm25=_BM25Config(b=0.75, k1=1.2), cleanup_interval_seconds=60, index_null_state=False, index_property_length=False, index_timestamps=False, stopwords=_StopwordsConfig(preset=<StopwordsPreset.EN: 'en'>, additions=None, removals=None)), multi_tenancy_config=_MultiTenancyConfig(enabled=False, auto_tenant_creation=False, auto_tenant_activation=False), properties=[_Property(name='text', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer=None, vectorizer_configs={'text2vec-transformers': _PropertyVectorizerConfig(skip=False, vectorize_property_name=False)})], references=[], replication_config=_ReplicationConfig(factor=1, async_enabled=False, deletion_strategy=<ReplicationDeletionStrategy.NO_AUTOMATED_RESOLUTION: 'NoAutomatedResolution'>), reranker_config=None, sharding_config=_ShardingConfig(virtual_per_physical=128, desired_count=1, actual_count=1, desired_virtual_count=128, actual_virtual_count=128, key='_id', strategy='hash', function='murmur3'), vector_index_config=None, vector_index_type=None, vectorizer_config=None, vectorizer=None, vector_config={'text_vector': _NamedVectorConfig(vectorizer=_NamedVectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_TRANSFORMERS: 'text2vec-transformers'>, model={'poolingStrategy': 'masked_mean', 'vectorizeClassName': True}, source_properties=['text']), vector_index_config=_VectorIndexConfigHNSW(multi_vector=None, quantizer=None, cleanup_interval_seconds=300, distance_metric=<VectorDistances.COSINE: 'cosine'>, dynamic_ef_min=100, dynamic_ef_max=500, dynamic_ef_factor=8, ef=-1, ef_construction=128, filter_strategy=<VectorFilterStrategy.SWEEPING: 'sweeping'>, flat_search_cutoff=40000, max_connections=32, skip=False, vector_cache_max_objects=1000000000000))})}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.collections.list_all(simple=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac152516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl-data-extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
